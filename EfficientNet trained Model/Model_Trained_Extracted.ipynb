{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Trained_Extracted.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RWtAWAat9gd"
      },
      "source": [
        "!pip install pytorch-ignite==0.2.* tensorboardX==1.6.*\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import ignite\n",
        "import os, os.path\n",
        "import shutil\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.nn import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "seed = 17\n",
        "random.seed(seed)\n",
        "_ = torch.manual_seed(seed)\n",
        "\n",
        "torch.set_printoptions(precision=8,sci_mode=False)\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgb7DJcYpymg"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "from torchvision import transforms\n",
        "tfms = transforms.Compose([transforms.Resize(224),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
        "\n",
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_array = []\n",
        "    class_name = []\n",
        "    itr = 0\n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread(image_path)\n",
        "            image=cv2.resize(image, (224, 224),interpolation = cv2.INTER_AREA)\n",
        "            # image = tfms(image).unsqueeze(0) \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir1)\n",
        "    return img_data_array, class_name\n",
        "\n",
        "!cp  /content/drive/MyDrive/Kaggle/COVID-19_Radiography_Dataset/TestingData.zip /content\n",
        "!unzip '/content/TestingData.zip'\n",
        "!cp  /content/drive/MyDrive/Kaggle/COVID-19_Radiography_Dataset/TrainingData.zip /content\n",
        "!unzip '/content/TrainingData.zip'\n",
        "\n",
        "!mv /content/content/drive/MyDrive/Kaggle/COVID-19_Radiography_Dataset/TrainingData /content\n",
        "!rm -r /content/content\n",
        "!rm -r '/content/TrainingData.zip'\n",
        "!rm -r '/content/TestingData.zip'\n",
        "\n",
        "DIR = '/content/TrainingData/1'\n",
        "print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))\n",
        "DIR = '/content/TrainingData/0'\n",
        "print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))\n",
        "\n",
        "DIR = '/content/TestingData/1'\n",
        "print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))\n",
        "DIR = '/content/TestingData/0'\n",
        "print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBNIWDGNtrBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3436b437-c4a3-4041-d69e-41d19841d222"
      },
      "source": [
        "train_path = '/content/TrainingData'\n",
        "\n",
        "\n",
        "img_data, class_name = create_dataset (train_path)\n",
        "\n",
        "target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
        "target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]\n",
        "class_name = np.array(list(map(int,target_val))).astype('float')\n",
        "\n",
        "target_val = 0\n",
        "target_dict = 0\n",
        "print(len(img_data))\n",
        "\n",
        "imgs = [torch.from_numpy(item).float().permute(2, 0, 1) for item in img_data]\n",
        "imgs = torch.stack(imgs)\n",
        "train_loader = 0\n",
        "train_sample_ds = torch.utils.data.TensorDataset(imgs, torch.Tensor(class_name.tolist()))\n",
        "train_loader = torch.utils.data.DataLoader(train_sample_ds, shuffle=True, batch_size=10)\n",
        "\n",
        "class_name, imgs, train_sample_ds = 0, 0, 0"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX86SYQctw-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa5fa20-7a62-475e-a5c3-e4472ecce5d9"
      },
      "source": [
        "test_path = '/content/TestingData'\n",
        "\n",
        "\n",
        "img_data, class_name = create_dataset (test_path)\n",
        "\n",
        "target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
        "target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]\n",
        "class_name = np.array(list(map(int,target_val))).astype('float')\n",
        "\n",
        "target_val = 0\n",
        "target_dict = 0\n",
        "print(len(img_data))\n",
        "\n",
        "imgs = [torch.from_numpy(item).float().permute(2, 0, 1) for item in img_data]\n",
        "imgs = torch.stack(imgs)\n",
        "\n",
        "train_sample_ds = torch.utils.data.TensorDataset(imgs, torch.Tensor(class_name.tolist()))\n",
        "test_loader = torch.utils.data.DataLoader(train_sample_ds, shuffle=True, batch_size=10)\n",
        "\n",
        "class_name, imgs, train_sample_ds = 0, 0, 0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI4oajhjuenX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghokNgO0t0tg"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.reshape(x.shape[0], -1)\n",
        "\n",
        "class SqueezeExcitation(nn.Module):\n",
        "    \n",
        "    def __init__(self, inplanes, se_planes):\n",
        "        super(SqueezeExcitation, self).__init__()\n",
        "        self.reduce_expand = nn.Sequential(\n",
        "            nn.Conv2d(inplanes, se_planes, \n",
        "                      kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            Swish(),\n",
        "            nn.Conv2d(se_planes, inplanes, \n",
        "                      kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_se = torch.mean(x, dim=(-2, -1), keepdim=True)\n",
        "        x_se = self.reduce_expand(x_se)\n",
        "        return x_se * x\n",
        "\n",
        "\n",
        "class MBConv(nn.Module):\n",
        "    def __init__(self, inplanes, planes, kernel_size, stride, \n",
        "                 expand_rate=1.0, se_rate=0.25, \n",
        "                 drop_connect_rate=0.2):\n",
        "        super(MBConv, self).__init__()\n",
        "\n",
        "        expand_planes = int(inplanes * expand_rate)\n",
        "        se_planes = max(1, int(inplanes * se_rate))\n",
        "\n",
        "        self.expansion_conv = None        \n",
        "        if expand_rate > 1.0:\n",
        "            self.expansion_conv = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, expand_planes, \n",
        "                          kernel_size=1, stride=1, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3),\n",
        "                Swish()\n",
        "            )\n",
        "            inplanes = expand_planes\n",
        "\n",
        "        self.depthwise_conv = nn.Sequential(\n",
        "            nn.Conv2d(inplanes, expand_planes,\n",
        "                      kernel_size=kernel_size, stride=stride, \n",
        "                      padding=kernel_size // 2, groups=expand_planes,\n",
        "                      bias=False),\n",
        "            nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3),\n",
        "            Swish()\n",
        "        )\n",
        "\n",
        "        self.squeeze_excitation = SqueezeExcitation(expand_planes, se_planes)\n",
        "        \n",
        "        self.project_conv = nn.Sequential(\n",
        "            nn.Conv2d(expand_planes, planes, \n",
        "                      kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(planes, momentum=0.01, eps=1e-3),\n",
        "        )\n",
        "\n",
        "        self.with_skip = stride == 1\n",
        "        self.drop_connect_rate = torch.tensor(drop_connect_rate, requires_grad=False)\n",
        "    \n",
        "    def _drop_connect(self, x):        \n",
        "        keep_prob = 1.0 - self.drop_connect_rate\n",
        "        drop_mask = torch.rand(x.shape[0], 1, 1, 1) + keep_prob\n",
        "        drop_mask = drop_mask.type_as(x)\n",
        "        drop_mask.floor_()\n",
        "        return drop_mask * x / keep_prob\n",
        "        \n",
        "    def forward(self, x):\n",
        "        z = x\n",
        "        if self.expansion_conv is not None:\n",
        "            x = self.expansion_conv(x)\n",
        "\n",
        "        x = self.depthwise_conv(x)\n",
        "        x = self.squeeze_excitation(x)\n",
        "        x = self.project_conv(x)\n",
        "        \n",
        "        # Add identity skip\n",
        "        if x.shape == z.shape and self.with_skip:            \n",
        "            if self.training and self.drop_connect_rate is not None:\n",
        "                self._drop_connect(x)\n",
        "            x += z\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SseyUFQujT1"
      },
      "source": [
        "def init_weights(module):    \n",
        "    if isinstance(module, nn.Conv2d):    \n",
        "        nn.init.kaiming_normal_(module.weight, a=0, mode='fan_out')\n",
        "    elif isinstance(module, nn.Linear):\n",
        "        init_range = 1.0 / math.sqrt(module.weight.shape[1])\n",
        "        nn.init.uniform_(module.weight, a=-init_range, b=init_range)\n",
        "        \n",
        "        \n",
        "class EfficientNet(nn.Module):\n",
        "        \n",
        "    def _setup_repeats(self, num_repeats):\n",
        "        return int(math.ceil(self.depth_coefficient * num_repeats))\n",
        "    \n",
        "    def _setup_channels(self, num_channels):\n",
        "        num_channels *= self.width_coefficient\n",
        "        new_num_channels = math.floor(num_channels / self.divisor + 0.5) * self.divisor\n",
        "        new_num_channels = max(self.divisor, new_num_channels)\n",
        "        if new_num_channels < 0.9 * num_channels:\n",
        "            new_num_channels += self.divisor\n",
        "        return new_num_channels\n",
        "\n",
        "    def __init__(self, num_classes=10, \n",
        "                 width_coefficient=1.0,\n",
        "                 depth_coefficient=1.0,\n",
        "                 se_rate=0.25,\n",
        "                 dropout_rate=0.2,\n",
        "                 drop_connect_rate=0.2):\n",
        "        super(EfficientNet, self).__init__()\n",
        "        \n",
        "        self.width_coefficient = width_coefficient\n",
        "        self.depth_coefficient = depth_coefficient\n",
        "        self.divisor = 8\n",
        "                \n",
        "        list_channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
        "        list_channels = [self._setup_channels(c) for c in list_channels]\n",
        "                \n",
        "        list_num_repeats = [1, 2, 2, 3, 3, 4, 1]\n",
        "        list_num_repeats = [self._setup_repeats(r) for r in list_num_repeats]        \n",
        "        \n",
        "        expand_rates = [1, 6, 6, 6, 6, 6, 6]\n",
        "        strides = [1, 2, 2, 2, 1, 2, 1]\n",
        "        kernel_sizes = [3, 3, 5, 3, 5, 5, 3]\n",
        "\n",
        "        # Define stem:\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, list_channels[0], kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(list_channels[0], momentum=0.01, eps=1e-3),\n",
        "            Swish()\n",
        "        )\n",
        "        \n",
        "        # Define MBConv blocks\n",
        "        blocks = []\n",
        "        counter = 0\n",
        "        num_blocks = sum(list_num_repeats)\n",
        "        for idx in range(7):\n",
        "            \n",
        "            num_channels = list_channels[idx]\n",
        "            next_num_channels = list_channels[idx + 1]\n",
        "            num_repeats = list_num_repeats[idx]\n",
        "            expand_rate = expand_rates[idx]\n",
        "            kernel_size = kernel_sizes[idx]\n",
        "            stride = strides[idx]\n",
        "            drop_rate = drop_connect_rate * counter / num_blocks\n",
        "            \n",
        "            name = \"MBConv{}_{}\".format(expand_rate, counter)\n",
        "            blocks.append((\n",
        "                name,\n",
        "                MBConv(num_channels, next_num_channels, \n",
        "                       kernel_size=kernel_size, stride=stride, expand_rate=expand_rate, \n",
        "                       se_rate=se_rate, drop_connect_rate=drop_rate)\n",
        "            ))\n",
        "            counter += 1\n",
        "            for i in range(1, num_repeats):                \n",
        "                name = \"MBConv{}_{}\".format(expand_rate, counter)\n",
        "                drop_rate = drop_connect_rate * counter / num_blocks                \n",
        "                blocks.append((\n",
        "                    name,\n",
        "                    MBConv(next_num_channels, next_num_channels, \n",
        "                           kernel_size=kernel_size, stride=1, expand_rate=expand_rate, \n",
        "                           se_rate=se_rate, drop_connect_rate=drop_rate)                                    \n",
        "                ))\n",
        "                counter += 1\n",
        "        \n",
        "        self.blocks = nn.Sequential(OrderedDict(blocks))\n",
        "        \n",
        "        # Define head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(list_channels[-2], list_channels[-1], \n",
        "                      kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(list_channels[-1], momentum=0.01, eps=1e-3),\n",
        "            Swish(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            Flatten(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(list_channels[-1], num_classes)\n",
        "        )\n",
        "\n",
        "        self.apply(init_weights)\n",
        "        \n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.stem(x)\n",
        "        f = self.blocks(f)\n",
        "        y = self.head(f)\n",
        "        y = self.sig(y)\n",
        "\n",
        "        return y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJe4932Ruo_F"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = EfficientNet(num_classes=1, \n",
        "                     width_coefficient=1.0, depth_coefficient=1.0, \n",
        "                     dropout_rate=0.2).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4s6IIWjuv79"
      },
      "source": [
        "out_label = []\n",
        "true_label = []\n",
        "\n",
        "model_dir = '/content/MODEL_PTH_FILE'\n",
        "\n",
        "def load_mode(model, model_dir):\n",
        "  model_path = os.path.join(model_dir, 'model.pth')\n",
        "  with open(model_path, 'rb') as f:\n",
        "      model.load_state_dict(torch.load(f))  \n",
        "  return model\n",
        "\n",
        "# Provided model saving functions\n",
        "def save_model(model, model_dir):\n",
        "  print(\"Saving the model.\")\n",
        "  if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "  path = os.path.join(model_dir, 'model.pth')\n",
        "  # save state dictionary\n",
        "  torch.save(model.cpu().state_dict(), path)\n",
        "    \n",
        "# Provided train function\n",
        "def train(model, train_loader, epochs, optimizer, criterion, device):\n",
        "  \"\"\"\n",
        "  This is the training method that is called by the PyTorch training script. The parameters\n",
        "  passed are as follows:\n",
        "  model        - The PyTorch model that we wish to train.\n",
        "  train_loader - The PyTorch DataLoader that should be used during training.\n",
        "  epochs       - The total number of epochs to train for.\n",
        "  optimizer    - The optimizer to use during training.\n",
        "  criterion    - The loss function used for training. \n",
        "  device       - Where the model and data should be loaded (gpu or cpu).\n",
        "  \"\"\"\n",
        "  \n",
        "  for epoch in range(1, epochs + 1):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      local__out_label = []\n",
        "      local__out_target = []\n",
        "      for batch_idx, (data, target) in enumerate(train_loader, 1):\n",
        "          # prep data\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          optimizer.zero_grad() # zero accumulated gradients\n",
        "          # get output of SimpleNet\n",
        "          output = model(data)\n",
        "          # calculate loss and perform backprop\n",
        "          \n",
        "          loss = criterion(output, target.reshape(10, 1))\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "  \n",
        "          total_loss += loss.item()\n",
        "          \n",
        "          out_np = output.cpu().detach().numpy()\n",
        "          local__out_label.append(np.squeeze(out_np.round()))\n",
        "          out_target = target.cpu().detach().numpy()\n",
        "          local__out_target.append(np.squeeze(out_target))\n",
        "\n",
        "      out_label = np.concatenate( local__out_label, axis=0 )\n",
        "      true_label = np.concatenate( local__out_target, axis=0)\n",
        "      train_accuracy=accuracy_score(true_label, out_label) *100   \n",
        "\n",
        "      # print loss stats\n",
        "      print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss / len(train_loader) * 100), 'train accuracy: ', train_accuracy, '%')\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDy4yc0CPa0w",
        "outputId": "d48daa2f-1a01-4b6d-9844-820fe541c2a6"
      },
      "source": [
        "train(model, train_loader, 100, optimizer, criterion, device)\n",
        "# Save model data\n",
        "save_model(model, model_dir)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 0.7647614330349437 train accuracy:  99.76666666666667 %\n",
            "Saving the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbCzbC-JP7PD"
      },
      "source": [
        "# For loading the model, uncomment this cell\n",
        "model = load_mode(model, model_dir)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X41anQRuyNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07b7193-9344-4bb0-9871-cd287130bb7a"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "out_label = []\n",
        "true_label = []\n",
        "\n",
        "\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    model.eval().to(device)\n",
        "    local__out_label = []\n",
        "    local__out_target = []\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(test_loader, 1):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(data.to(device))\n",
        "        \n",
        "        out_np = outputs.cpu().detach().numpy()\n",
        "        local__out_label.append(np.squeeze(out_np.round()))\n",
        "        \t\t    \n",
        "        out_target = target.cpu().detach().numpy()\n",
        "        local__out_target.append(np.squeeze(out_target))\n",
        "\n",
        "out_label = np.concatenate(local__out_label, axis=0)\n",
        "true_label = np.concatenate(local__out_target, axis=0 )\n",
        "\n",
        "test_accuracy=accuracy_score(true_label, out_label)\n",
        "print('Test accuracy: ', test_accuracy*100, '% ')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:  94.8051948051948 % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTb1zKgQByvt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuSyCexhCpe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2447cec9-b3ce-499f-bca2-4633c1554f9c"
      },
      "source": [
        "\n",
        "activation = {}\n",
        "inputs = {}\n",
        "\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "        inputs[name] = input\n",
        "    return hook\n",
        "\n",
        "\n",
        "\n",
        "## This section is for exporting MBConv layers starting from 6_1\n",
        "# Convolution for all MBConv*_* layers\n",
        "def get_layer_matrices_conv2d(layer, dict_name):\n",
        "  if dict_name == \"MBConv1_0\":\n",
        "    print(\"No expansion layer for this version: Conv2d\")\n",
        "  else:\n",
        "    layer.expansion_conv[0].register_forward_hook(get_activation('expansion_conv' + dict_name))\n",
        "  layer.depthwise_conv[0].register_forward_hook(get_activation('depthwise_conv' + dict_name))\n",
        "  layer.squeeze_excitation.reduce_expand[0].register_forward_hook(get_activation('squeeze_excitation1' + dict_name))\n",
        "  layer.squeeze_excitation.reduce_expand[2].register_forward_hook(get_activation('squeeze_excitation2' + dict_name))\n",
        "  layer.project_conv[0].register_forward_hook(get_activation('project_conv' + dict_name))\n",
        "\n",
        "# BatchNorm for all MBConv*_* layers\n",
        "def get_layer_matrices_BN(layer, dict_name):\n",
        "  if dict_name == \"MBConv1_0\":\n",
        "    print(\"No expansion layer for this version: BN\")\n",
        "  else:  \n",
        "    layer.expansion_conv[1].register_forward_hook(get_activation('expansion_conv_BN' + dict_name))\n",
        "  layer.depthwise_conv[1].register_forward_hook(get_activation('depthwise_conv_BN' + dict_name))\n",
        "  layer.project_conv[1].register_forward_hook(get_activation('project_conv_BN' + dict_name))\n",
        "\n",
        "# Activation for all MBConv*_* layers\n",
        "def get_layer_matrices_activation(layer, dict_name):\n",
        "  if dict_name == \"MBConv1_0\":\n",
        "    print(\"No expansion layer for this version: Activation\")\n",
        "  else:  \n",
        "    layer.expansion_conv[2].register_forward_hook(get_activation('expansion_conv_swish' + dict_name))\n",
        "  layer.depthwise_conv[2].register_forward_hook(get_activation('depthwise_conv_swish' + dict_name))\n",
        "  layer.squeeze_excitation.reduce_expand[1].register_forward_hook(get_activation('squeeze_excitation1_swish' + dict_name))\n",
        "  layer.squeeze_excitation.reduce_expand[3].register_forward_hook(get_activation('squeeze_excitation2_sigmoid' + dict_name))\n",
        "\n",
        "#Stem data\n",
        "model.stem[0].register_forward_hook(get_activation('stem'))\n",
        "model.stem[1].register_forward_hook(get_activation('stem_BN'))\n",
        "model.stem[2].register_forward_hook(get_activation('stem_swish'))\n",
        "\n",
        "\n",
        "# MBConv1_0 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv1_0, \"MBConv1_0\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv1_0, \"MBConv1_0\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv1_0, \"MBConv1_0\")\n",
        "\n",
        "# MBConv6_1 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_1, \"MBConv6_1\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_1, \"MBConv6_1\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_1, \"MBConv6_1\")\n",
        "\n",
        "# MBConv6_2 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_2, \"MBConv6_2\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_2, \"MBConv6_2\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_2, \"MBConv6_2\")\n",
        "\n",
        "# MBConv6_3 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_3, \"MBConv6_3\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_3, \"MBConv6_3\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_3, \"MBConv6_3\")\n",
        "\n",
        "# MBConv6_4 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_4, \"MBConv6_4\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_4, \"MBConv6_4\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_4, \"MBConv6_4\")\n",
        "\n",
        "# MBConv6_5 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_5, \"MBConv6_5\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_5, \"MBConv6_5\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_5, \"MBConv6_5\")\n",
        "\n",
        "# MBConv6_6 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_6, \"MBConv6_6\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_6, \"MBConv6_6\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_6, \"MBConv6_6\")\n",
        "\n",
        "# MBConv6_7 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_7, \"MBConv6_7\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_7, \"MBConv6_7\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_7, \"MBConv6_7\")\n",
        "\n",
        "# MBConv6_8 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_8, \"MBConv6_8\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_8, \"MBConv6_8\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_8, \"MBConv6_8\")\n",
        "\n",
        "# MBConv6_9 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_9, \"MBConv6_9\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_9, \"MBConv6_9\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_9, \"MBConv6_9\")\n",
        "\n",
        "# MBConv6_10 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_10, \"MBConv6_10\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_10, \"MBConv6_10\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_10, \"MBConv6_10\")\n",
        "\n",
        "# MBConv6_11 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_11, \"MBConv6_11\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_11, \"MBConv6_11\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_11, \"MBConv6_11\")\n",
        "\n",
        "# MBConv6_12 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_12, \"MBConv6_12\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_12, \"MBConv6_12\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_12, \"MBConv6_12\")\n",
        "\n",
        "# MBConv6_13 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_13, \"MBConv6_13\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_13, \"MBConv6_13\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_13, \"MBConv6_13\")\n",
        "\n",
        "# MBConv6_14 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_14, \"MBConv6_14\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_14, \"MBConv6_14\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_14, \"MBConv6_14\")\n",
        "\n",
        "# MBConv6_15 all the details\n",
        "get_layer_matrices_conv2d(model.blocks.MBConv6_15, \"MBConv6_15\")\n",
        "get_layer_matrices_BN(model.blocks.MBConv6_15, \"MBConv6_15\")\n",
        "get_layer_matrices_activation(model.blocks.MBConv6_15, \"MBConv6_15\")\n",
        "\n",
        "#head data\n",
        "model.head[0].register_forward_hook(get_activation('head'))\n",
        "model.head[1].register_forward_hook(get_activation('head_BN'))\n",
        "model.head[2].register_forward_hook(get_activation('head_swish'))\n",
        "model.head[3].register_forward_hook(get_activation('head_pooling'))\n",
        "model.head[4].register_forward_hook(get_activation('head_flatten'))\n",
        "model.head[5].register_forward_hook(get_activation('head_dropOut'))\n",
        "model.head[6].register_forward_hook(get_activation('head_linear'))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No expansion layer for this version: Conv2d\n",
            "No expansion layer for this version: BN\n",
            "No expansion layer for this version: Activation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f836cd2e250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwusi3CaBze6"
      },
      "source": [
        "## This cell for Conv2d parameters only fot a sublayer_name\n",
        "\n",
        "%%capture cap --no-stderr\n",
        "torch.set_printoptions(precision=8, sci_mode=False)\n",
        "\n",
        "sublayer_name = \"MBConv6_2\"\n",
        "layer_attr = getattr(model.blocks, sublayer_name)\n",
        "\n",
        "def reshape_input(input, name):\n",
        "  mat_input = input\n",
        "  print(name + \" has a shape of\", mat_input[0].shape)\n",
        "  mat_input_reshaped = torch.reshape(mat_input[0], (1, 1, 1, mat_input[0].numel()))\n",
        "  print(name + \" matrix is \", mat_input_reshaped)\n",
        "  \n",
        "# Weight shapes function  \n",
        "def print_weight_shapes(layer, name):\n",
        "  if sublayer_name == \"MBConv1_0\":\n",
        "    print(\"No expansion wegihts to print\")\n",
        "  else:  \n",
        "    print('Weight dimensions for conv2d operations')\n",
        "    print(name, \"\\n\", \"Weight matrix shape = \", layer.expansion_conv[0].weight.shape)\n",
        "    print(name, \"\\n\", \"Weight matrix shape = \", layer.depthwise_conv[0].weight.shape)\n",
        "    print(name, \"\\n\", \"Weight matrix shape = \", layer.squeeze_excitation.reduce_expand[0].weight.shape)\n",
        "    print(name, \"\\n\", \"Weight matrix shape = \", layer.squeeze_excitation.reduce_expand[2].weight.shape)\n",
        "    print(name, \"\\n\", \"Weight matrix shape = \", layer.project_conv[0].weight.shape)\n",
        "\n",
        "# Bias shapes function\n",
        "def print_bias_shapes(layer, name):\n",
        "  if sublayer_name == \"MBConv1_0\":\n",
        "    print(\"No expansion weights to print\")\n",
        "  else:\n",
        "    print('Bias dimensions for conv2d operations')\n",
        "    if layer.expansion_conv[0].bias is not None:\n",
        "      print(name, \"\\n\", \"Bias matrix shape = \", layer.expansion_conv[0].bias.shape)\n",
        "    if layer.depthwise_conv[0].bias is not None:\n",
        "      print(name, \"\\n\", \"Bias matrix shape = \", layer.depthwise_conv[0].bias.shape)\n",
        "    if layer.squeeze_excitation.reduce_expand[0].bias is not None:\n",
        "      print(name, \"\\n\", \"Bias matrix shape = \", layer.squeeze_excitation.reduce_expand[0].bias.shape)\n",
        "    if layer.squeeze_excitation.reduce_expand[2].bias is not None:\n",
        "      print(name, \"\\n\", \"Bias matrix shape = \", layer.squeeze_excitation.reduce_expand[2].bias.shape)\n",
        "    if layer.project_conv[0].bias is not None:\n",
        "      print(name, \"\\n\", \"Bias matrix shape = \", layer.project_conv[0].bias.shape)\n",
        "\n",
        "# Weight tensor function\n",
        "def permutate_weight_tensor(mat, name, par):\n",
        "  if par == \"DW\":\n",
        "    mat_weight = mat.weight.T.permute(3, 2, 1, 0)\n",
        "    print(name, \"\\n\", \"has dimension of \", mat_weight.size())\n",
        "    mat_weight_reshaped = mat_weight\n",
        "\n",
        "  else:\n",
        "    mat_weight = mat.weight.T.permute(1, 0, 3, 2)\n",
        "    print(name, \"\\n\", \"has dimension of \", mat_weight.size())\n",
        "    mat_weight_reshaped = torch.reshape(mat_weight, (1, 1, 1,mat_weight.numel()))\n",
        "  print(mat_weight_reshaped)\n",
        "\n",
        "# Bias tensor function \n",
        "def permutate_bias_tensor(mat, name):\n",
        "  if mat.bias is not None:\n",
        "    mat_bias = mat.bias.T\n",
        "    print(name, \"\\n\", \"has dimension of \", mat_bias.size())\n",
        "    mat_bias_reshaped = torch.reshape(mat_bias, (1, 1, 1,mat_bias.numel()))\n",
        "    print(mat_bias_reshaped)\n",
        "\n",
        "\n",
        "# Input Matrix to the current MBConv layer\n",
        "print(\"Input Matrices to \" + sublayer_name)\n",
        "if sublayer_name == \"MBConv1_0\":\n",
        "  print(\"No expansion input\")\n",
        "else:\n",
        "  reshape_input(inputs['expansion_conv' + sublayer_name],       \"Input for Expansion Convolution layer\")\n",
        "reshape_input(inputs['depthwise_conv' + sublayer_name],       \"Input for Depthwise layer\")\n",
        "reshape_input(inputs['squeeze_excitation1' + sublayer_name],  \"Input for Squeeze Excitation1 layer\")\n",
        "reshape_input(inputs['squeeze_excitation2' + sublayer_name],  \"Input for Squeeze Excitation2 layer\")\n",
        "reshape_input(inputs['project_conv' + sublayer_name],         \"Input for Project Conv layer\")\n",
        "\n",
        "# Weight Dimensions of the current MBConv layer\n",
        "print('weight dimensions for conv2d operations')\n",
        "print_weight_shapes(layer_attr, sublayer_name)\n",
        "\n",
        "# Bias Dimensions of the current MBConv layer\n",
        "print('Bias dimensions for conv2d operations')\n",
        "print_bias_shapes(layer_attr, sublayer_name)\n",
        "\n",
        "# Get weight and bias matrices of the current MBConv layer\n",
        "print(\"Weight tensors\")\n",
        "if sublayer_name == \"MBConv1_0\":\n",
        "  print(\"No expansion weight\")\n",
        "else:\n",
        "  permutate_weight_tensor(layer_attr.expansion_conv[0], \"weight for Expansion Convolution layer\", \"reg\")\n",
        "permutate_weight_tensor(layer_attr.depthwise_conv[0], \"weight for Depthwise layer\", \"DW\")\n",
        "permutate_weight_tensor(layer_attr.squeeze_excitation.reduce_expand[0], \"weight for Squeeze Excitation1 layer\", \"reg\")\n",
        "permutate_weight_tensor(layer_attr.squeeze_excitation.reduce_expand[2], \"weight for Squeeze Excitation2 layer\", \"reg\")\n",
        "permutate_weight_tensor(layer_attr.project_conv[0], \"Weight for Project Conv layer\", \"reg\")\n",
        "\n",
        "# Bias matrix pre-processing for current MBConv layer\n",
        "print(\"Biasing tensors\")\n",
        "if sublayer_name == \"MBConv1_0\":\n",
        "  print(\"No expansion bias\")\n",
        "else:\n",
        "  permutate_bias_tensor(layer_attr.expansion_conv[0], \"Bias for Expansion Convolution layer\")\n",
        "permutate_bias_tensor(layer_attr.depthwise_conv[0], \"Bias for Depthwise layer\")\n",
        "permutate_bias_tensor(layer_attr.squeeze_excitation.reduce_expand[0], \"Bias for Squeeze Excitation1 layer\")\n",
        "permutate_bias_tensor(layer_attr.squeeze_excitation.reduce_expand[2], \"Bias for Squeeze Excitation2 layer\")\n",
        "permutate_bias_tensor(layer_attr.project_conv[0], \"Bias for Project Conv layer\")\n",
        "\n",
        "# Output Matrix of current MBConv layer\n",
        "print(\"Output Matrices to a whole MBConv layer\", )\n",
        "if sublayer_name == \"MBConv1_0\":\n",
        "  print(\"No expansion output\")\n",
        "else:\n",
        "  reshape_input(activation['expansion_conv' + sublayer_name],       \"Output for Expansion Convolution layer\")\n",
        "reshape_input(activation['depthwise_conv' + sublayer_name],       \"Output for Depthwise layer\")\n",
        "reshape_input(activation['squeeze_excitation1' + sublayer_name],  \"Output for Squeeze Excitation1 layer\")\n",
        "reshape_input(activation['squeeze_excitation2' + sublayer_name],  \"Output for Squeeze Excitation2 layer\")\n",
        "reshape_input(activation['project_conv' + sublayer_name],         \"Output for Project Conv layer\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKlvCzejB1gi"
      },
      "source": [
        "with open(sublayer_name + '_All_convolution_layers_in_this_layer'+'.txt', 'w') as out:\n",
        "    out.write(cap.stdout)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBs1w1eAB3z5"
      },
      "source": [
        "## This cell for BN parameters only fot a sublayer_name\n",
        "\n",
        "%%capture cap --no-stderr\n",
        "torch.set_printoptions(precision=8, sci_mode=False)\n",
        "\n",
        "\n",
        "# Print weight, bias, running mean, running variance\n",
        "def WBRMRV(layer, name):\n",
        "  print(name, \"\\n\",\"Weight shape = \", layer.weight.shape)\n",
        "  print(\"BatchNorm weight, bias, running mean and variance parameters: \", \"\\n\" , layer.__dict__)\n",
        "\n",
        "# Input Matrix to the current BN of convolutions in MBConv layer\n",
        "print(\"Input Matrices to BN of \" + sublayer_name)\n",
        "if sublayer_name == \"MBConv1_0\":\n",
        "  print(\"Input for BN of Expansion Convolution layer\")\n",
        "else:\n",
        "  reshape_input(inputs['expansion_conv_BN' + sublayer_name],       \"Input for BN of Expansion Convolution layer\")\n",
        "reshape_input(inputs['depthwise_conv_BN' + sublayer_name],       \"Input for BN of Depthwise layer\")\n",
        "reshape_input(inputs['project_conv_BN' + sublayer_name],         \"Input for BN of Project Conv layer\")\n",
        "\n",
        "# weights, bias, running mean and running variance\n",
        "print(\"BatchNorm: weight, bias, running mean and running variance\")\n",
        "if sublayer_name == \"MBConv1_0\":\n",
        "  print(\"Parameters for BN in Expansion Convolution layer\")\n",
        "else:\n",
        "  WBRMRV(layer_attr.expansion_conv[1], \"Parameters for BN in Expansion Convolution layer\")\n",
        "WBRMRV(layer_attr.depthwise_conv[1], \"Parameters for BN in Depthwise layer\")\n",
        "WBRMRV(layer_attr.project_conv[1], \"Parameters for BN in Project Conv layer\")\n",
        "\n",
        "# Output Matrix of current MBConv layer\n",
        "print(\"Output Matrices of a BN layer of MBConv layer\")\n",
        "if sublayer_name == \"MBConv1_0\":\n",
        "  print(\"No Output for BN of Expansion Convolution layer\")\n",
        "else:\n",
        "  reshape_input(activation['expansion_conv_BN' + sublayer_name],       \"Output for BN of Expansion Convolution layer\")\n",
        "reshape_input(activation['depthwise_conv_BN' + sublayer_name],       \"Output for BN of Depthwise layer\")\n",
        "reshape_input(activation['project_conv_BN' + sublayer_name],         \"Output for BN of Project Conv layer\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOeg1YZTB63M"
      },
      "source": [
        "with open(sublayer_name + '_All_BatchNorm_in_this_layer'+'.txt', 'w') as out:\n",
        "    out.write(cap.stdout)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu09Smv2B86A"
      },
      "source": [
        "## This cell for Swish activations only fot a sublayer_name\n",
        "\n",
        "%%capture cap --no-stderr\n",
        "torch.set_printoptions(precision=8, sci_mode=False)\n",
        "\n",
        "\n",
        "print(\"Swish activation details \")\n",
        "\n",
        "# Output Matrix of current MBConv layer\n",
        "print(\"Input Matrices of an activation layer of MBConv layer\")\n",
        "if sublayer_name == \"MBConv1_0\":\n",
        "  print(\"No Activation function input of Expansion Convolution layer\")\n",
        "else:\n",
        "  reshape_input(inputs['expansion_conv_swish' + sublayer_name],       \"Activation function input of Expansion Convolution layer\")\n",
        "reshape_input(inputs['depthwise_conv_swish' + sublayer_name],       \"Activation function input of Depthwise layer\")\n",
        "reshape_input(inputs['squeeze_excitation1_swish' + sublayer_name],         \"Activation function input for squeeze_excitation1_swish\")\n",
        "reshape_input(inputs['squeeze_excitation2_sigmoid' + sublayer_name],         \"Activation function input for squeeze_excitation2_sigmoid\")\n",
        "\n",
        "# Output Matrix of current MBConv layer\n",
        "print(\"Output Matrices of an activation layer of MBConv layer\")\n",
        "if sublayer_name == \"MBConv1_0\":\n",
        "  print(\"No Activation function output of Expansion Convolution layer\")\n",
        "else:\n",
        "  reshape_input(activation['expansion_conv_swish' + sublayer_name],       \"Activation function output of Expansion Convolution layer\")\n",
        "reshape_input(activation['depthwise_conv_swish' + sublayer_name],       \"Activation function output of Depthwise layer\")\n",
        "reshape_input(activation['squeeze_excitation1_swish' + sublayer_name],         \"Activation function output for squeeze_excitation1_swish\")\n",
        "reshape_input(activation['squeeze_excitation2_sigmoid' + sublayer_name],         \"Activation function output for squeeze_excitation2_sigmoid\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTzzp_flB-m0"
      },
      "source": [
        "with open(sublayer_name + '_All_Activations_in_this_layer'+'.txt', 'w') as out:\n",
        "    out.write(cap.stdout)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kQrLIVbCBGf"
      },
      "source": [
        "# This section is for stem layer\n",
        "%%capture cap --no-stderr\n",
        "torch.set_printoptions(precision=8, sci_mode=False)\n",
        "\n",
        "####### model.blocks.stem[0].register_forward_hook(get_activation('stem'))\n",
        "####### model.blocks.stem[1].register_forward_hook(get_activation('stem_BN'))\n",
        "####### model.blocks.stem[2].register_forward_hook(get_activation('stem_swish'))\n",
        "\n",
        "# Conv2d parameters: input, weight, output\n",
        "reshape_input(inputs['stem'], \"Input for stem_conv\")\n",
        "print(\"\\n\\nStem\", \"\\n\", \"Weight matrix shape = \", model.stem[0].weight.shape)\n",
        "\n",
        "mat_weight = model.stem[0].weight.T.permute(1, 0, 3, 2)\n",
        "print(\"\\n\\nweight for stem layer has dimension of \", mat_weight.size(), \"\\n\\n\")\n",
        "mat_weight_reshaped = torch.reshape(mat_weight, (1, 1, 1,mat_weight.numel()))\n",
        "print(mat_weight_reshaped)\n",
        "\n",
        "reshape_input(activation['stem'],       \"Output for stem_conv layer\")\n",
        "\n",
        "# BN parameters: input, weight, bias, mean, variance, output\n",
        "reshape_input(inputs['stem_BN'],       \"Input for BN of stem layer\")\n",
        "\n",
        "WBRMRV(model.stem[1], \"Parameters for BN in stem layer\")\n",
        "\n",
        "reshape_input(activation['stem_BN'],       \"Output for BN of stem layer\")\n",
        "\n",
        "# Swish activation: Input, output\n",
        "reshape_input(inputs['stem_swish'],         \"Activation function input for stem_swish\")\n",
        "\n",
        "reshape_input(activation['stem_swish'],         \"Activation function output for stem_swish\")\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2jVqo3dCM4v"
      },
      "source": [
        "with open(\"Stem\" + '_All_details'+'.txt', 'w') as out:\n",
        "    out.write(cap.stdout)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUNkjDblCNwI"
      },
      "source": [
        "# This section is for head layer\n",
        "%%capture cap --no-stderr\n",
        "torch.set_printoptions(precision=8, sci_mode=False)\n",
        "\n",
        "####### model.head[0].register_forward_hook(get_activation('head'))\n",
        "####### model.head[1].register_forward_hook(get_activation('head'))\n",
        "####### model.head[2].register_forward_hook(get_activation('head'))\n",
        "\n",
        "# Conv2d parameters: input, weight, output\n",
        "reshape_input(inputs['head'], \"Input for head_conv\")\n",
        "print(\"\\n\\nhead\", \"\\n\", \"Weight matrix shape = \", model.head[0].weight.shape)\n",
        "\n",
        "mat_weight = model.head[0].weight.T.permute(1, 0, 3, 2)\n",
        "print(\"\\n\\nweight for head layer has dimension of \", mat_weight.size(), \"\\n\\n\")\n",
        "mat_weight_reshaped = torch.reshape(mat_weight, (1, 1, 1,mat_weight.numel()))\n",
        "print(mat_weight_reshaped)\n",
        "\n",
        "reshape_input(activation['head'],       \"Output for head_conv layer\")\n",
        "\n",
        "# BN parameters: input, weight, bias, mean, variance, output\n",
        "reshape_input(inputs['head_BN'],       \"Input for BN of head layer\")\n",
        "\n",
        "WBRMRV(model.head[1], \"Parameters for BN in head layer\")\n",
        "\n",
        "reshape_input(activation['head_BN'],       \"Output for BN of head layer\")\n",
        "\n",
        "# Swish activation: Input, output\n",
        "reshape_input(inputs['head_swish'],         \"Activation function input for head_swish\")\n",
        "\n",
        "reshape_input(activation['head_swish'],         \"Activation function output for head_swish\")\n",
        "\n",
        "# Adaptive pooling\n",
        "reshape_input(inputs['head_pooling'],         \"Pooling input for head_swish\")\n",
        "\n",
        "reshape_input(activation['head_pooling'],         \"Pooling output for head_swish\")\n",
        "\n",
        "# Flatten\n",
        "reshape_input(inputs['head_flatten'],         \"Flatting input for head_swish\")\n",
        "\n",
        "reshape_input(activation['head_flatten'],         \"Flatting output for head_swish\")\n",
        "\n",
        "# Dropout\n",
        "reshape_input(inputs['head_dropOut'],         \"Dropout input for head_swish\")\n",
        "\n",
        "reshape_input(activation['head_dropOut'],         \"Dropout output for head_swish\")\n",
        "\n",
        "# Linear\n",
        "reshape_input(inputs['head_linear'],         \"Linear FC input for head_swish\")\n",
        "\n",
        "mat_weight = model.head[6].weight.T\n",
        "print(\"\\n\\nweight for linear in head layer has dimension of \", mat_weight.size(), \"\\n\\n\")\n",
        "mat_weight_reshaped = torch.reshape(mat_weight, (1, 1, 1,mat_weight.numel()))\n",
        "print(mat_weight_reshaped)\n",
        "\n",
        "mat_bias = model.head[6].bias.T\n",
        "print(\"\\n\\bias for linear head layer has dimension of \", mat_bias.size(), \"\\n\\n\")\n",
        "mat_bias_reshaped = torch.reshape(mat_bias, (1, 1, 1,mat_bias.numel()))\n",
        "print(mat_bias_reshaped)\n",
        "\n",
        "reshape_input(activation['head_linear'],         \"Linear FC output for head_swish\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHmSnmf_CQ23"
      },
      "source": [
        "with open(\"head\" + '_All_details'+'.txt', 'w') as out:\n",
        "    out.write(cap.stdout)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N6-NcUMCTHZ"
      },
      "source": [
        "# Download the notebook\n",
        "!pwd\n",
        "!jupyter nbconvert --execute --to html '/content/drive/MyDrive/Colab Notebooks/Model_Trained_Extracted.ipynb'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}