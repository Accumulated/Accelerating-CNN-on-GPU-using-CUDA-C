{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Reference42_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfp2HUnz6CR1"
      },
      "source": [
        "# !apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "# !dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "# !apt-get remove cuda-*\n",
        "# !apt autoremove\n",
        "# !apt-get update"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_ALHmgw7F6L"
      },
      "source": [
        "# !wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "# !dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "# !apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "# !apt-get update\n",
        "# !apt-get install cuda-9.2"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehCqOlQ8dmG"
      },
      "source": [
        "# !nvcc --version "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bog6uNQT8f9Q"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xua-cpZQ8lt1"
      },
      "source": [
        "%load_ext nvcc_plugin\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdDEDNbDdy65"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/ /content/MBCONVS_float"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "K8xAh2jVyUSx",
        "outputId": "a26706e3-89e2-4ea2-f425-8a55e0e53d42"
      },
      "source": [
        "%%cuda --name KERNELS.cu \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <cusolverDn.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#include \"/content/MBCONVS_float/functionsV2.h\"\n",
        "#include \"/content/MBCONVS_float/KERNELSH.h\"\n",
        "\n",
        "/* Kernel definitions */\n",
        "__global__ void INPUT_UNROLLING(int stride, int Filter_Height,\n",
        "                                float *Input, int H1, int W1, int D1,\n",
        "                                float *X_unrolled, int H2, int W2, int D2,\n",
        "                                int Output_Height, int Output_Width)\n",
        "{  \n",
        "    int bx = blockIdx.x, by = blockIdx.y, bz = blockIdx.z;\n",
        "    int tx = threadIdx.x, ty = threadIdx.y;\n",
        " \n",
        "    // Select row and column values \n",
        "    int row =  by * blockDim.y + ty;\n",
        "    int col = bx * blockDim.x + tx;\n",
        "    int depth = bz;\n",
        " \n",
        "    int col_no_strided = col, row_no_strided = row;\n",
        "    int depth_offset = depth * W2 * Filter_Height * Filter_Height;\n",
        "\n",
        "    /* \n",
        "      Note for bx, by and bz= 0, stride = 2: \n",
        "          @ tx = 0, ty = 0 -> First multiply the col * stride, row * stride; = 0, 0\n",
        "                            you are shifting in x direction using local col\n",
        "                            you are shifting in y direction using local row;\n",
        "          @ tx = 1, ty = 0 -> First multiply the col * stride, row * stride; = 2, 0 \n",
        "                            you are shifting in x direction using local col\n",
        "                            you are shifting in y direction using local row;   \n",
        "          @ tx = 0, ty = 1 -> First multiply the col * stride, row * stride; = 0, 2 \n",
        "                            you are shifting in x direction using local col\n",
        "                            you are shifting in y direction using local row;                   \n",
        "    */ \n",
        "  \n",
        "    col *= stride; row *= stride;\n",
        " \n",
        "    // Limit number of threads \n",
        "    if (row_no_strided < Output_Height && col_no_strided < Output_Width && depth < D1)\n",
        "    {   \n",
        "      // Each thread unrolls k x k elements\n",
        "      for (int local_row = 0; local_row < Filter_Height; local_row++)\n",
        "      {\n",
        "        for (int local_col = 0; local_col < Filter_Height; local_col++)\n",
        "        {                                  \n",
        "          // 1. local row and column shifts affect the locations in Unrolled matrix\n",
        "          // 2. For each col and row non strided values -> you are adding an offset to columns and rows in Unrolled matrix\n",
        "          // 3. Offset the depth using \"depth_offset\" variable\n",
        "          X_unrolled[local_col * W2 + local_row * Filter_Height * W2 + col_no_strided + row_no_strided * Output_Width + depth_offset] = \n",
        "          Input[(row + local_row) * W1 + (col + local_col) + depth * H1 * W1];\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void DWConv2d_kernel(float *Input, int H1, int W1, int D1,\n",
        "                                float *Filter, int H2, int W2, int D2,\n",
        "                                float *Output, int H3, int W3, int D3,\n",
        "                                int stride)\n",
        "{\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int bz = blockIdx.z;\n",
        "\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int row = by * blockDim.y + ty;\n",
        "    int col = bx * blockDim.x + tx;\n",
        "    int dep = bz;\n",
        "\n",
        "    float Pvalue = 0;\n",
        "\n",
        "    if (row < H3 && col < W3 && dep < D3)\n",
        "    {\n",
        "      // 1 thread unrolls kxk section\n",
        "      for (int j = 0; j < H2; j++)\n",
        "      {\n",
        "        for (int i = 0; i < W2; i++)\n",
        "        {\n",
        "            Pvalue += Filter[j * W2 + i + dep * H2 * W2] *\n",
        "                Input[(j * W1 + row * stride * W1) + (i + col * stride) + dep * H1 * W1];\n",
        "        }\n",
        "      }\n",
        "      Output[row * W3 + col + dep * H3 * W3] = Pvalue;\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void MatrixMulKernel(float *M, int H1, int W1, int D1,\n",
        "                                float *N, int H2, int W2, int D2,\n",
        "                                float *P, int H3, int W3, int D3,\n",
        "                                int num_blocks, int activation, \n",
        "                                int IS_BIASED, float *bias_mat)\n",
        "{\n",
        "  __shared__ float Mds[Tile_GEMM][Tile_GEMM];\n",
        "  __shared__ float Nds[Tile_GEMM][THREAD_GRANULARITY_BLOCKS * Tile_GEMM];\n",
        "\n",
        "  int bx = blockIdx.x * THREAD_GRANULARITY_BLOCKS;\n",
        "  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x;\n",
        "  int ty = threadIdx.y;\n",
        "\n",
        "  // Identify the row and column of the d_P element to work on\n",
        "  int Row = by * Tile_GEMM + ty;\n",
        "  int Col = bx * Tile_GEMM + tx;\n",
        "  float Pvalue = 0;\n",
        "  float Pvalue_2 = 0;\n",
        "\n",
        "  // Loop over the d_M and d_N tiles required to compute d_P element\n",
        "  for (int ph = 0; ph < num_blocks; ++ph)\n",
        "  {\n",
        "    // Collaborative loading of d_M and d_N tiles into shared memory\n",
        "    if ((Row < H1) && (ph * Tile_GEMM + tx) < W1)\n",
        "    {\n",
        "      Mds[ty][tx] = M[Row * W1 + ph * Tile_GEMM + tx];\n",
        "    }\n",
        "\n",
        "    if ((ph * Tile_GEMM + ty) < H2 && Col < W2)\n",
        "    {\n",
        "      Nds[ty][tx] = N[(ph * Tile_GEMM + ty) * W2 + Col];\n",
        "    }\n",
        "\n",
        "    if ((ph * Tile_GEMM + ty) < H2 && Col + Tile_GEMM < W2)\n",
        "    {\n",
        "      Nds[ty][tx + Tile_GEMM] = N[(ph * Tile_GEMM + ty) * W2 + Col + Tile_GEMM];\n",
        "    }     \n",
        "   \n",
        "    __syncthreads();\n",
        "\n",
        "    for (int k = 0; k < Tile_GEMM && (ph * Tile_GEMM) + k < W1; ++k)\n",
        "    {\n",
        "      Pvalue += Mds[ty][k] * Nds[k][tx];\n",
        "      if (Col + Tile_GEMM < W2)\n",
        "        Pvalue_2 += Mds[ty][k] * Nds[k][tx + Tile_GEMM];\n",
        "    }\n",
        "  \n",
        "    __syncthreads();\n",
        "\n",
        "  }\n",
        "\n",
        "  if ((Row < H1) && (Col < W2))\n",
        "  {\n",
        "    P[Row * W3 + Col] = Pvalue;\n",
        "    \n",
        "    switch (IS_BIASED) \n",
        "    {\n",
        "      case BIASED:\n",
        "        Pvalue = Pvalue + bias_mat[Row];\n",
        "        break;\n",
        "      \n",
        "      default:\n",
        "        break;\n",
        "    } \n",
        "            \n",
        "    switch (activation) \n",
        "    {\n",
        "      case SWISH_ACTIVATION:\n",
        "        // Swish activation function\n",
        "        P[Row * W3 + Col] = Pvalue / (1.0f + expf(-1.0f * Pvalue));\n",
        "        break;\n",
        "\n",
        "      case SIGMOID_ACTIVATION:\n",
        "        // Sigmoid activation function\n",
        "        P[Row * W3 + Col] = 1.0f / (1.0f + expf(-1.0f * Pvalue));\n",
        "        break;\n",
        "\n",
        "      default:\n",
        "        break;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if ((Row < H1) && (Col + Tile_GEMM < W2))\n",
        "    {\n",
        "      P[Row * W3 + Col + Tile_GEMM] = Pvalue_2;\n",
        "      \n",
        "      switch (IS_BIASED) \n",
        "      {\n",
        "        case BIASED:\n",
        "          Pvalue_2 = Pvalue_2 + bias_mat[Row];\n",
        "          break;\n",
        "        \n",
        "        default:\n",
        "          break;\n",
        "      } \n",
        "              \n",
        "      switch (activation) \n",
        "      {\n",
        "        case SWISH_ACTIVATION:\n",
        "          // Swish activation function\n",
        "          P[Row * W3 + Col + Tile_GEMM] = Pvalue_2 / (1.0f + expf(-1.0f * Pvalue_2));\n",
        "          break;\n",
        "\n",
        "        case SIGMOID_ACTIVATION:\n",
        "          // Sigmoid activation function\n",
        "          P[Row * W3 + Col + Tile_GEMM] = 1.0f / (1.0f + expf(-1.0f * Pvalue_2));\n",
        "          break;\n",
        "\n",
        "        default:\n",
        "          break;\n",
        "      }\n",
        "    }    \n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "__global__ void ConvChannelElementWiseMultiplication(float *A, int H1, int W1, int D1,\n",
        "                                                     float *B)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "\n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = A[index] * B[depth];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void CastingDivision(float *A, int W1, float B)\n",
        "{\n",
        "    // Warning: 1-D kernel only in x dir.\n",
        " \n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        " \n",
        "    if ((col < W1))\n",
        "    {\n",
        "        A[col] /= B;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Used with MBConv layers that has skip identity = true\n",
        "__global__ void Identity_Skip(float *A,  int H1, int W1, int D1,\n",
        "                              float *B)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "\n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = A[index] + B[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void Complete_Padding_Process(float *Original_Padded, int H1, int W1, int D1, \n",
        "                                         float *Original,        int H2, int W2, int D2,\n",
        "                                         int padding_value)\n",
        "{   \n",
        "    // There must be a constant shift between indeces in 2 matrices\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int depth = blockIdx.z * blockDim.z + threadIdx.z;\n",
        "\n",
        "    int index = depth * W2 * H2 + row * W2 + col;\n",
        "    int Padding_Index = depth * W1 * H1 + (row + padding_value) * W1 + (col + padding_value);\n",
        "\n",
        "    if ((row < (H2)) && (col < (W2)) && (depth < (D2)))\n",
        "    {\n",
        "        Original_Padded[Padding_Index] = Original[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Batch Normalization Kernels */\n",
        "const int BLOCK_SIZE = 128;\n",
        "\n",
        "__global__ void BN_Kernel_Mean_Reduction(float *input, int H1, int W1, int D1,\n",
        "                                         float *Mean, int W2)\n",
        "{\n",
        "    /*\n",
        "        This code works on 2 * Block_Size elements.\n",
        "        i.e. for 512 Block_Size -> we are reducing 1024 elements.\n",
        "        Each thread loads 2 elements, one at tx and the\n",
        "        other shifted by blockIdx.x.\n",
        "    */\n",
        "\n",
        "    __shared__ float partialSum[2 * BLOCK_SIZE];\n",
        "    float tmp = 0;\n",
        "\n",
        "    int tx = threadIdx.x;\n",
        "    int bx = blockDim.x;\n",
        "\n",
        "    int by_index = blockIdx.y;\n",
        "    int bx_index = blockIdx.x;\n",
        "\n",
        "    // The start variable is to get offset for input matrix in loading\n",
        "    int start = blockIdx.x * (2 * blockDim.x);\n",
        "    int start_yDir = blockIdx.y * W1;\n",
        "\n",
        "    if (start + tx < W1 && start_yDir < H1 * W1)\n",
        "        // Load 2 elements in the shared memory\n",
        "        partialSum[tx] = input[start + tx + start_yDir];\n",
        "    else\n",
        "        partialSum[tx] = tmp;\n",
        "\n",
        "    if (tx + bx + start < W1 && start_yDir < H1 * W1)\n",
        "        partialSum[bx + tx] = input[start + bx + tx + start_yDir];\n",
        "    else\n",
        "        partialSum[bx + tx] = tmp;\n",
        "\n",
        "\n",
        "    unsigned int stride = 0;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    for (stride = blockDim.x; stride > 0; stride = stride / 2.0f)\n",
        "    {\n",
        "        __syncthreads();\n",
        "        if (tx < stride)\n",
        "            partialSum[tx] += partialSum[tx + stride];\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "\n",
        "    if (tx == 0)\n",
        "        Mean[bx_index + by_index * W2] = partialSum[tx];\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void ElementWiseSquaring(float *A, int H1, int W1, int D1)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "\n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = A[index] * A[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void ElementWiseSubtraction(float *A, int H1, int W1, int D1,\n",
        "                                       float *mean)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x  + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "\n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = A[index] - mean[depth];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void BN_Kernel_Final_Layer(float *A, int H1, int W1, int D1, \n",
        "                                      float *D_mean, float *D_variance,\n",
        "                                      float *D_weight, float *D_bias,\n",
        "                                      int activate)\n",
        "{\n",
        "    // Activate values are assigned as follow\n",
        "    /*\n",
        "      0 -> no activation, 1 -> swish, 2 -> sigmoid\n",
        "    */\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "    int index3 = depth;\n",
        "\n",
        "    float tmp = 0;\n",
        " \n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = ((A[index] - D_mean[index3]) / (sqrtf(D_variance[index3] + 0.001f))) * D_weight[index3] + D_bias[index3];\n",
        "        tmp = A[index];\n",
        "\n",
        "        switch (activate) {\n",
        "                  case 1:\n",
        "                      // Swish activation function\n",
        "                      A[index] = tmp / (1.0f + expf(-1.0f * tmp));\n",
        "                      break;\n",
        "                  case 2:\n",
        "                      // Sigmoid activation function\n",
        "                      A[index] = 1.0f / (1.0f + expf(-1.0f * tmp));\n",
        "                      break;\n",
        "                  default:\n",
        "                      break;\n",
        "                    }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/KERNELS.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0b4nSRha8tBJ",
        "outputId": "14d49745-9fad-4bd2-9386-426ffb7ee37e"
      },
      "source": [
        "%%cuda --name APP.cu \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <cusolverDn.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "#include \"/content/MBCONVS_float/Input_For_Stem_Layer.h\"\n",
        "#include \"/content/MBCONVS_float/Stem/Stem_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/functionsV2.h\"\n",
        "#include \"/content/MBCONVS_float/CONFIG.h\"\n",
        "#include \"/content/MBCONVS_float/Input_Matrix.h\"\n",
        "#include \"/content/MBCONVS_float/KERNELSH.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MBConv1_0/MBConv1_0_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MBConv1_0/MBConv1_0_project_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MBConv1_0/MBConv1_0_squeeze_excitation_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_1/MBConv6_1_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_1/MBConv6_1_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_1/MBConv6_1_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_1/MBConv6_1_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_2/MBConv6_2_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_2/MBConv6_2_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_2/MBConv6_2_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_2/MBConv6_2_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_3/MBConv6_3_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_3/MBConv6_3_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_3/MBConv6_3_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_3/MBConv6_3_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_4/MBConv6_4_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_4/MBConv6_4_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_4/MBConv6_4_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_4/MBConv6_4_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_5/MBConv6_5_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_5/MBConv6_5_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_5/MBConv6_5_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_5/MBConv6_5_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_6/MBConv6_6_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_6/MBConv6_6_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_6/MBConv6_6_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_6/MBConv6_6_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_7/MBConv6_7_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_7/MBConv6_7_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_7/MBConv6_7_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_7/MBConv6_7_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_8/MBConv6_8_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_8/MBConv6_8_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_8/MBConv6_8_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_8/MBConv6_8_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_9/MBConv6_9_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_9/MBConv6_9_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_9/MBConv6_9_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_9/MBConv6_9_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_10/MBConv6_10_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_10/MBConv6_10_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_10/MBConv6_10_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_10/MBConv6_10_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_11/MBConv6_11_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_11/MBConv6_11_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_11/MBConv6_11_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_11/MBConv6_11_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_12/MBConv6_12_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_12/MBConv6_12_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_12/MBConv6_12_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_12/MBConv6_12_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_13/MBConv6_13_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_13/MBConv6_13_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_13/MBConv6_13_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_13/MBConv6_13_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_14/MBConv6_14_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_14/MBConv6_14_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_14/MBConv6_14_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_14/MBConv6_14_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/MbConv6_15/MBConv6_15_expansion_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_15/MBConv6_15_depthwise_conv_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_15/MBConv6_15_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/MBCONVS_float/MbConv6_15/MBConv6_15_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/MBCONVS_float/Head/Head_conv_parameters.h\"\n",
        "\n",
        "\n",
        "int MBCONV1_0_flag = 0;\n",
        "\n",
        "int main()\n",
        "{\n",
        "  // 1. Define dimensions for input image.\n",
        "  set_allocate_copy_array_Device(&DInput_Mat, Input_for_stem_conv,\n",
        "                                 INPUT_IMAGE_HEIGHT, INPUT_IMAGE_WIDTH, \n",
        "                                 INPUT_IMAGE_DEPTH,\n",
        "                                 \"Input Image is allocated in device memory\");  \n",
        "\n",
        "  // 2. Get layers' filters ready\n",
        "  set_allocate_copy_array_Device(&F_STEM, Stem_conv2d_weights,\n",
        "                                 STEM_FILTER_HEIGHT, STEM_FILTER_WIDTH, \n",
        "                                 STEM_FILTER_DEPTH * STEM_FILTER_DENSITY,\n",
        "                                 \"Stem Filter  is allocated in device memory\");\n",
        "  \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_1_0_EXPD_WEIGHTS, NULL, \n",
        "                            MBCONV_1_0_EXPD_F_HEIGHT,   MBCONV_1_0_EXPD_F_WIDTH, \n",
        "                            MBCONV_1_0_EXPD_F_DEPTH * MBCONV_1_0_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_1_0_DW_WEIGHTS, MBConv1_0_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_1_0_DW_F_HEIGHT, MBCONV_1_0_DW_F_WIDTH, \n",
        "                            MBCONV_1_0_DW_F_DEPTH * MBCONV_1_0_DW_F_DENSITY,\n",
        "                            &D_MBConv_1_0_SQZ_1_WEIGHTS, MBConv1_0_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_1_0_SQZ_1_F_HEIGHT, MBCONV_1_0_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_1_0_SQZ_1_F_DEPTH * MBCONV_1_0_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_1_0_SQZ_2_WEIGHTS, MBConv1_0_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_1_0_SQZ_2_F_HEIGHT, MBCONV_1_0_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_1_0_SQZ_2_F_DEPTH * MBCONV_1_0_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_1_0_PRJ_WEIGHTS, MBConv1_0_project_conv_conv2d_weights, \n",
        "                            MBCONV_1_0_PRJ_F_HEIGHT, MBCONV_1_0_PRJ_F_WIDTH, \n",
        "                            MBCONV_1_0_PRJ_F_DEPTH * MBCONV_1_0_PRJ_F_DENSITY); \n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_1_EXPD_WEIGHTS, MBConv6_1_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_1_EXPD_F_HEIGHT,   MBCONV_6_1_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_1_EXPD_F_DEPTH * MBCONV_6_1_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_1_DW_WEIGHTS, MBConv6_1_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_1_DW_F_HEIGHT, MBCONV_6_1_DW_F_WIDTH, \n",
        "                            MBCONV_6_1_DW_F_DEPTH * MBCONV_6_1_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_1_SQZ_1_WEIGHTS, MBConv6_1_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_1_SQZ_1_F_HEIGHT, MBCONV_6_1_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_1_SQZ_1_F_DEPTH * MBCONV_6_1_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_1_SQZ_2_WEIGHTS, MBConv6_1_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_1_SQZ_2_F_HEIGHT, MBCONV_6_1_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_1_SQZ_2_F_DEPTH * MBCONV_6_1_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_1_PRJ_WEIGHTS, MBConv6_1_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_1_PRJ_F_HEIGHT, MBCONV_6_1_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_1_PRJ_F_DEPTH * MBCONV_6_1_PRJ_F_DENSITY); \n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_2_EXPD_WEIGHTS, MBConv6_2_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_2_EXPD_F_HEIGHT,   MBCONV_6_2_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_2_EXPD_F_DEPTH * MBCONV_6_2_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_2_DW_WEIGHTS, MBConv6_2_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_2_DW_F_HEIGHT, MBCONV_6_2_DW_F_WIDTH, \n",
        "                            MBCONV_6_2_DW_F_DEPTH * MBCONV_6_2_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_2_SQZ_1_WEIGHTS, MBConv6_2_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_2_SQZ_1_F_HEIGHT, MBCONV_6_2_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_2_SQZ_1_F_DEPTH * MBCONV_6_2_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_2_SQZ_2_WEIGHTS, MBConv6_2_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_2_SQZ_2_F_HEIGHT, MBCONV_6_2_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_2_SQZ_2_F_DEPTH * MBCONV_6_2_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_2_PRJ_WEIGHTS, MBConv6_2_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_2_PRJ_F_HEIGHT, MBCONV_6_2_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_2_PRJ_F_DEPTH * MBCONV_6_2_PRJ_F_DENSITY);\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_3_EXPD_WEIGHTS, MBConv6_3_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_3_EXPD_F_HEIGHT,   MBCONV_6_3_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_3_EXPD_F_DEPTH * MBCONV_6_3_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_3_DW_WEIGHTS, MBConv6_3_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_3_DW_F_HEIGHT, MBCONV_6_3_DW_F_WIDTH, \n",
        "                            MBCONV_6_3_DW_F_DEPTH * MBCONV_6_3_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_3_SQZ_1_WEIGHTS, MBConv6_3_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_3_SQZ_1_F_HEIGHT, MBCONV_6_3_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_3_SQZ_1_F_DEPTH * MBCONV_6_3_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_3_SQZ_2_WEIGHTS, MBConv6_3_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_3_SQZ_2_F_HEIGHT, MBCONV_6_3_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_3_SQZ_2_F_DEPTH * MBCONV_6_3_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_3_PRJ_WEIGHTS, MBConv6_3_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_3_PRJ_F_HEIGHT, MBCONV_6_3_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_3_PRJ_F_DEPTH * MBCONV_6_3_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_4_EXPD_WEIGHTS, MBConv6_4_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_4_EXPD_F_HEIGHT,   MBCONV_6_4_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_4_EXPD_F_DEPTH * MBCONV_6_4_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_4_DW_WEIGHTS, MBConv6_4_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_4_DW_F_HEIGHT, MBCONV_6_4_DW_F_WIDTH, \n",
        "                            MBCONV_6_4_DW_F_DEPTH * MBCONV_6_4_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_4_SQZ_1_WEIGHTS, MBConv6_4_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_4_SQZ_1_F_HEIGHT, MBCONV_6_4_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_4_SQZ_1_F_DEPTH * MBCONV_6_4_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_4_SQZ_2_WEIGHTS, MBConv6_4_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_4_SQZ_2_F_HEIGHT, MBCONV_6_4_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_4_SQZ_2_F_DEPTH * MBCONV_6_4_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_4_PRJ_WEIGHTS, MBConv6_4_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_4_PRJ_F_HEIGHT, MBCONV_6_4_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_4_PRJ_F_DEPTH * MBCONV_6_4_PRJ_F_DENSITY);\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_5_EXPD_WEIGHTS, MBConv6_5_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_5_EXPD_F_HEIGHT,   MBCONV_6_5_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_5_EXPD_F_DEPTH * MBCONV_6_5_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_5_DW_WEIGHTS, MBConv6_5_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_5_DW_F_HEIGHT, MBCONV_6_5_DW_F_WIDTH, \n",
        "                            MBCONV_6_5_DW_F_DEPTH * MBCONV_6_5_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_5_SQZ_1_WEIGHTS, MBConv6_5_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_5_SQZ_1_F_HEIGHT, MBCONV_6_5_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_5_SQZ_1_F_DEPTH * MBCONV_6_5_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_5_SQZ_2_WEIGHTS, MBConv6_5_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_5_SQZ_2_F_HEIGHT, MBCONV_6_5_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_5_SQZ_2_F_DEPTH * MBCONV_6_5_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_5_PRJ_WEIGHTS, MBConv6_5_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_5_PRJ_F_HEIGHT, MBCONV_6_5_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_5_PRJ_F_DEPTH * MBCONV_6_5_PRJ_F_DENSITY);\n",
        "     \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_6_EXPD_WEIGHTS, MBConv6_6_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_6_EXPD_F_HEIGHT,   MBCONV_6_6_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_6_EXPD_F_DEPTH * MBCONV_6_6_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_6_DW_WEIGHTS, MBConv6_6_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_6_DW_F_HEIGHT, MBCONV_6_6_DW_F_WIDTH, \n",
        "                            MBCONV_6_6_DW_F_DEPTH * MBCONV_6_6_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_6_SQZ_1_WEIGHTS, MBConv6_6_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_6_SQZ_1_F_HEIGHT, MBCONV_6_6_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_6_SQZ_1_F_DEPTH * MBCONV_6_6_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_6_SQZ_2_WEIGHTS, MBConv6_6_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_6_SQZ_2_F_HEIGHT, MBCONV_6_6_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_6_SQZ_2_F_DEPTH * MBCONV_6_6_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_6_PRJ_WEIGHTS, MBConv6_6_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_6_PRJ_F_HEIGHT, MBCONV_6_6_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_6_PRJ_F_DEPTH * MBCONV_6_6_PRJ_F_DENSITY);\n",
        "     \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_7_EXPD_WEIGHTS, MBConv6_7_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_7_EXPD_F_HEIGHT,   MBCONV_6_7_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_7_EXPD_F_DEPTH * MBCONV_6_7_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_7_DW_WEIGHTS, MBConv6_7_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_7_DW_F_HEIGHT, MBCONV_6_7_DW_F_WIDTH, \n",
        "                            MBCONV_6_7_DW_F_DEPTH * MBCONV_6_7_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_7_SQZ_1_WEIGHTS, MBConv6_7_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_7_SQZ_1_F_HEIGHT, MBCONV_6_7_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_7_SQZ_1_F_DEPTH * MBCONV_6_7_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_7_SQZ_2_WEIGHTS, MBConv6_7_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_7_SQZ_2_F_HEIGHT, MBCONV_6_7_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_7_SQZ_2_F_DEPTH * MBCONV_6_7_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_7_PRJ_WEIGHTS, MBConv6_7_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_7_PRJ_F_HEIGHT, MBCONV_6_7_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_7_PRJ_F_DEPTH * MBCONV_6_7_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_8_EXPD_WEIGHTS, MBConv6_8_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_8_EXPD_F_HEIGHT,   MBCONV_6_8_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_8_EXPD_F_DEPTH * MBCONV_6_8_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_8_DW_WEIGHTS, MBConv6_8_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_8_DW_F_HEIGHT, MBCONV_6_8_DW_F_WIDTH, \n",
        "                            MBCONV_6_8_DW_F_DEPTH * MBCONV_6_8_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_8_SQZ_1_WEIGHTS, MBConv6_8_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_8_SQZ_1_F_HEIGHT, MBCONV_6_8_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_8_SQZ_1_F_DEPTH * MBCONV_6_8_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_8_SQZ_2_WEIGHTS, MBConv6_8_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_8_SQZ_2_F_HEIGHT, MBCONV_6_8_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_8_SQZ_2_F_DEPTH * MBCONV_6_8_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_8_PRJ_WEIGHTS, MBConv6_8_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_8_PRJ_F_HEIGHT, MBCONV_6_8_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_8_PRJ_F_DEPTH * MBCONV_6_8_PRJ_F_DENSITY);\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_9_EXPD_WEIGHTS, MBConv6_9_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_9_EXPD_F_HEIGHT,   MBCONV_6_9_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_9_EXPD_F_DEPTH * MBCONV_6_9_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_9_DW_WEIGHTS, MBConv6_9_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_9_DW_F_HEIGHT, MBCONV_6_9_DW_F_WIDTH, \n",
        "                            MBCONV_6_9_DW_F_DEPTH * MBCONV_6_9_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_9_SQZ_1_WEIGHTS, MBConv6_9_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_9_SQZ_1_F_HEIGHT, MBCONV_6_9_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_9_SQZ_1_F_DEPTH * MBCONV_6_9_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_9_SQZ_2_WEIGHTS, MBConv6_9_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_9_SQZ_2_F_HEIGHT, MBCONV_6_9_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_9_SQZ_2_F_DEPTH * MBCONV_6_9_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_9_PRJ_WEIGHTS, MBConv6_9_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_9_PRJ_F_HEIGHT, MBCONV_6_9_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_9_PRJ_F_DEPTH * MBCONV_6_9_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_10_EXPD_WEIGHTS, MBConv6_10_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_10_EXPD_F_HEIGHT,   MBCONV_6_10_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_10_EXPD_F_DEPTH * MBCONV_6_10_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_10_DW_WEIGHTS, MBConv6_10_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_10_DW_F_HEIGHT, MBCONV_6_10_DW_F_WIDTH, \n",
        "                            MBCONV_6_10_DW_F_DEPTH * MBCONV_6_10_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_10_SQZ_1_WEIGHTS, MBConv6_10_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_10_SQZ_1_F_HEIGHT, MBCONV_6_10_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_10_SQZ_1_F_DEPTH * MBCONV_6_10_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_10_SQZ_2_WEIGHTS, MBConv6_10_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_10_SQZ_2_F_HEIGHT, MBCONV_6_10_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_10_SQZ_2_F_DEPTH * MBCONV_6_10_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_10_PRJ_WEIGHTS, MBConv6_10_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_10_PRJ_F_HEIGHT, MBCONV_6_10_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_10_PRJ_F_DEPTH * MBCONV_6_10_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_11_EXPD_WEIGHTS, MBConv6_11_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_11_EXPD_F_HEIGHT,   MBCONV_6_11_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_11_EXPD_F_DEPTH * MBCONV_6_11_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_11_DW_WEIGHTS, MBConv6_11_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_11_DW_F_HEIGHT, MBCONV_6_11_DW_F_WIDTH, \n",
        "                            MBCONV_6_11_DW_F_DEPTH * MBCONV_6_11_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_11_SQZ_1_WEIGHTS, MBConv6_11_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_11_SQZ_1_F_HEIGHT, MBCONV_6_11_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_11_SQZ_1_F_DEPTH * MBCONV_6_11_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_11_SQZ_2_WEIGHTS, MBConv6_11_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_11_SQZ_2_F_HEIGHT, MBCONV_6_11_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_11_SQZ_2_F_DEPTH * MBCONV_6_11_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_11_PRJ_WEIGHTS, MBConv6_11_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_11_PRJ_F_HEIGHT, MBCONV_6_11_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_11_PRJ_F_DEPTH * MBCONV_6_11_PRJ_F_DENSITY);\n",
        "\n",
        " \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_12_EXPD_WEIGHTS, MBConv6_12_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_12_EXPD_F_HEIGHT,   MBCONV_6_12_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_12_EXPD_F_DEPTH * MBCONV_6_12_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_12_DW_WEIGHTS, MBConv6_12_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_12_DW_F_HEIGHT, MBCONV_6_12_DW_F_WIDTH, \n",
        "                            MBCONV_6_12_DW_F_DEPTH * MBCONV_6_12_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_12_SQZ_1_WEIGHTS, MBConv6_12_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_12_SQZ_1_F_HEIGHT, MBCONV_6_12_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_12_SQZ_1_F_DEPTH * MBCONV_6_12_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_12_SQZ_2_WEIGHTS, MBConv6_12_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_12_SQZ_2_F_HEIGHT, MBCONV_6_12_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_12_SQZ_2_F_DEPTH * MBCONV_6_12_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_12_PRJ_WEIGHTS, MBConv6_12_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_12_PRJ_F_HEIGHT, MBCONV_6_12_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_12_PRJ_F_DEPTH * MBCONV_6_12_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_13_EXPD_WEIGHTS, MBConv6_13_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_13_EXPD_F_HEIGHT,   MBCONV_6_13_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_13_EXPD_F_DEPTH * MBCONV_6_13_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_13_DW_WEIGHTS, MBConv6_13_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_13_DW_F_HEIGHT, MBCONV_6_13_DW_F_WIDTH, \n",
        "                            MBCONV_6_13_DW_F_DEPTH * MBCONV_6_13_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_13_SQZ_1_WEIGHTS, MBConv6_13_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_13_SQZ_1_F_HEIGHT, MBCONV_6_13_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_13_SQZ_1_F_DEPTH * MBCONV_6_13_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_13_SQZ_2_WEIGHTS, MBConv6_13_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_13_SQZ_2_F_HEIGHT, MBCONV_6_13_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_13_SQZ_2_F_DEPTH * MBCONV_6_13_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_13_PRJ_WEIGHTS, MBConv6_13_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_13_PRJ_F_HEIGHT, MBCONV_6_13_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_13_PRJ_F_DEPTH * MBCONV_6_13_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_14_EXPD_WEIGHTS, MBConv6_14_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_14_EXPD_F_HEIGHT,   MBCONV_6_14_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_14_EXPD_F_DEPTH * MBCONV_6_14_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_14_DW_WEIGHTS, MBConv6_14_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_14_DW_F_HEIGHT, MBCONV_6_14_DW_F_WIDTH, \n",
        "                            MBCONV_6_14_DW_F_DEPTH * MBCONV_6_14_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_14_SQZ_1_WEIGHTS, MBConv6_14_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_14_SQZ_1_F_HEIGHT, MBCONV_6_14_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_14_SQZ_1_F_DEPTH * MBCONV_6_14_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_14_SQZ_2_WEIGHTS, MBConv6_14_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_14_SQZ_2_F_HEIGHT, MBCONV_6_14_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_14_SQZ_2_F_DEPTH * MBCONV_6_14_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_14_PRJ_WEIGHTS, MBConv6_14_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_14_PRJ_F_HEIGHT, MBCONV_6_14_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_14_PRJ_F_DEPTH * MBCONV_6_14_PRJ_F_DENSITY);\n",
        "     \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_15_EXPD_WEIGHTS, MBConv6_15_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_15_EXPD_F_HEIGHT,   MBCONV_6_15_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_15_EXPD_F_DEPTH * MBCONV_6_15_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_15_DW_WEIGHTS, MBConv6_15_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_15_DW_F_HEIGHT, MBCONV_6_15_DW_F_WIDTH, \n",
        "                            MBCONV_6_15_DW_F_DEPTH * MBCONV_6_15_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_15_SQZ_1_WEIGHTS, MBConv6_15_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_15_SQZ_1_F_HEIGHT, MBCONV_6_15_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_15_SQZ_1_F_DEPTH * MBCONV_6_15_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_15_SQZ_2_WEIGHTS, MBConv6_15_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_15_SQZ_2_F_HEIGHT, MBCONV_6_15_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_15_SQZ_2_F_DEPTH * MBCONV_6_15_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_15_PRJ_WEIGHTS, MBConv6_15_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_15_PRJ_F_HEIGHT, MBCONV_6_15_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_15_PRJ_F_DEPTH * MBCONV_6_15_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  set_allocate_copy_array_Device(&HEAD_CONV_WEIGHTS, Head_conv2d_weights,\n",
        "                                  HEAD_CONV_F_HEIGHT, HEAD_CONV_F_WIDTH, HEAD_CONV_F_DEPTH * HEAD_CONV_F_DENSITY,\n",
        "                                \"Head Filter  is allocated in device memory\");   \n",
        " \n",
        "  set_allocate_copy_array_Device(&HEAD_FC_WEIGHTS, Head_linear_weights,\n",
        "                                HEAD_FC_F_HEIGHT, HEAD_FC_F_WIDTH, 1,\n",
        "                                \"Fully Connected weights matrix is allocated in device memory\");  \n",
        "  \n",
        "  // Define bias matrices for all squeeze layers\n",
        "  set_allocate_copy_array_Device(&MBConv6_15_SQZ_1_bias, MBConv6_15_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_15_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #15\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_14_SQZ_1_bias, MBConv6_14_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_14_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #14\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_13_SQZ_1_bias, MBConv6_13_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_13_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #13\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_12_SQZ_1_bias, MBConv6_12_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_12_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #12\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_11_SQZ_1_bias, MBConv6_11_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_11_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #11\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_10_SQZ_1_bias, MBConv6_10_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_10_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #10\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_9_SQZ_1_bias, MBConv6_9_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_9_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #9\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_8_SQZ_1_bias, MBConv6_8_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_8_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #8\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_7_SQZ_1_bias, MBConv6_7_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_7_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #7\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_6_SQZ_1_bias, MBConv6_6_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_6_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #6\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_5_SQZ_1_bias, MBConv6_5_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_5_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #5\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_4_SQZ_1_bias, MBConv6_4_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_4_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #4\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_3_SQZ_1_bias, MBConv6_3_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_3_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #3\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_2_SQZ_1_bias, MBConv6_2_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_2_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #2\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_1_SQZ_1_bias, MBConv6_1_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_1_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #1\");\n",
        "  set_allocate_copy_array_Device(&MBConv1_0_SQZ_1_bias, MBConv1_0_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv1_0_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #0\");   \n",
        "  set_allocate_copy_array_Device(&MBConv6_15_SQZ_2_bias, MBConv6_15_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_15_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #15\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_14_SQZ_2_bias, MBConv6_14_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_14_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #14\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_13_SQZ_2_bias, MBConv6_13_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_13_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #13\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_12_SQZ_2_bias, MBConv6_12_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_12_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #12\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_11_SQZ_2_bias, MBConv6_11_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_11_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #11\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_10_SQZ_2_bias, MBConv6_10_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_10_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #10\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_9_SQZ_2_bias, MBConv6_9_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_9_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #9\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_8_SQZ_2_bias, MBConv6_8_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_8_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #8\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_7_SQZ_2_bias, MBConv6_7_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_7_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #7\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_6_SQZ_2_bias, MBConv6_6_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_6_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #6\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_5_SQZ_2_bias, MBConv6_5_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_5_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #5\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_4_SQZ_2_bias, MBConv6_4_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_4_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #4\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_3_SQZ_2_bias, MBConv6_3_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_3_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #3\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_2_SQZ_2_bias, MBConv6_2_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_2_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #2\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_1_SQZ_2_bias, MBConv6_1_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_1_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #1\");\n",
        "  set_allocate_copy_array_Device(&MBConv1_0_SQZ_2_bias, MBConv1_0_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv1_0_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #0\");    \n",
        "\n",
        "// 3. Define BN mean,variance, weights and bias\n",
        "MBCONV1_0_flag = 1;\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv1_0_EXPD_BN_MEAN,      NULL, 0,\n",
        "  &MBConv1_0_EXPD_BN_VARIANCE,\tNULL, 0,\n",
        "  &MBConv1_0_EXPD_BN_WEIGHTS,\t\tNULL, 0,\n",
        "  &MBConv1_0_EXPD_BN_BIAS,\t\t\tNULL, 0,\n",
        "\n",
        "  &MBConv1_0_DW_BN_MEAN,        MBConv1_0_depthwise_conv_BN_mean,\t\t  sizeof(MBConv1_0_depthwise_conv_BN_mean) / sizeof(float), \t\t\n",
        "  &MBConv1_0_DW_BN_VARIANCE,\t\tMBConv1_0_depthwise_conv_BN_variance,\tsizeof(MBConv1_0_depthwise_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv1_0_DW_BN_WEIGHTS,     MBConv1_0_depthwise_conv_BN_weights,\tsizeof(MBConv1_0_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv1_0_DW_BN_BIAS,\t\t\t\tMBConv1_0_depthwise_conv_BN_bias,\t\t  sizeof(MBConv1_0_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\n",
        "  &MBConv1_0_PRJ_BN_MEAN,       MBConv1_0_project_conv_BN_mean,\t\t\t  sizeof(MBConv1_0_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv1_0_PRJ_BN_VARIANCE,\t\tMBConv1_0_project_conv_BN_variance,\t\tsizeof(MBConv1_0_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv1_0_PRJ_BN_WEIGHTS,    MBConv1_0_project_conv_BN_weights,\t\tsizeof(MBConv1_0_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv1_0_PRJ_BN_BIAS,\t\t\t\tMBConv1_0_project_conv_BN_bias, \t\t  sizeof(MBConv1_0_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "MBCONV1_0_flag = 0;\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_1_EXPD_BN_MEAN,      MBConv6_1_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_1_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_1_EXPD_BN_VARIANCE,\tMBConv6_1_expansion_conv_BN_variance,\tsizeof(MBConv6_1_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_1_EXPD_BN_WEIGHTS,   MBConv6_1_expansion_conv_BN_weights,\tsizeof(MBConv6_1_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_1_EXPD_BN_BIAS,\t\t\tMBConv6_1_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_1_expansion_conv_BN_bias) / sizeof(float),\n",
        "\n",
        "  &MBConv6_1_DW_BN_MEAN,        MBConv6_1_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_1_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_1_DW_BN_VARIANCE,\t\tMBConv6_1_depthwise_conv_BN_variance,\tsizeof(MBConv6_1_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_1_DW_BN_WEIGHTS,     MBConv6_1_depthwise_conv_BN_weights,\tsizeof(MBConv6_1_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_1_DW_BN_BIAS,\t\t\t\tMBConv6_1_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_1_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\n",
        "  &MBConv6_1_PRJ_BN_MEAN,       MBConv6_1_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_1_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_1_PRJ_BN_VARIANCE,\t\tMBConv6_1_project_conv_BN_variance,\t\tsizeof(MBConv6_1_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_1_PRJ_BN_WEIGHTS,    MBConv6_1_project_conv_BN_weights,\t\tsizeof(MBConv6_1_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_1_PRJ_BN_BIAS,\t\t\t\tMBConv6_1_project_conv_BN_bias, \t\t  sizeof(MBConv6_1_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_2_EXPD_BN_MEAN,      MBConv6_2_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_2_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_2_EXPD_BN_VARIANCE,\tMBConv6_2_expansion_conv_BN_variance,\tsizeof(MBConv6_2_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_2_EXPD_BN_WEIGHTS,   MBConv6_2_expansion_conv_BN_weights,\tsizeof(MBConv6_2_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_2_EXPD_BN_BIAS,\t\t\tMBConv6_2_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_2_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_2_DW_BN_MEAN,        MBConv6_2_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_2_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_2_DW_BN_VARIANCE,\t\tMBConv6_2_depthwise_conv_BN_variance,\tsizeof(MBConv6_2_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_2_DW_BN_WEIGHTS,     MBConv6_2_depthwise_conv_BN_weights,\tsizeof(MBConv6_2_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_2_DW_BN_BIAS,\t\t\t  MBConv6_2_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_2_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_2_PRJ_BN_MEAN,       MBConv6_2_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_2_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_2_PRJ_BN_VARIANCE,\t\tMBConv6_2_project_conv_BN_variance,\t\tsizeof(MBConv6_2_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_2_PRJ_BN_WEIGHTS,    MBConv6_2_project_conv_BN_weights,\t\tsizeof(MBConv6_2_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_2_PRJ_BN_BIAS,\t\t\t\tMBConv6_2_project_conv_BN_bias, \t\t  sizeof(MBConv6_2_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_3_EXPD_BN_MEAN,      MBConv6_3_expansion_conv_BN_mean, \t\tsizeof(MBConv6_3_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_3_EXPD_BN_VARIANCE,\tMBConv6_3_expansion_conv_BN_variance,\tsizeof(MBConv6_3_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_3_EXPD_BN_WEIGHTS,   MBConv6_3_expansion_conv_BN_weights,\tsizeof(MBConv6_3_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_3_EXPD_BN_BIAS,\t\t\tMBConv6_3_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_3_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_3_DW_BN_MEAN,        MBConv6_3_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_3_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_3_DW_BN_VARIANCE,\t\tMBConv6_3_depthwise_conv_BN_variance,\tsizeof(MBConv6_3_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_3_DW_BN_WEIGHTS,     MBConv6_3_depthwise_conv_BN_weights,\tsizeof(MBConv6_3_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_3_DW_BN_BIAS,\t\t\t\tMBConv6_3_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_3_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_3_PRJ_BN_MEAN,       MBConv6_3_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_3_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_3_PRJ_BN_VARIANCE,\t\tMBConv6_3_project_conv_BN_variance,\t\tsizeof(MBConv6_3_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_3_PRJ_BN_WEIGHTS,    MBConv6_3_project_conv_BN_weights,\t\tsizeof(MBConv6_3_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_3_PRJ_BN_BIAS,\t\t\t\tMBConv6_3_project_conv_BN_bias, \t\t  sizeof(MBConv6_3_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_4_EXPD_BN_MEAN,      MBConv6_4_expansion_conv_BN_mean, \t\tsizeof(MBConv6_4_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_4_EXPD_BN_VARIANCE,\tMBConv6_4_expansion_conv_BN_variance,\tsizeof(MBConv6_4_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_4_EXPD_BN_WEIGHTS,   MBConv6_4_expansion_conv_BN_weights,\tsizeof(MBConv6_4_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_4_EXPD_BN_BIAS,\t\t\tMBConv6_4_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_4_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_4_DW_BN_MEAN,        MBConv6_4_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_4_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_4_DW_BN_VARIANCE,\t\tMBConv6_4_depthwise_conv_BN_variance,\tsizeof(MBConv6_4_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_4_DW_BN_WEIGHTS,     MBConv6_4_depthwise_conv_BN_weights,\tsizeof(MBConv6_4_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_4_DW_BN_BIAS,\t\t\t\tMBConv6_4_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_4_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_4_PRJ_BN_MEAN,       MBConv6_4_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_4_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_4_PRJ_BN_VARIANCE,\t\tMBConv6_4_project_conv_BN_variance,\t\tsizeof(MBConv6_4_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_4_PRJ_BN_WEIGHTS,    MBConv6_4_project_conv_BN_weights,\t\tsizeof(MBConv6_4_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_4_PRJ_BN_BIAS,\t\t\t\tMBConv6_4_project_conv_BN_bias, \t\t  sizeof(MBConv6_4_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_5_EXPD_BN_MEAN,      MBConv6_5_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_5_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_5_EXPD_BN_VARIANCE,\tMBConv6_5_expansion_conv_BN_variance,\tsizeof(MBConv6_5_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_5_EXPD_BN_WEIGHTS,   MBConv6_5_expansion_conv_BN_weights,\tsizeof(MBConv6_5_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_5_EXPD_BN_BIAS,\t\t\tMBConv6_5_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_5_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_5_DW_BN_MEAN,        MBConv6_5_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_5_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_5_DW_BN_VARIANCE,\t\tMBConv6_5_depthwise_conv_BN_variance,\tsizeof(MBConv6_5_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_5_DW_BN_WEIGHTS,     MBConv6_5_depthwise_conv_BN_weights,\tsizeof(MBConv6_5_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_5_DW_BN_BIAS,\t\t\t\tMBConv6_5_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_5_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_5_PRJ_BN_MEAN,       MBConv6_5_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_5_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_5_PRJ_BN_VARIANCE,\t\tMBConv6_5_project_conv_BN_variance,\t\tsizeof(MBConv6_5_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_5_PRJ_BN_WEIGHTS,    MBConv6_5_project_conv_BN_weights,\t\tsizeof(MBConv6_5_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_5_PRJ_BN_BIAS,\t\t\t\tMBConv6_5_project_conv_BN_bias, \t\t  sizeof(MBConv6_5_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_6_EXPD_BN_MEAN,      MBConv6_6_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_6_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_6_EXPD_BN_VARIANCE,\tMBConv6_6_expansion_conv_BN_variance,\tsizeof(MBConv6_6_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_6_EXPD_BN_WEIGHTS,   MBConv6_6_expansion_conv_BN_weights,\tsizeof(MBConv6_6_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_6_EXPD_BN_BIAS,\t\t\tMBConv6_6_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_6_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_6_DW_BN_MEAN,        MBConv6_6_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_6_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_6_DW_BN_VARIANCE,\t\tMBConv6_6_depthwise_conv_BN_variance,\tsizeof(MBConv6_6_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_6_DW_BN_WEIGHTS,     MBConv6_6_depthwise_conv_BN_weights,\tsizeof(MBConv6_6_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_6_DW_BN_BIAS,\t\t\t\tMBConv6_6_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_6_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_6_PRJ_BN_MEAN,       MBConv6_6_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_6_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_6_PRJ_BN_VARIANCE,\t\tMBConv6_6_project_conv_BN_variance,\t\tsizeof(MBConv6_6_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_6_PRJ_BN_WEIGHTS,    MBConv6_6_project_conv_BN_weights,\t\tsizeof(MBConv6_6_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_6_PRJ_BN_BIAS,\t\t\t\tMBConv6_6_project_conv_BN_bias, \t\t  sizeof(MBConv6_6_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_7_EXPD_BN_MEAN,      MBConv6_7_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_7_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_7_EXPD_BN_VARIANCE,\tMBConv6_7_expansion_conv_BN_variance,\tsizeof(MBConv6_7_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_7_EXPD_BN_WEIGHTS,   MBConv6_7_expansion_conv_BN_weights,\tsizeof(MBConv6_7_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_7_EXPD_BN_BIAS,\t\t\tMBConv6_7_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_7_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_7_DW_BN_MEAN,        MBConv6_7_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_7_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_7_DW_BN_VARIANCE,\t\tMBConv6_7_depthwise_conv_BN_variance,\tsizeof(MBConv6_7_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_7_DW_BN_WEIGHTS,     MBConv6_7_depthwise_conv_BN_weights,\tsizeof(MBConv6_7_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_7_DW_BN_BIAS,\t\t\t\tMBConv6_7_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_7_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_7_PRJ_BN_MEAN,       MBConv6_7_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_7_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_7_PRJ_BN_VARIANCE,\t\tMBConv6_7_project_conv_BN_variance,\t\tsizeof(MBConv6_7_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_7_PRJ_BN_WEIGHTS,    MBConv6_7_project_conv_BN_weights,\t\tsizeof(MBConv6_7_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_7_PRJ_BN_BIAS,\t\t\t\tMBConv6_7_project_conv_BN_bias, \t\t  sizeof(MBConv6_7_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_8_EXPD_BN_MEAN,      MBConv6_8_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_8_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_8_EXPD_BN_VARIANCE,\tMBConv6_8_expansion_conv_BN_variance,\tsizeof(MBConv6_8_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_8_EXPD_BN_WEIGHTS,   MBConv6_8_expansion_conv_BN_weights,\tsizeof(MBConv6_8_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_8_EXPD_BN_BIAS,\t\t\tMBConv6_8_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_8_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_8_DW_BN_MEAN,        MBConv6_8_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_8_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_8_DW_BN_VARIANCE,\t\tMBConv6_8_depthwise_conv_BN_variance,\tsizeof(MBConv6_8_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_8_DW_BN_WEIGHTS,     MBConv6_8_depthwise_conv_BN_weights,\tsizeof(MBConv6_8_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_8_DW_BN_BIAS,\t\t\t\tMBConv6_8_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_8_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_8_PRJ_BN_MEAN,       MBConv6_8_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_8_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_8_PRJ_BN_VARIANCE,\t\tMBConv6_8_project_conv_BN_variance,\t\tsizeof(MBConv6_8_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_8_PRJ_BN_WEIGHTS,    MBConv6_8_project_conv_BN_weights,\t\tsizeof(MBConv6_8_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_8_PRJ_BN_BIAS,\t\t\t\tMBConv6_8_project_conv_BN_bias, \t\t  sizeof(MBConv6_8_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_9_EXPD_BN_MEAN,      MBConv6_9_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_9_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_9_EXPD_BN_VARIANCE,\tMBConv6_9_expansion_conv_BN_variance,\tsizeof(MBConv6_9_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_9_EXPD_BN_WEIGHTS,   MBConv6_9_expansion_conv_BN_weights,\tsizeof(MBConv6_9_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_9_EXPD_BN_BIAS,\t\t\tMBConv6_9_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_9_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_9_DW_BN_MEAN,        MBConv6_9_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_9_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_9_DW_BN_VARIANCE,\t\tMBConv6_9_depthwise_conv_BN_variance,\tsizeof(MBConv6_9_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_9_DW_BN_WEIGHTS,     MBConv6_9_depthwise_conv_BN_weights,\tsizeof(MBConv6_9_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_9_DW_BN_BIAS,\t\t\t\tMBConv6_9_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_9_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_9_PRJ_BN_MEAN,       MBConv6_9_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_9_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_9_PRJ_BN_VARIANCE,\t\tMBConv6_9_project_conv_BN_variance,\t\tsizeof(MBConv6_9_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_9_PRJ_BN_WEIGHTS,    MBConv6_9_project_conv_BN_weights,\t\tsizeof(MBConv6_9_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_9_PRJ_BN_BIAS,\t\t\t\tMBConv6_9_project_conv_BN_bias, \t\t  sizeof(MBConv6_9_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_10_EXPD_BN_MEAN,     MBConv6_10_expansion_conv_BN_mean,    sizeof(MBConv6_10_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_10_EXPD_BN_VARIANCE,\tMBConv6_10_expansion_conv_BN_variance,sizeof(MBConv6_10_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_10_EXPD_BN_WEIGHTS,  MBConv6_10_expansion_conv_BN_weights,\tsizeof(MBConv6_10_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_10_EXPD_BN_BIAS,\t\t\tMBConv6_10_expansion_conv_BN_bias,\t\tsizeof(MBConv6_10_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_10_DW_BN_MEAN,       MBConv6_10_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_10_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_10_DW_BN_VARIANCE,\t\tMBConv6_10_depthwise_conv_BN_variance,sizeof(MBConv6_10_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_10_DW_BN_WEIGHTS,    MBConv6_10_depthwise_conv_BN_weights,\tsizeof(MBConv6_10_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_10_DW_BN_BIAS,\t\t\t\tMBConv6_10_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_10_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_10_PRJ_BN_MEAN,      MBConv6_10_project_conv_BN_mean,\t\t  sizeof(MBConv6_10_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_10_PRJ_BN_VARIANCE,\tMBConv6_10_project_conv_BN_variance,\tsizeof(MBConv6_10_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_10_PRJ_BN_WEIGHTS,   MBConv6_10_project_conv_BN_weights,\t\tsizeof(MBConv6_10_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_10_PRJ_BN_BIAS,\t\t\tMBConv6_10_project_conv_BN_bias, \t\t  sizeof(MBConv6_10_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_11_EXPD_BN_MEAN,     MBConv6_11_expansion_conv_BN_mean,\t\tsizeof(MBConv6_11_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_11_EXPD_BN_VARIANCE,\tMBConv6_11_expansion_conv_BN_variance,sizeof(MBConv6_11_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_11_EXPD_BN_WEIGHTS,  MBConv6_11_expansion_conv_BN_weights,\tsizeof(MBConv6_11_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_11_EXPD_BN_BIAS,\t\t\tMBConv6_11_expansion_conv_BN_bias,\t\tsizeof(MBConv6_11_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_11_DW_BN_MEAN,       MBConv6_11_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_11_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_11_DW_BN_VARIANCE,\t\tMBConv6_11_depthwise_conv_BN_variance,sizeof(MBConv6_11_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_11_DW_BN_WEIGHTS,    MBConv6_11_depthwise_conv_BN_weights,\tsizeof(MBConv6_11_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_11_DW_BN_BIAS,\t\t\t\tMBConv6_11_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_11_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_11_PRJ_BN_MEAN,      MBConv6_11_project_conv_BN_mean,\t\t  sizeof(MBConv6_11_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_11_PRJ_BN_VARIANCE,\tMBConv6_11_project_conv_BN_variance,\tsizeof(MBConv6_11_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_11_PRJ_BN_WEIGHTS,   MBConv6_11_project_conv_BN_weights,\t\tsizeof(MBConv6_11_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_11_PRJ_BN_BIAS,\t\t\tMBConv6_11_project_conv_BN_bias, \t\t  sizeof(MBConv6_11_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_12_EXPD_BN_MEAN,     MBConv6_12_expansion_conv_BN_mean,\t\tsizeof(MBConv6_12_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_12_EXPD_BN_VARIANCE,\tMBConv6_12_expansion_conv_BN_variance,sizeof(MBConv6_12_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_12_EXPD_BN_WEIGHTS,  MBConv6_12_expansion_conv_BN_weights,\tsizeof(MBConv6_12_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_12_EXPD_BN_BIAS,\t\t\tMBConv6_12_expansion_conv_BN_bias,\t\tsizeof(MBConv6_12_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_12_DW_BN_MEAN,       MBConv6_12_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_12_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_12_DW_BN_VARIANCE,\t\tMBConv6_12_depthwise_conv_BN_variance,sizeof(MBConv6_12_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_12_DW_BN_WEIGHTS,    MBConv6_12_depthwise_conv_BN_weights,\tsizeof(MBConv6_12_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_12_DW_BN_BIAS,\t\t\t\tMBConv6_12_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_12_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_12_PRJ_BN_MEAN,      MBConv6_12_project_conv_BN_mean,\t\t  sizeof(MBConv6_12_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_12_PRJ_BN_VARIANCE,\tMBConv6_12_project_conv_BN_variance,\tsizeof(MBConv6_12_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_12_PRJ_BN_WEIGHTS,   MBConv6_12_project_conv_BN_weights,\t\tsizeof(MBConv6_12_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_12_PRJ_BN_BIAS,\t\t\tMBConv6_12_project_conv_BN_bias, \t\t  sizeof(MBConv6_12_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_13_EXPD_BN_MEAN,     MBConv6_13_expansion_conv_BN_mean,\t\tsizeof(MBConv6_13_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_13_EXPD_BN_VARIANCE,\tMBConv6_13_expansion_conv_BN_variance,sizeof(MBConv6_13_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_13_EXPD_BN_WEIGHTS,  MBConv6_13_expansion_conv_BN_weights,\tsizeof(MBConv6_13_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_13_EXPD_BN_BIAS,\t\t\tMBConv6_13_expansion_conv_BN_bias,\t\tsizeof(MBConv6_13_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_13_DW_BN_MEAN,       MBConv6_13_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_13_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_13_DW_BN_VARIANCE,\t\tMBConv6_13_depthwise_conv_BN_variance,sizeof(MBConv6_13_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_13_DW_BN_WEIGHTS,    MBConv6_13_depthwise_conv_BN_weights,\tsizeof(MBConv6_13_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_13_DW_BN_BIAS,\t\t\t\tMBConv6_13_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_13_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_13_PRJ_BN_MEAN,      MBConv6_13_project_conv_BN_mean,\t\t  sizeof(MBConv6_13_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_13_PRJ_BN_VARIANCE,\tMBConv6_13_project_conv_BN_variance,\tsizeof(MBConv6_13_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_13_PRJ_BN_WEIGHTS,   MBConv6_13_project_conv_BN_weights,\t\tsizeof(MBConv6_13_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_13_PRJ_BN_BIAS,\t\t\tMBConv6_13_project_conv_BN_bias, \t\t  sizeof(MBConv6_13_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_14_EXPD_BN_MEAN,     MBConv6_14_expansion_conv_BN_mean,\t\tsizeof(MBConv6_14_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_14_EXPD_BN_VARIANCE,\tMBConv6_14_expansion_conv_BN_variance,sizeof(MBConv6_14_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_14_EXPD_BN_WEIGHTS,  MBConv6_14_expansion_conv_BN_weights,\tsizeof(MBConv6_14_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_14_EXPD_BN_BIAS,\t\t\tMBConv6_14_expansion_conv_BN_bias,\t\tsizeof(MBConv6_14_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_14_DW_BN_MEAN,       MBConv6_14_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_14_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_14_DW_BN_VARIANCE,\t\tMBConv6_14_depthwise_conv_BN_variance,sizeof(MBConv6_14_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_14_DW_BN_WEIGHTS,    MBConv6_14_depthwise_conv_BN_weights,\tsizeof(MBConv6_14_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_14_DW_BN_BIAS,\t\t\t\tMBConv6_14_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_14_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_14_PRJ_BN_MEAN,      MBConv6_14_project_conv_BN_mean,\t\t  sizeof(MBConv6_14_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_14_PRJ_BN_VARIANCE,\tMBConv6_14_project_conv_BN_variance,\tsizeof(MBConv6_14_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_14_PRJ_BN_WEIGHTS,   MBConv6_14_project_conv_BN_weights,\t\tsizeof(MBConv6_14_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_14_PRJ_BN_BIAS,\t\t\tMBConv6_14_project_conv_BN_bias, \t\t  sizeof(MBConv6_14_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "  &MBConv6_15_EXPD_BN_MEAN,     MBConv6_15_expansion_conv_BN_mean,\t\tsizeof(MBConv6_15_expansion_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_15_EXPD_BN_VARIANCE,\tMBConv6_15_expansion_conv_BN_variance,sizeof(MBConv6_15_expansion_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_15_EXPD_BN_WEIGHTS,  MBConv6_15_expansion_conv_BN_weights,\tsizeof(MBConv6_15_expansion_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_15_EXPD_BN_BIAS,\t\t\tMBConv6_15_expansion_conv_BN_bias,\t\tsizeof(MBConv6_15_expansion_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_15_DW_BN_MEAN,       MBConv6_15_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_15_depthwise_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_15_DW_BN_VARIANCE,\t\tMBConv6_15_depthwise_conv_BN_variance,sizeof(MBConv6_15_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "  &MBConv6_15_DW_BN_WEIGHTS,    MBConv6_15_depthwise_conv_BN_weights,\tsizeof(MBConv6_15_depthwise_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_15_DW_BN_BIAS,\t\t\t\tMBConv6_15_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_15_depthwise_conv_BN_bias) / sizeof(float),\n",
        "  &MBConv6_15_PRJ_BN_MEAN,      MBConv6_15_project_conv_BN_mean,\t\t  sizeof(MBConv6_15_project_conv_BN_mean) / sizeof(float),\n",
        "  &MBConv6_15_PRJ_BN_VARIANCE,\tMBConv6_15_project_conv_BN_variance,\tsizeof(MBConv6_15_project_conv_BN_variance) / sizeof(float),\n",
        "  &MBConv6_15_PRJ_BN_WEIGHTS,   MBConv6_15_project_conv_BN_weights,\t\tsizeof(MBConv6_15_project_conv_BN_weights) / sizeof(float),\n",
        "  &MBConv6_15_PRJ_BN_BIAS,\t\t\tMBConv6_15_project_conv_BN_bias, \t\t  sizeof(MBConv6_15_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "\n",
        "set_allocate_copy_array_Device(&D_STEM_BN_MEAN, Stem_BN_mean,\n",
        "                sizeof(Stem_BN_mean)/sizeof(float), 1, 1,\n",
        "                \"STEM MEAN\"); \n",
        "set_allocate_copy_array_Device(&D_STEM_BN_VARIANCE, Stem_BN_variance,\n",
        "                sizeof(Stem_BN_variance)/sizeof(float), 1, 1,\n",
        "                \"STEAM VARIANCE\"); \n",
        "set_allocate_copy_array_Device(&D_STEM_BN_WEIGHTS, Stem_BN_weights,\n",
        "                sizeof(Stem_BN_weights)/sizeof(float), 1, 1,\n",
        "                \"STEM WEIGHTS\"); \n",
        "set_allocate_copy_array_Device(&D_STEM_BN_BIAS, Stem_BN_bias,\n",
        "                sizeof(Stem_BN_bias)/sizeof(float), 1, 1,\n",
        "                \"STEM BIAS\"); \n",
        "                \n",
        "set_allocate_copy_array_Device(&D_HEAD_BN_MEAN, Head_BN_mean,\n",
        "                sizeof(Head_BN_mean)/sizeof(float), 1, 1,\n",
        "                \"HEAD MEAN\"); \n",
        "set_allocate_copy_array_Device(&D_HEAD_BN_VARIANCE, Head_BN_variance,\n",
        "                sizeof(Head_BN_variance)/sizeof(float), 1, 1,\n",
        "                \"HEAD VARIANCE\"); \n",
        "set_allocate_copy_array_Device(&D_HEAD_BN_WEIGHTS, Head_BN_weights,\n",
        "                sizeof(Head_BN_weights)/sizeof(float), 1, 1,\n",
        "                \"HEAD WEIGHTS\"); \n",
        "set_allocate_copy_array_Device(&D_HEAD_BN_BIAS, Head_BN_bias,\n",
        "                sizeof(Head_BN_bias)/sizeof(float), 1, 1,\n",
        "                \"HEAD BIAS\"); \n",
        "start();\n",
        "  // 3. Move through all layers starting from stem layer till head layer\n",
        "  Matrix ConvOutStem;\n",
        "  STEM_LAYER(&DInput_Mat, &F_STEM,\n",
        "              INPUT_IMAGE_HEIGHT, INPUT_IMAGE_WIDTH, INPUT_IMAGE_DEPTH,\n",
        "              STEM_FILTER_HEIGHT, STEM_FILTER_WIDTH, STEM_FILTER_DEPTH, \n",
        "              STEM_FILTER_DENSITY,STEM_PADDING,      STEM_STRIDE,\n",
        "              &ConvOutStem);\n",
        "\n",
        "\n",
        "  Matrix ConvOut1_0;\n",
        "  MBCONV1_0_flag = 1;  \n",
        "\n",
        "  MBConv_Layer(&ConvOutStem, &ConvOut1_0,\n",
        "                &D_MBConv_1_0_EXPD_WEIGHTS, &D_MBConv_1_0_DW_WEIGHTS,\n",
        "                &D_MBConv_1_0_SQZ_1_WEIGHTS,&D_MBConv_1_0_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_1_0_PRJ_WEIGHTS,\n",
        "                MBCONV_1_0_EXPD_F_DENSITY,  MBCONV_1_0_DW_F_DENSITY, \n",
        "                MBCONV_1_0_SQZ_1_F_DENSITY, MBCONV_1_0_SQZ_2_F_DENSITY, \n",
        "                MBCONV_1_0_PRJ_F_DENSITY,\n",
        "                ConvOutStem.depth,          MBCONV_1_0_PRJ_F_DENSITY, MBCONV_1_0_DW_F_HEIGHT,\n",
        "                MBCONV_1_0_STRIDE,          MBCONV_1_0_PADDING, MBCONV_1_0_SKIP,\n",
        "                &MBConv1_0_SQZ_1_bias, \t    &MBConv1_0_SQZ_2_bias,\n",
        "                NULL,                       NULL,\n",
        "                NULL,                       NULL,\n",
        "                &MBConv1_0_DW_BN_MEAN,      &MBConv1_0_DW_BN_VARIANCE,\n",
        "                &MBConv1_0_DW_BN_WEIGHTS,   &MBConv1_0_DW_BN_BIAS,\n",
        "                &MBConv1_0_PRJ_BN_MEAN,     &MBConv1_0_PRJ_BN_VARIANCE,\n",
        "                &MBConv1_0_PRJ_BN_WEIGHTS,  &MBConv1_0_PRJ_BN_BIAS);\n",
        "  MBCONV1_0_flag = 0;\n",
        "  \n",
        "\n",
        "  Matrix ConvOut;\n",
        "  MBConv_Layer(&ConvOut1_0, &ConvOut,\n",
        "                &D_MBConv_6_1_EXPD_WEIGHTS, &D_MBConv_6_1_DW_WEIGHTS,\n",
        "                &D_MBConv_6_1_SQZ_1_WEIGHTS,&D_MBConv_6_1_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_1_PRJ_WEIGHTS,\n",
        "                MBCONV_6_1_EXPD_F_DENSITY,  MBCONV_6_1_DW_F_DENSITY, \n",
        "                MBCONV_6_1_SQZ_1_F_DENSITY, MBCONV_6_1_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_1_PRJ_F_DENSITY,\n",
        "                ConvOut1_0.depth,           MBCONV_6_1_PRJ_F_DENSITY, MBCONV_6_1_DW_F_HEIGHT,\n",
        "                MBCONV_6_1_STRIDE,          MBCONV_6_1_PADDING, MBCONV_6_1_SKIP,\n",
        "                &MBConv6_1_SQZ_1_bias, \t    &MBConv6_1_SQZ_2_bias,\n",
        "                &MBConv6_1_EXPD_BN_MEAN,    &MBConv6_1_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_1_EXPD_BN_WEIGHTS, &MBConv6_1_EXPD_BN_BIAS,\n",
        "                &MBConv6_1_DW_BN_MEAN,      &MBConv6_1_DW_BN_VARIANCE,\n",
        "                &MBConv6_1_DW_BN_WEIGHTS,   &MBConv6_1_DW_BN_BIAS,\n",
        "                &MBConv6_1_PRJ_BN_MEAN,     &MBConv6_1_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_1_PRJ_BN_WEIGHTS,  &MBConv6_1_PRJ_BN_BIAS);\n",
        "\n",
        "\n",
        "  Matrix ConvOut2;\n",
        "  MBConv_Layer(&ConvOut, &ConvOut2,\n",
        "                &D_MBConv_6_2_EXPD_WEIGHTS, &D_MBConv_6_2_DW_WEIGHTS,\n",
        "                &D_MBConv_6_2_SQZ_1_WEIGHTS,&D_MBConv_6_2_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_2_PRJ_WEIGHTS,\n",
        "                MBCONV_6_2_EXPD_F_DENSITY,  MBCONV_6_2_DW_F_DENSITY, \n",
        "                MBCONV_6_2_SQZ_1_F_DENSITY, MBCONV_6_2_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_2_PRJ_F_DENSITY,\n",
        "                ConvOut.depth,              MBCONV_6_2_PRJ_F_DENSITY, MBCONV_6_2_DW_F_HEIGHT,\n",
        "                MBCONV_6_2_STRIDE,          MBCONV_6_2_PADDING, MBCONV_6_2_SKIP,\n",
        "                &MBConv6_2_SQZ_1_bias, \t    &MBConv6_2_SQZ_2_bias,\n",
        "                &MBConv6_2_EXPD_BN_MEAN,    &MBConv6_2_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_2_EXPD_BN_WEIGHTS, &MBConv6_2_EXPD_BN_BIAS,\n",
        "                &MBConv6_2_DW_BN_MEAN,      &MBConv6_2_DW_BN_VARIANCE,\n",
        "                &MBConv6_2_DW_BN_WEIGHTS,   &MBConv6_2_DW_BN_BIAS,\n",
        "                &MBConv6_2_PRJ_BN_MEAN,     &MBConv6_2_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_2_PRJ_BN_WEIGHTS,  &MBConv6_2_PRJ_BN_BIAS); \n",
        "\n",
        "\n",
        "  Matrix ConvOut3;\n",
        "\tMBConv_Layer(&ConvOut2, &ConvOut3,\n",
        "                &D_MBConv_6_3_EXPD_WEIGHTS, &D_MBConv_6_3_DW_WEIGHTS,\n",
        "                &D_MBConv_6_3_SQZ_1_WEIGHTS,&D_MBConv_6_3_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_3_PRJ_WEIGHTS,\n",
        "                MBCONV_6_3_EXPD_F_DENSITY,  MBCONV_6_3_DW_F_DENSITY, \n",
        "                MBCONV_6_3_SQZ_1_F_DENSITY, MBCONV_6_3_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_3_PRJ_F_DENSITY,\n",
        "                ConvOut2.depth,             MBCONV_6_3_PRJ_F_DENSITY, MBCONV_6_3_DW_F_HEIGHT,\n",
        "                MBCONV_6_3_STRIDE,          MBCONV_6_3_PADDING, MBCONV_6_3_SKIP,\n",
        "                &MBConv6_3_SQZ_1_bias,  \t  &MBConv6_3_SQZ_2_bias,\n",
        "                &MBConv6_3_EXPD_BN_MEAN,    &MBConv6_3_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_3_EXPD_BN_WEIGHTS, &MBConv6_3_EXPD_BN_BIAS,\n",
        "                &MBConv6_3_DW_BN_MEAN,      &MBConv6_3_DW_BN_VARIANCE,\n",
        "                &MBConv6_3_DW_BN_WEIGHTS,   &MBConv6_3_DW_BN_BIAS,\n",
        "                &MBConv6_3_PRJ_BN_MEAN,     &MBConv6_3_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_3_PRJ_BN_WEIGHTS,  &MBConv6_3_PRJ_BN_BIAS);  \n",
        " \n",
        "\n",
        "  // MBConv6_4 layer implementation\n",
        "\n",
        "  Matrix ConvOut4;\n",
        "  MBConv_Layer(&ConvOut3, &ConvOut4,\n",
        "                &D_MBConv_6_4_EXPD_WEIGHTS, &D_MBConv_6_4_DW_WEIGHTS,\n",
        "                &D_MBConv_6_4_SQZ_1_WEIGHTS,&D_MBConv_6_4_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_4_PRJ_WEIGHTS,\n",
        "                MBCONV_6_4_EXPD_F_DENSITY,  MBCONV_6_4_DW_F_DENSITY, \n",
        "                MBCONV_6_4_SQZ_1_F_DENSITY, MBCONV_6_4_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_4_PRJ_F_DENSITY,\n",
        "                ConvOut3.depth,             MBCONV_6_4_PRJ_F_DENSITY, MBCONV_6_4_DW_F_HEIGHT,\n",
        "                MBCONV_6_4_STRIDE,          MBCONV_6_4_PADDING, MBCONV_6_4_SKIP,\n",
        "                &MBConv6_4_SQZ_1_bias,  \t  &MBConv6_4_SQZ_2_bias,\n",
        "                &MBConv6_4_EXPD_BN_MEAN,    &MBConv6_4_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_4_EXPD_BN_WEIGHTS, &MBConv6_4_EXPD_BN_BIAS,\n",
        "                &MBConv6_4_DW_BN_MEAN,      &MBConv6_4_DW_BN_VARIANCE,\n",
        "                &MBConv6_4_DW_BN_WEIGHTS,   &MBConv6_4_DW_BN_BIAS,\n",
        "                &MBConv6_4_PRJ_BN_MEAN,     &MBConv6_4_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_4_PRJ_BN_WEIGHTS,  &MBConv6_4_PRJ_BN_BIAS);   \n",
        "  \n",
        "\n",
        "  Matrix ConvOut5;\n",
        "  MBConv_Layer(&ConvOut4, &ConvOut5,\n",
        "                &D_MBConv_6_5_EXPD_WEIGHTS, &D_MBConv_6_5_DW_WEIGHTS,\n",
        "                &D_MBConv_6_5_SQZ_1_WEIGHTS,&D_MBConv_6_5_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_5_PRJ_WEIGHTS,\n",
        "                MBCONV_6_5_EXPD_F_DENSITY,  MBCONV_6_5_DW_F_DENSITY, \n",
        "                MBCONV_6_5_SQZ_1_F_DENSITY, MBCONV_6_5_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_5_PRJ_F_DENSITY,\n",
        "                ConvOut4.depth,             MBCONV_6_5_PRJ_F_DENSITY, MBCONV_6_5_DW_F_HEIGHT,\n",
        "                MBCONV_6_5_STRIDE,          MBCONV_6_5_PADDING, MBCONV_6_5_SKIP,\n",
        "                &MBConv6_5_SQZ_1_bias,  \t  &MBConv6_5_SQZ_2_bias,\n",
        "                &MBConv6_5_EXPD_BN_MEAN,    &MBConv6_5_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_5_EXPD_BN_WEIGHTS, &MBConv6_5_EXPD_BN_BIAS,\n",
        "                &MBConv6_5_DW_BN_MEAN,      &MBConv6_5_DW_BN_VARIANCE,\n",
        "                &MBConv6_5_DW_BN_WEIGHTS,   &MBConv6_5_DW_BN_BIAS,\n",
        "                &MBConv6_5_PRJ_BN_MEAN,     &MBConv6_5_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_5_PRJ_BN_WEIGHTS,  &MBConv6_5_PRJ_BN_BIAS); \n",
        "            \n",
        "\n",
        "\n",
        "  // MBConv6_6 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut6;\n",
        "  MBConv_Layer(&ConvOut5, &ConvOut6,\n",
        "                &D_MBConv_6_6_EXPD_WEIGHTS, &D_MBConv_6_6_DW_WEIGHTS,\n",
        "                &D_MBConv_6_6_SQZ_1_WEIGHTS,&D_MBConv_6_6_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_6_PRJ_WEIGHTS,\n",
        "                MBCONV_6_6_EXPD_F_DENSITY,  MBCONV_6_6_DW_F_DENSITY, \n",
        "                MBCONV_6_6_SQZ_1_F_DENSITY, MBCONV_6_6_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_6_PRJ_F_DENSITY,\n",
        "                ConvOut5.depth,             MBCONV_6_6_PRJ_F_DENSITY, MBCONV_6_6_DW_F_HEIGHT,\n",
        "                MBCONV_6_6_STRIDE,          MBCONV_6_6_PADDING, MBCONV_6_6_SKIP,\n",
        "                &MBConv6_6_SQZ_1_bias, \t    &MBConv6_6_SQZ_2_bias,\n",
        "                &MBConv6_6_EXPD_BN_MEAN,    &MBConv6_6_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_6_EXPD_BN_WEIGHTS, &MBConv6_6_EXPD_BN_BIAS,\n",
        "                &MBConv6_6_DW_BN_MEAN,      &MBConv6_6_DW_BN_VARIANCE,\n",
        "                &MBConv6_6_DW_BN_WEIGHTS,   &MBConv6_6_DW_BN_BIAS,\n",
        "                &MBConv6_6_PRJ_BN_MEAN,     &MBConv6_6_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_6_PRJ_BN_WEIGHTS,  &MBConv6_6_PRJ_BN_BIAS);  \n",
        "            \n",
        "\n",
        "\n",
        "  // MBConv6_7 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut7;\n",
        "  MBConv_Layer(&ConvOut6, &ConvOut7,\n",
        "                &D_MBConv_6_7_EXPD_WEIGHTS, &D_MBConv_6_7_DW_WEIGHTS,\n",
        "                &D_MBConv_6_7_SQZ_1_WEIGHTS,&D_MBConv_6_7_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_7_PRJ_WEIGHTS,\n",
        "                MBCONV_6_7_EXPD_F_DENSITY,  MBCONV_6_7_DW_F_DENSITY, \n",
        "                MBCONV_6_7_SQZ_1_F_DENSITY, MBCONV_6_7_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_7_PRJ_F_DENSITY,\n",
        "                ConvOut6.depth,             MBCONV_6_7_PRJ_F_DENSITY, MBCONV_6_7_DW_F_HEIGHT,                   \n",
        "                MBCONV_6_7_STRIDE,          MBCONV_6_7_PADDING, MBCONV_6_7_SKIP,\n",
        "                &MBConv6_7_SQZ_1_bias,  \t  &MBConv6_7_SQZ_2_bias,\n",
        "                &MBConv6_7_EXPD_BN_MEAN,    &MBConv6_7_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_7_EXPD_BN_WEIGHTS, &MBConv6_7_EXPD_BN_BIAS,\n",
        "                &MBConv6_7_DW_BN_MEAN,      &MBConv6_7_DW_BN_VARIANCE,\n",
        "                &MBConv6_7_DW_BN_WEIGHTS,   &MBConv6_7_DW_BN_BIAS,\n",
        "                &MBConv6_7_PRJ_BN_MEAN,     &MBConv6_7_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_7_PRJ_BN_WEIGHTS,  &MBConv6_7_PRJ_BN_BIAS);  \n",
        "          \n",
        "\n",
        "\n",
        "  // MBConv6_8 layer implementation\n",
        "  Matrix ConvOut8;\n",
        "  MBConv_Layer(&ConvOut7, &ConvOut8,\n",
        "                &D_MBConv_6_8_EXPD_WEIGHTS, &D_MBConv_6_8_DW_WEIGHTS,\n",
        "                &D_MBConv_6_8_SQZ_1_WEIGHTS,&D_MBConv_6_8_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_8_PRJ_WEIGHTS,\n",
        "                MBCONV_6_8_EXPD_F_DENSITY,  MBCONV_6_8_DW_F_DENSITY, \n",
        "                MBCONV_6_8_SQZ_1_F_DENSITY, MBCONV_6_8_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_8_PRJ_F_DENSITY,\n",
        "                ConvOut7.depth,             MBCONV_6_8_PRJ_F_DENSITY, MBCONV_6_8_DW_F_HEIGHT,    \n",
        "                MBCONV_6_8_STRIDE,          MBCONV_6_8_PADDING, MBCONV_6_8_SKIP,\n",
        "                &MBConv6_8_SQZ_1_bias,      &MBConv6_8_SQZ_2_bias,\n",
        "                &MBConv6_8_EXPD_BN_MEAN,    &MBConv6_8_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_8_EXPD_BN_WEIGHTS, &MBConv6_8_EXPD_BN_BIAS,\n",
        "                &MBConv6_8_DW_BN_MEAN,      &MBConv6_8_DW_BN_VARIANCE,\n",
        "                &MBConv6_8_DW_BN_WEIGHTS,   &MBConv6_8_DW_BN_BIAS,\n",
        "                &MBConv6_8_PRJ_BN_MEAN,     &MBConv6_8_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_8_PRJ_BN_WEIGHTS,  &MBConv6_8_PRJ_BN_BIAS); \n",
        "        \n",
        "\n",
        "\n",
        "  // MBConv6_9 layer implementation\n",
        "  Matrix ConvOut9;\n",
        "  MBConv_Layer(&ConvOut8, &ConvOut9,\n",
        "                &D_MBConv_6_9_EXPD_WEIGHTS, &D_MBConv_6_9_DW_WEIGHTS,\n",
        "                &D_MBConv_6_9_SQZ_1_WEIGHTS,&D_MBConv_6_9_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_9_PRJ_WEIGHTS,\n",
        "                MBCONV_6_9_EXPD_F_DENSITY,  MBCONV_6_9_DW_F_DENSITY, \n",
        "                MBCONV_6_9_SQZ_1_F_DENSITY, MBCONV_6_9_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_9_PRJ_F_DENSITY,\n",
        "                ConvOut8.depth,             MBCONV_6_9_PRJ_F_DENSITY, MBCONV_6_9_DW_F_HEIGHT,\n",
        "                MBCONV_6_9_STRIDE,          MBCONV_6_9_PADDING, MBCONV_6_9_SKIP,\n",
        "                &MBConv6_9_SQZ_1_bias,  \t  &MBConv6_9_SQZ_2_bias,\n",
        "                &MBConv6_9_EXPD_BN_MEAN,    &MBConv6_9_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_9_EXPD_BN_WEIGHTS, &MBConv6_9_EXPD_BN_BIAS,\n",
        "                &MBConv6_9_DW_BN_MEAN,      &MBConv6_9_DW_BN_VARIANCE,\n",
        "                &MBConv6_9_DW_BN_WEIGHTS,   &MBConv6_9_DW_BN_BIAS,\n",
        "                &MBConv6_9_PRJ_BN_MEAN,     &MBConv6_9_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_9_PRJ_BN_WEIGHTS,  &MBConv6_9_PRJ_BN_BIAS);  \t\t\t\t  \n",
        "\n",
        "\n",
        "\n",
        "  // MBConv6_10 layer implementation\n",
        "  Matrix ConvOut10;\n",
        "\tMBConv_Layer(&ConvOut9, &ConvOut10,\n",
        "                &D_MBConv_6_10_EXPD_WEIGHTS,  &D_MBConv_6_10_DW_WEIGHTS,\n",
        "                &D_MBConv_6_10_SQZ_1_WEIGHTS, &D_MBConv_6_10_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_10_PRJ_WEIGHTS,\n",
        "                MBCONV_6_10_EXPD_F_DENSITY,   MBCONV_6_10_DW_F_DENSITY, \n",
        "                MBCONV_6_10_SQZ_1_F_DENSITY,  MBCONV_6_10_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_10_PRJ_F_DENSITY,\n",
        "                ConvOut9.depth,               MBCONV_6_10_PRJ_F_DENSITY, MBCONV_6_10_DW_F_HEIGHT,\n",
        "                MBCONV_6_10_STRIDE,           MBCONV_6_10_PADDING, MBCONV_6_10_SKIP,\n",
        "                &MBConv6_10_SQZ_1_bias, \t    &MBConv6_10_SQZ_2_bias,\n",
        "                &MBConv6_10_EXPD_BN_MEAN,     &MBConv6_10_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_10_EXPD_BN_WEIGHTS,  &MBConv6_10_EXPD_BN_BIAS,\n",
        "                &MBConv6_10_DW_BN_MEAN,       &MBConv6_10_DW_BN_VARIANCE,\n",
        "                &MBConv6_10_DW_BN_WEIGHTS,    &MBConv6_10_DW_BN_BIAS,\n",
        "                &MBConv6_10_PRJ_BN_MEAN,      &MBConv6_10_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_10_PRJ_BN_WEIGHTS,   &MBConv6_10_PRJ_BN_BIAS);   \n",
        "  \n",
        "\n",
        "\n",
        "  // MBConv6_11 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut11;\n",
        "  MBConv_Layer(&ConvOut10, &ConvOut11,\n",
        "                &D_MBConv_6_11_EXPD_WEIGHTS,  &D_MBConv_6_11_DW_WEIGHTS,\n",
        "                &D_MBConv_6_11_SQZ_1_WEIGHTS, &D_MBConv_6_11_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_11_PRJ_WEIGHTS,\n",
        "                MBCONV_6_11_EXPD_F_DENSITY,   MBCONV_6_11_DW_F_DENSITY, \n",
        "                MBCONV_6_11_SQZ_1_F_DENSITY,  MBCONV_6_11_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_11_PRJ_F_DENSITY,  \n",
        "                ConvOut10.depth,              MBCONV_6_11_PRJ_F_DENSITY, MBCONV_6_11_DW_F_HEIGHT,\n",
        "                MBCONV_6_11_STRIDE,           MBCONV_6_11_PADDING, MBCONV_6_11_SKIP,\n",
        "                &MBConv6_11_SQZ_1_bias,       &MBConv6_11_SQZ_2_bias,\n",
        "                &MBConv6_11_EXPD_BN_MEAN,     &MBConv6_11_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_11_EXPD_BN_WEIGHTS,  &MBConv6_11_EXPD_BN_BIAS,\n",
        "                &MBConv6_11_DW_BN_MEAN,       &MBConv6_11_DW_BN_VARIANCE,\n",
        "                &MBConv6_11_DW_BN_WEIGHTS,    &MBConv6_11_DW_BN_BIAS,\n",
        "                &MBConv6_11_PRJ_BN_MEAN,      &MBConv6_11_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_11_PRJ_BN_WEIGHTS,   &MBConv6_11_PRJ_BN_BIAS);  \n",
        "  \n",
        "\n",
        "\n",
        "  // MBConv6_12 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut12;\n",
        "  MBConv_Layer(&ConvOut11, &ConvOut12,\n",
        "                &D_MBConv_6_12_EXPD_WEIGHTS,  &D_MBConv_6_12_DW_WEIGHTS,\n",
        "                &D_MBConv_6_12_SQZ_1_WEIGHTS, &D_MBConv_6_12_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_12_PRJ_WEIGHTS,\n",
        "                MBCONV_6_12_EXPD_F_DENSITY,   MBCONV_6_12_DW_F_DENSITY, \n",
        "                MBCONV_6_12_SQZ_1_F_DENSITY,  MBCONV_6_12_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_12_PRJ_F_DENSITY,\n",
        "                ConvOut11.depth,              MBCONV_6_12_PRJ_F_DENSITY, MBCONV_6_12_DW_F_HEIGHT,\n",
        "                MBCONV_6_12_STRIDE,           MBCONV_6_12_PADDING, MBCONV_6_12_SKIP,\n",
        "                &MBConv6_12_SQZ_1_bias,       &MBConv6_12_SQZ_2_bias,\n",
        "                &MBConv6_12_EXPD_BN_MEAN,     &MBConv6_12_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_12_EXPD_BN_WEIGHTS,  &MBConv6_12_EXPD_BN_BIAS,\n",
        "                &MBConv6_12_DW_BN_MEAN,       &MBConv6_12_DW_BN_VARIANCE,\n",
        "                &MBConv6_12_DW_BN_WEIGHTS,    &MBConv6_12_DW_BN_BIAS,\n",
        "                &MBConv6_12_PRJ_BN_MEAN,      &MBConv6_12_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_12_PRJ_BN_WEIGHTS,   &MBConv6_12_PRJ_BN_BIAS);   \n",
        "  \n",
        "\n",
        "\n",
        "  // MBConv6_13 layer implementation\n",
        "\n",
        "  Matrix ConvOut13;\n",
        "  MBConv_Layer(&ConvOut12, &ConvOut13,\n",
        "                &D_MBConv_6_13_EXPD_WEIGHTS,  &D_MBConv_6_13_DW_WEIGHTS,\n",
        "                &D_MBConv_6_13_SQZ_1_WEIGHTS, &D_MBConv_6_13_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_13_PRJ_WEIGHTS,\n",
        "                MBCONV_6_13_EXPD_F_DENSITY,   MBCONV_6_13_DW_F_DENSITY, \n",
        "                MBCONV_6_13_SQZ_1_F_DENSITY,  MBCONV_6_13_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_13_PRJ_F_DENSITY,\n",
        "                ConvOut12.depth,              MBCONV_6_13_PRJ_F_DENSITY, MBCONV_6_13_DW_F_HEIGHT,\n",
        "                MBCONV_6_13_STRIDE,           MBCONV_6_13_PADDING, MBCONV_6_13_SKIP,\n",
        "                &MBConv6_13_SQZ_1_bias,       &MBConv6_13_SQZ_2_bias,\n",
        "                &MBConv6_13_EXPD_BN_MEAN,     &MBConv6_13_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_13_EXPD_BN_WEIGHTS,  &MBConv6_13_EXPD_BN_BIAS,\n",
        "                &MBConv6_13_DW_BN_MEAN,       &MBConv6_13_DW_BN_VARIANCE,\n",
        "                &MBConv6_13_DW_BN_WEIGHTS,    &MBConv6_13_DW_BN_BIAS,\n",
        "                &MBConv6_13_PRJ_BN_MEAN,      &MBConv6_13_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_13_PRJ_BN_WEIGHTS,   &MBConv6_13_PRJ_BN_BIAS);\n",
        "\n",
        "\n",
        "  Matrix ConvOut14;\n",
        "  MBConv_Layer(&ConvOut13, &ConvOut14,\n",
        "                &D_MBConv_6_14_EXPD_WEIGHTS,  &D_MBConv_6_14_DW_WEIGHTS,\n",
        "                &D_MBConv_6_14_SQZ_1_WEIGHTS, &D_MBConv_6_14_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_14_PRJ_WEIGHTS,\n",
        "                MBCONV_6_14_EXPD_F_DENSITY,   MBCONV_6_14_DW_F_DENSITY, \n",
        "                MBCONV_6_14_SQZ_1_F_DENSITY,  MBCONV_6_14_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_14_PRJ_F_DENSITY,\n",
        "                ConvOut13.depth,              MBCONV_6_14_PRJ_F_DENSITY, MBCONV_6_14_DW_F_HEIGHT,\n",
        "                MBCONV_6_14_STRIDE,           MBCONV_6_14_PADDING, MBCONV_6_14_SKIP,\n",
        "                &MBConv6_14_SQZ_1_bias, \t    &MBConv6_14_SQZ_2_bias,\n",
        "                &MBConv6_14_EXPD_BN_MEAN,     &MBConv6_14_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_14_EXPD_BN_WEIGHTS,  &MBConv6_14_EXPD_BN_BIAS,\n",
        "                &MBConv6_14_DW_BN_MEAN,       &MBConv6_14_DW_BN_VARIANCE,\n",
        "                &MBConv6_14_DW_BN_WEIGHTS,    &MBConv6_14_DW_BN_BIAS,\n",
        "                &MBConv6_14_PRJ_BN_MEAN,      &MBConv6_14_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_14_PRJ_BN_WEIGHTS,   &MBConv6_14_PRJ_BN_BIAS);  \n",
        "\n",
        "\n",
        "  Matrix ConvOut15;\n",
        "  MBConv_Layer(&ConvOut14, &ConvOut15,\n",
        "                &D_MBConv_6_15_EXPD_WEIGHTS,  &D_MBConv_6_15_DW_WEIGHTS,\n",
        "                &D_MBConv_6_15_SQZ_1_WEIGHTS, &D_MBConv_6_15_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_15_PRJ_WEIGHTS,\n",
        "                MBCONV_6_15_EXPD_F_DENSITY,   MBCONV_6_15_DW_F_DENSITY, \n",
        "                MBCONV_6_15_SQZ_1_F_DENSITY,  MBCONV_6_15_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_15_PRJ_F_DENSITY,\n",
        "                ConvOut14.depth,              MBCONV_6_15_PRJ_F_DENSITY, MBCONV_6_15_DW_F_HEIGHT,\n",
        "                MBCONV_6_15_STRIDE,           MBCONV_6_15_PADDING, MBCONV_6_15_SKIP,\n",
        "                &MBConv6_15_SQZ_1_bias,       &MBConv6_15_SQZ_2_bias,\n",
        "                &MBConv6_15_EXPD_BN_MEAN,     &MBConv6_15_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_15_EXPD_BN_WEIGHTS,  &MBConv6_15_EXPD_BN_BIAS,\n",
        "                &MBConv6_15_DW_BN_MEAN,       &MBConv6_15_DW_BN_VARIANCE,\n",
        "                &MBConv6_15_DW_BN_WEIGHTS,    &MBConv6_15_DW_BN_BIAS,\n",
        "                &MBConv6_15_PRJ_BN_MEAN,      &MBConv6_15_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_15_PRJ_BN_WEIGHTS,   &MBConv6_15_PRJ_BN_BIAS);   \n",
        "\n",
        "  // Head layer\n",
        "  Matrix HEAD_OUT;\n",
        "  HEAD_LAYER(&ConvOut15, &HEAD_CONV_WEIGHTS, &HEAD_FC_WEIGHTS,\n",
        "              HEAD_CONV_F_HEIGHT, HEAD_CONV_F_WIDTH, HEAD_CONV_F_DEPTH, HEAD_CONV_F_DENSITY,\n",
        "              0, 1,\n",
        "              &HEAD_OUT);\n",
        "  \n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// The last layer in efficient net\n",
        "void HEAD_LAYER(Matrix *INPUT_MATRIX, Matrix *F_HEAD, Matrix *FC_WEIGHTS,\n",
        "                int filter_height, int filter_width, int filter_depth, int filter_density,\n",
        "                int padding, int stride,\n",
        "                Matrix *HEAD_OUT)\n",
        "{                \n",
        "  // Calculate output dimensions       \n",
        "  int out_height = (INPUT_MATRIX -> height + 2 * padding - filter_height) / stride + 1;\n",
        "  int out_width = (INPUT_MATRIX -> width + 2 * padding - filter_width) / stride + 1;\n",
        "  int out_depth = filter_density;\n",
        "\n",
        "  Set_DeviceMatrix(out_height, out_width, out_depth, HEAD_OUT,\n",
        "                   \"Output is allocated in device memory\"); \n",
        "\n",
        "  // 1st 3 layers: Conv2d 1x1: BN: Swish()\n",
        "  Conv2d_Layer(INPUT_MATRIX,  F_HEAD, HEAD_OUT,\n",
        "              stride, padding,\n",
        "              INPUT_MATRIX -> depth, out_depth, filter_density,\n",
        "              Conv2d_1_x_1, NO_ACTIVATION,\n",
        "              0, NULL);\n",
        " \n",
        "  BN_ALL_PRE_DEFINED(HEAD_OUT, SWISH_ACTIVATION, \n",
        "                      &D_HEAD_BN_MEAN,\t&D_HEAD_BN_VARIANCE ,\n",
        "                      &D_HEAD_BN_WEIGHTS, &D_HEAD_BN_BIAS);\n",
        "\n",
        "\n",
        "  // 4th layer: Average pooling layer which is just a reduction sum layer\n",
        "  // Get mean values for all channels; Dims(1 x 1 x InputDepth)\n",
        "  \n",
        "  Matrix MEAN, Result_Mean;\n",
        "\n",
        "  Set_DeviceMatrix(HEAD_OUT -> depth,\n",
        "                    (int)ceil((double)HEAD_OUT -> height * HEAD_OUT -> width / (2 * BLOCK_SIZE)),\n",
        "                    1, \n",
        "                    &Result_Mean, \n",
        "                    \"Reesult Mean matrix allocated in device memory\");\n",
        "\n",
        "  REDUCTION_SUM(HEAD_OUT, &MEAN, &Result_Mean);\n",
        "\n",
        "\n",
        "  // 5th layer: Fully connected layer::\n",
        "\n",
        "  // Set Output matrix details\n",
        "  Matrix Out1;\n",
        "  Set_DeviceMatrix(1, 1000, 1, &Out1, \"Setting Final Model Output matrix in device memory\");\n",
        "     \n",
        "  Conv_vidMultiplier(&Out1, FC_WEIGHTS, &Result_Mean,\n",
        "                      1, 1000, 1,\n",
        "                      Conv2d_1_x_1, 1,\n",
        "                      NO_ACTIVATION, \n",
        "                      0, NULL);\n",
        "  \n",
        "  stop(\"Model: \", 0);\n",
        "  \n",
        "  Matrix tmp_out_host;\n",
        "  set_allocate_Host(&tmp_out_host, 1, 1000, 1);\n",
        "  just_copy_DTH(&tmp_out_host, &Out1, \"Copying to add bias\");\n",
        " \n",
        "  for (int i = 0; i < 1000; i++)\n",
        "  {\n",
        "    tmp_out_host.elements[i] += Head_linear_bias[i];\n",
        "  }\n",
        "\n",
        "  just_copy_HTD(&Out1, &tmp_out_host, \"Copying to add bias\");\n",
        "  show_me_enhanced_from_devince(&Out1, \"Model final output::\");\n",
        "}\n",
        "\n",
        "// The first layer in efficient net: \n",
        "// It reutnrs a pointer to matrix, its elements are allocated in device memory \n",
        "void STEM_LAYER(Matrix *DInput_Mat, Matrix *F_STEM,\n",
        "                  int image_height, int image_width, int image_depth,\n",
        "                  int filter_height, int filter_width, int filter_depth, int filter_density,\n",
        "                  int padding, int stride,\n",
        "                  Matrix *STEM_OUT)\n",
        "{\n",
        "\n",
        "  // Calculate output dimensions       \n",
        "  int out_height = (image_height + 2 * padding - filter_height) / stride + 1;\n",
        "  int out_width = (image_width + 2 * padding - filter_width) / stride + 1;\n",
        "  int out_depth = filter_density;\n",
        " \n",
        "\n",
        "  // Allow the output from this layer to go accross the next layer       \n",
        "  Set_DeviceMatrix(out_height, out_width, out_depth, STEM_OUT,\n",
        "                   \"Output is allocated in device memory\"); \n",
        " \n",
        "  Conv2d_Layer(DInput_Mat,  F_STEM, STEM_OUT,\n",
        "              stride, padding,\n",
        "              image_depth, out_depth, filter_density,\n",
        "              Regular_Conv, NO_ACTIVATION,\n",
        "              0, NULL);\n",
        " \n",
        "\n",
        "  BN_ALL_PRE_DEFINED(STEM_OUT, SWISH_ACTIVATION, \n",
        "                      &D_STEM_BN_MEAN, &D_STEM_BN_VARIANCE ,\n",
        "                      &D_STEM_BN_WEIGHTS, &D_STEM_BN_BIAS);  \n",
        "}"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/APP.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HPpV1Lk28NYo",
        "outputId": "4cf61488-fca0-4e7b-f01e-fc9822368d1f"
      },
      "source": [
        "%%cuda --name FUNCTIONS.cu \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <cusolverDn.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "#include \"/content/MBCONVS_float/functionsV2.h\"\n",
        "#include \"/content/MBCONVS_float/KERNELSH.h\"\n",
        "\n",
        "static void HandleError( cudaError_t err,\n",
        "                         char *file,\n",
        "                         int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))\n",
        "\n",
        "float time_defined = 0, tmp_time = 0, total_time_for_layer = 0;; \n",
        "cudaEvent_t start_timing, stop_timing;\n",
        "\n",
        "\n",
        "int show_out = 0;\n",
        "\n",
        "int total_constant_memory = 0;\n",
        "                \n",
        "// Device memory for filters\n",
        "void DEFINE_FILTERS_FOR_MBCONV(Matrix *D_f1, float *filter1, int h1, int w1, int dens1,\n",
        "                               Matrix *D_f2, float *filter2, int h2, int w2, int dens2,\n",
        "                               Matrix *D_f3, float *filter3, int h3, int w3, int dens3,\n",
        "                               Matrix *D_f4, float *filter4, int h4, int w4, int dens4,\n",
        "                               Matrix *D_f5, float *filter5, int h5, int w5, int dens5)\n",
        "{\n",
        "    // Note: No allocations are done, just pointers point to matrices pre-defined\n",
        "\n",
        "    // This condition is important as the float * is NULL\n",
        "    if (MBCONV1_0_flag == 1);\n",
        "    else\n",
        "      set_allocate_copy_array_Device(D_f1, filter1,\n",
        "                                    h1, w1, dens1,\n",
        "                                    \"1st filter allocated\");\n",
        " \n",
        "    set_allocate_copy_array_Device(D_f2, filter2,\n",
        "                                    h2, w2, dens2,\n",
        "                                    \"2nd filter allocated\");\n",
        " \n",
        "    set_allocate_copy_array_Device(D_f3, filter3,\n",
        "                                    h3, w3, dens3,\n",
        "                                    \"3rd filter allocated\");\n",
        "\n",
        "    set_allocate_copy_array_Device(D_f4, filter4,\n",
        "                                    h4, w4, dens4,\n",
        "                                    \"4th filter allocated\");\n",
        "\n",
        "    set_allocate_copy_array_Device(D_f5, filter5,\n",
        "                                    h5, w5, dens5,\n",
        "                                    \"5th filter allocated\");                                                         \n",
        "}\n",
        "\n",
        "// Free the device filters\n",
        "void FREE_FILTERS_FOR_MBCONV(Matrix *D_f1, Matrix *D_f2, \n",
        "                             Matrix *D_f3, Matrix *D_f4,\n",
        "                             Matrix *D_f5)\n",
        "{\n",
        "  cudaFree(D_f1 -> elements);\n",
        "  cudaFree(D_f2 -> elements);\n",
        "  cudaFree(D_f3 -> elements);\n",
        "  cudaFree(D_f4 -> elements);\n",
        "  cudaFree(D_f5 -> elements);\n",
        "}\n",
        "\n",
        "void REDUCTION_SUM(Matrix* Output_Modified, Matrix *sum, Matrix *DMean)\n",
        "{\n",
        "    /*\n",
        "      The mean will be a row vector of 1 x C;\n",
        "      where C is number of original matrix channels\n",
        "      All input matrices for this function are device matrices,\n",
        "      except for sum, it's just a transition that later can be removed \n",
        "    */\n",
        "    \n",
        "    // Define number of blocks in different directions\n",
        "    int nbx = 0;\n",
        "    int nby = 0;\n",
        "    int nbz = 1;\n",
        "\n",
        "    size_t size;\n",
        "    cudaError err;\n",
        " \n",
        "    /*\n",
        "      Load input Matrix inot device t calculate mean for it\n",
        "      Unfortionately the code requires to copy the input matrix\n",
        "    */\n",
        " \n",
        "    Matrix DInputMat;\n",
        "    // Allocate and set its dimensions as needed from the algorithm\n",
        "    Set_DeviceMatrix(Output_Modified -> depth, Output_Modified -> height * Output_Modified -> width, 1,\n",
        "                     &DInputMat, \"Copyting Input of reduction mean function into Device memory\");\n",
        "\n",
        "    // Copy input from a device memory to device memory in order to process the elements\n",
        "    size = DInputMat.height * DInputMat.width * DInputMat.depth * sizeof(float);\n",
        "    err = cudaMemcpyAsync(DInputMat.elements, Output_Modified -> elements, size, cudaMemcpyDeviceToDevice, 0);\n",
        "    CheckCudaError(\"Copying mean matrix elements from \", err);\n",
        "\n",
        "    /* Starting reduction sum calculations */\n",
        "\n",
        "    // Note: All blocks are 1D threads. We use Block.x to reduce 1 channel elements'\n",
        "    // Diffferent block.y to address different number of channels\n",
        "    nbx = (int)ceil((float)DInputMat.width / (2 * BLOCK_SIZE));\n",
        "    nby = (int)ceil((float)DInputMat.height);\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    // For loop is held to maintain huge number of summations needed\n",
        "    for (int i = 0; DInputMat.width != 1; i++)\n",
        "    {\n",
        "        dim3 dim_Grid2(nbx, nby, nbz);\n",
        "        dim3 dim_Block2(BLOCK_SIZE, 1, 1);\n",
        "\n",
        "        // Make sure to synch between multiple runs\n",
        "       //cudaDeviceSynchronize();\n",
        "        \n",
        "        BN_Kernel_Mean_Reduction <<< dim_Grid2, dim_Block2 >>> (DInputMat.elements,\n",
        "                                                                DInputMat.height,\n",
        "                                                                DInputMat.width,\n",
        "                                                                DInputMat.depth,\n",
        "                                                                DMean -> elements,\n",
        "                                                                DMean -> width);\n",
        "\n",
        "        \n",
        "        // Save and copy mean values array into the filter array\n",
        "        size = DMean -> height * DMean -> width * DMean -> depth * sizeof(float);\n",
        "        err = cudaMemcpyAsync(DInputMat.elements, DMean -> elements, size, cudaMemcpyDeviceToDevice, 0);\n",
        "        CheckCudaError(\"Copying mean matrix elements from \", err);\n",
        "\n",
        "        // Modify filter width to fit into the new elements width\n",
        "        DInputMat.width = nbx;\n",
        "        DInputMat.height = nby;\n",
        "\n",
        "        // Recalculate number of blocks in x direction\n",
        "        nbx = (int)ceil((float)DInputMat.width / (2 * BLOCK_SIZE));\n",
        "        nby = (int)ceil((float)DInputMat.height);\n",
        "\n",
        "        if (nbx == 0) nbx = 1;\n",
        "        if (nby == 0) nby = 1;\n",
        "\n",
        "        // Set width of mean matrix to the new number of blocks\n",
        "        DMean -> width = nbx;\n",
        "        DMean -> height = nby;\n",
        "    }\n",
        "    \n",
        "    // Set mean matrix to 1 X C X 1 to ease further calculations\n",
        "    DMean -> height = 1; DMean -> width = Output_Modified -> depth; DMean -> depth = 1;\n",
        "    \n",
        "    nbx = (int)ceil((float)DMean -> width / 1024);\n",
        "    \n",
        "    dim3 dim_Grid2(nbx, 1, 1);\n",
        "    dim3 dim_Block2(1024, 1, 1);\n",
        "    CastingDivision <<<dim_Grid2, dim_Block2>>> (DMean -> elements, DMean -> width, \n",
        "                                                 Output_Modified->height * Output_Modified->width);\n",
        "}\n",
        "\n",
        "\n",
        "/*  Squeeze_and_Excite(&tmp2, &SE_OUT, F3, F4,\n",
        "                      FD4, FD3, FD4, FD3);\n",
        "                      */\n",
        "// Note: input and output channels args represents the 2 Conv layers output channels respectively\n",
        "void Squeeze_and_Excite(Matrix* InputIMG, Matrix* Result,\n",
        "                        Matrix* Filter1, Matrix* Filter2,\n",
        "                        int FilterDensity2, int FilterDensity1,\n",
        "                        int input_channels, int output_channels,\n",
        "                        Matrix * First_bias, Matrix *Second_bias)\n",
        "{\n",
        "    /*\n",
        "       Steps in squeeze and excite layer:\n",
        "        1. Get mean value for a tensor\n",
        "        2. pass the mean to the covolution, swish, convolution, sigmoid\n",
        "        3. the result will be a 1 x 1 x C, multiply elementwise.\n",
        "          \"each element in a channel is multiplied by the result's corresponding channel element\"\n",
        "        \n",
        "        Filter Density means #filters used\n",
        " \n",
        "      Note: All input matrices are device allocated matrices\n",
        "    */\n",
        "\n",
        " \n",
        "    /*\n",
        "      Get mean values for all channels; Dims(1 x InputDepth x 1) \n",
        "      Note: Mean matrix is a host allocated memory in REDUCTION_SUM;\n",
        "            It's used to get the final summation from device and\n",
        "            then divide each element sequentially by total number \n",
        "            of elements. It's then later copied back to Result_Mean\n",
        "            Matrix which is a device matrix.\n",
        "            \"This can be later changed\"\n",
        "    */\n",
        " \n",
        "    Matrix MEAN, Result_Mean;\n",
        "\n",
        "    Set_DeviceMatrix(InputIMG -> depth,\n",
        "                      (int)ceil((double)InputIMG -> height * InputIMG -> width / (2 * BLOCK_SIZE)),\n",
        "                      1, \n",
        "                      &Result_Mean, \n",
        "                      \"Reesult Mean matrix allocated in device memory\");\n",
        "\n",
        "    REDUCTION_SUM(InputIMG, &MEAN, &Result_Mean);\n",
        " \n",
        "\n",
        "    // Tmp1 is used as a transition between 2 convolution layers; Dims(1 x 1 x FilterDensity3)\n",
        "    Matrix tmp1;\n",
        "    Set_DeviceMatrix(1, 1, FilterDensity1, &tmp1, \"Allocating tmp1 in device for transition\");\n",
        " \n",
        "    // tmp2 matrix is the result from sigmoid function: Dims(1 x 1 x FilterDensity4)\n",
        "    Matrix tmp2;\n",
        "    Set_DeviceMatrix( 1, 1, FilterDensity2, &tmp2, \"Allocating tmp2 in device for final output\");\n",
        " \n",
        "    // Sequence: Conv1x1, swish, Conv1x1, sigmoid \n",
        "    // Warning: Remember to pre-process Result_Mean matrix to match 1 x 1 x C as it's the input in this case to Conv2d\n",
        "    Set_HostMatrix(1, 1, InputIMG -> depth, &Result_Mean);\n",
        " \n",
        "    Conv2d_Layer(&Result_Mean, Filter1, &tmp1, 1, 0, input_channels, output_channels, FilterDensity1,\n",
        "                 Conv2d_1_x_1, SWISH_ACTIVATION,\n",
        "                 BIASED, First_bias);\n",
        "    \n",
        "    Conv2d_Layer(&tmp1, Filter2, &tmp2, 1, 0, output_channels, input_channels, FilterDensity2,\n",
        "                 Conv2d_1_x_1, SIGMOID_ACTIVATION,\n",
        "                 BIASED, Second_bias);\n",
        " \n",
        "\n",
        "    int nbx = (int)ceil((float)InputIMG -> width / DYNAMIC_TILE);\n",
        "    int nby = (int)ceil((float)InputIMG -> height / DYNAMIC_TILE);\n",
        "    int nbz = InputIMG -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    // This is the only kernel that runs 3d Grid; \n",
        "    // Each block in z dimension controls 1 channel  \n",
        "    dim3 dim_Grid2(nbx, nby, nbz);\n",
        "    dim3 dim_Block2(DYNAMIC_TILE, DYNAMIC_TILE, 1);\n",
        "\n",
        "    // C then D, the final multiplication is in C matrix\n",
        "    ConvChannelElementWiseMultiplication <<< dim_Grid2, dim_Block2 >>> (InputIMG -> elements,\n",
        "                                                                        InputIMG -> height,\n",
        "                                                                        InputIMG -> width,\n",
        "                                                                        InputIMG -> depth,\n",
        "                                                                        tmp2.elements);\n",
        "\n",
        "   \n",
        "    cudaFree(tmp1.elements);\n",
        "    cudaFree(tmp2.elements);\n",
        "}\n",
        "\n",
        "// Warning: Fuction Input matrices are allocated in device memory directly\n",
        "// InputIMG, FilterK and ConvOut are device memory allocations\n",
        "void Conv2d_Layer(Matrix* InputIMG, Matrix* FilterK, Matrix* ConvOut,\n",
        "                  int stride, int padding,\n",
        "                  int InputChannels, int OutputChannels, int FilterDensity,\n",
        "                  int Conv_Type, int activation_type,\n",
        "                  int BIASED_CHOISE, Matrix *biasMat)\n",
        "{\n",
        "    //printf(\"The start of Conv2d layer\\n\\n\");\n",
        "    \n",
        "    int OutputHeight = 0, OutputWidth = 0, OutputDepth = 0;\n",
        "\n",
        "    // 1x1 Conv2d is a special case of Convolution\n",
        "    if (Conv_Type == Conv2d_1_x_1)\n",
        "    {\n",
        "        // Conv2d 1x1 has stride = 1, no padding and K = 1\n",
        "\n",
        "        /*\n",
        "          Input Dimensions is the same as Output dimensions\n",
        "          Only Depth of the output channels differ from input\n",
        "        */\n",
        "        OutputHeight = InputIMG -> height; OutputWidth = InputIMG -> width; OutputDepth = FilterDensity;\n",
        "\n",
        "        /*\n",
        "          Note: Set_HostMatrix function just changes the dimensions\n",
        "                so it's okey to use on a device memory\n",
        "        */\n",
        "     \n",
        "        // Modify Filter Matrix to have dimensions ((K^2 * M) x C x 1); K = 1\n",
        "        Set_HostMatrix(1 * 1 * FilterDensity, InputIMG -> depth, 1, FilterK);\n",
        "\n",
        "        // Modify Input matrix to have dimensions (C x (H * W) x 1)\n",
        "        Set_HostMatrix(InputIMG -> depth, InputIMG -> height * InputIMG -> width, 1, InputIMG);\n",
        "\n",
        "        // Modify Output Matrix preprocessing to have dimesions ((K^2 * M) x (H * W) x 1); K = 1\n",
        "        Set_HostMatrix(1 * 1 * FilterDensity, OutputWidth * OutputHeight, 1, ConvOut);\n",
        "\n",
        "        Conv_vidMultiplier(ConvOut, InputIMG, FilterK,\n",
        "                            OutputHeight, OutputWidth, OutputDepth,\n",
        "                            Conv2d_1_x_1, 1,\n",
        "                            activation_type, \n",
        "                            BIASED_CHOISE, biasMat);\n",
        "    }\n",
        "    else if (Conv_Type == DWConv_k_x_k)\n",
        "    {\n",
        "        // Ptr is used to alternate between input image and padding if needed\n",
        "        Matrix* ptr = InputIMG;\n",
        "\n",
        "        // DWConv2d has stride = s, padding = p and kernel = k\n",
        "        OutputHeight = ConvOut -> height; OutputWidth = ConvOut -> width; OutputDepth = ConvOut -> depth;\n",
        "\n",
        "        Matrix padded_matr;\n",
        "        if (padding != 0)\n",
        "        {\n",
        "            Padding_Zeros_Function(InputIMG, padding, &padded_matr);\n",
        "            ptr = &padded_matr;\n",
        "        }\n",
        "       \n",
        "        Conv_vidMultiplier(ConvOut, ptr, FilterK,\n",
        "                            OutputHeight, OutputWidth, OutputDepth,\n",
        "                            DWConv_k_x_k, stride,\n",
        "                            activation_type, \n",
        "                            BIASED_CHOISE, biasMat);\n",
        "\n",
        "        // Padded matrix is no longer needed as Convout has the final result\n",
        "    }\n",
        "    // Any other kernel size goes here\n",
        "    else\n",
        "    {        \n",
        "        // Regular convolution: Filter and input unrolling\n",
        "        Matrix* ptr = InputIMG;\n",
        "        OutputHeight = (ptr -> height + 2 * padding - FilterK -> height) / stride + 1;\n",
        "        OutputWidth = (ptr -> width + 2 * padding - FilterK -> width) / stride + 1;\n",
        "        OutputDepth = FilterDensity;\n",
        "\n",
        "        Matrix padded_matr;\n",
        "        if (padding != 0)\n",
        "        {\n",
        "            Padding_Zeros_Function(InputIMG, padding, &padded_matr);\n",
        "            ptr = &padded_matr;          \n",
        "        }\n",
        "\n",
        "        // 1st phase: Filter unrolling\n",
        "\n",
        "        // Unrolled filter has dimesnios (M x (C * k * k) x 1)\n",
        "        Set_HostMatrix(FilterDensity, FilterK -> depth / FilterDensity * FilterK -> height * FilterK -> width,\n",
        "                      1, FilterK);\n",
        "\n",
        "        // 2nd phase: Input unrolling\n",
        "\n",
        "        // The unrolled Input matrix has dimensions((C * k * k) x (H_out * W_out) x 1)\n",
        "        Matrix INPUT_MODIFIED;\n",
        "        \n",
        "        Set_DeviceMatrix(ptr -> depth * 3 * 3,\n",
        "                        OutputHeight * OutputWidth, 1,\n",
        "                        &INPUT_MODIFIED, \n",
        "                        \"Input unrolled Matrix allocated in device memory\");\n",
        "\n",
        "        Input_Unroll_gpu(stride, ptr, &INPUT_MODIFIED, OutputHeight, OutputWidth, 3);\n",
        "\n",
        "        // Convolution output has dimensions of (M x (H_out * W_out) x 1)\n",
        "        Set_HostMatrix(FilterDensity, OutputWidth * OutputHeight, 1, ConvOut);\n",
        "\n",
        "          \n",
        "        // Perform Multiplication and re-edit the dimensions of output\n",
        "        Conv_vidMultiplier(ConvOut, &INPUT_MODIFIED, FilterK,\n",
        "                            OutputHeight, OutputWidth, OutputDepth,\n",
        "                            Regular_Conv, stride,\n",
        "                            activation_type,\n",
        "                            BIASED_CHOISE, biasMat);\n",
        "\n",
        "    }\n",
        " }\n",
        "\n",
        "// 5 Filters needed to run the 4 layers sequentially\n",
        "void MBConv_Layer(Matrix* Input, Matrix* MBConvOut,\n",
        "    Matrix* F1, Matrix* F2, Matrix* F3, Matrix* F4, Matrix* F5,\n",
        "    int FD1, int FD2, int FD3, int FD4, int FD5,\n",
        "    int input_channels, int output_channels, int FilterSizeDW,\n",
        "    int Stride, int padding, int skip,\n",
        "    Matrix *bias1, Matrix *bias2,\n",
        "    Matrix *MBConv_expansion_conv_BN_mean,     Matrix *MBConv_expansion_conv_BN_variance,\n",
        "    Matrix *MBConv_expansion_conv_BN_weights,  Matrix *MBConv_expansion_conv_BN_bias,\n",
        "    Matrix *MBConv_depthwise_conv_BN_mean,     Matrix *MBConv_depthwise_conv_BN_variance,\n",
        "    Matrix *MBConv_depthwise_conv_BN_weights,  Matrix *MBConv_depthwise_conv_BN_bias,\n",
        "    Matrix *MBConv_project_conv_BN_mean,       Matrix *MBConv_project_conv_BN_variance,\n",
        "    Matrix *MBConv_project_conv_BN_weights,    Matrix *MBConv_project_conv_BN_bias)\n",
        "{\n",
        "    /*\n",
        "      Note: MBConv1_0 doesn't have the expansion conv function;\n",
        "            The input matrices to this function are device matrices;\n",
        "            including all the filters, you don't need to allocate or\n",
        "            copy any thing; just pass to the functions\n",
        "    */\n",
        "\n",
        "    /*\n",
        "      ptr_mat is the pointer that gets past expansion conv;\n",
        "      Meaning: in case of MBconv1_0 the pointer is same as input matrix;\n",
        "                in case of any other MBConv6_! it's the output of Conv2d \n",
        "                and BN with swish\n",
        "    */\n",
        "    \n",
        "    Matrix H_OUT;\n",
        "    Matrix tmp1; Matrix *ptr_mat; \n",
        " \n",
        "    if (MBCONV1_0_flag == 1)\n",
        "      ptr_mat = Input;\n",
        "    else\n",
        "    {     \n",
        "      Set_DeviceMatrix(Input -> height, Input -> width , FD1, \n",
        "                       &tmp1,\n",
        "                       \"Output_1 is allocated in device memory\"); \n",
        "               \n",
        "      // 1st layer: 1x1 Conv2d, stride = 1, padding = 0, K = 1\n",
        "      Conv2d_Layer(Input, F1, &tmp1, 1, 0,\n",
        "                   input_channels, FD1, FD1,\n",
        "                   Conv2d_1_x_1,\n",
        "                   NO_ACTIVATION, 0, NULL);\n",
        "  \n",
        "      BN_ALL_PRE_DEFINED(&tmp1, SWISH_ACTIVATION, \n",
        "                          MBConv_expansion_conv_BN_mean,    MBConv_expansion_conv_BN_variance,\n",
        "                          MBConv_expansion_conv_BN_weights, MBConv_expansion_conv_BN_bias);\n",
        "      ptr_mat = &tmp1;\n",
        "    }\n",
        "\n",
        "   // 2nd Layer: KxK DWconv, stride = s, padding = p, K = k\n",
        "\n",
        "    // Height and width changes, Only depth remains still\n",
        "    int OutputHeight = (ptr_mat -> height + 2 * padding - FilterSizeDW)/Stride + 1;\n",
        "    int OutputWidth = (ptr_mat -> width + 2 * padding - FilterSizeDW)/Stride + 1;\n",
        "    int OutputDepth = ptr_mat -> depth;\n",
        " \n",
        "    // Set and allocate tmp2 matrix; it's a transistion between expansion and squeeze\n",
        "    Matrix tmp2;\n",
        "    Set_DeviceMatrix(OutputHeight, OutputWidth, OutputDepth, &tmp2,\n",
        "                    \"Output_2 is allocated in device memory\");    \n",
        "\n",
        "    Conv2d_Layer(ptr_mat, F2, &tmp2,\n",
        "                 Stride, padding, FD1, FD2, FD2, DWConv_k_x_k,\n",
        "                 NO_ACTIVATION, 0, NULL);\n",
        "  \n",
        "\n",
        "    BN_ALL_PRE_DEFINED(&tmp2, SWISH_ACTIVATION, \n",
        "                       MBConv_depthwise_conv_BN_mean,     MBConv_depthwise_conv_BN_variance,\n",
        "                       MBConv_depthwise_conv_BN_weights,  MBConv_depthwise_conv_BN_bias);\n",
        "  \n",
        "    // 3rd Layer: squeeze and excitation\n",
        "\n",
        "    /*\n",
        "      Squeeze excite layer doesn't change the final output dimensions;\n",
        "      SE_OUT can be removed; Do so later\n",
        "    */\n",
        " \n",
        "    Matrix *SE_OUT;\n",
        "    Squeeze_and_Excite(&tmp2, SE_OUT, F3, F4,\n",
        "                        FD4, FD3, FD4, FD3,\n",
        "                        bias1, bias2);\n",
        "\n",
        "    // 4th Layer: 1x1 Conv2d\n",
        "    // MBConv output pointer is set and finally updated after this layer execution\n",
        "    Set_DeviceMatrix(tmp2.height, tmp2.width, FD5, MBConvOut,\n",
        "                     \"Matrix final output is allocated in device memory\");\n",
        " \n",
        "\n",
        "    // 1x1 Conv2d layer\n",
        "    Conv2d_Layer(&tmp2, F5, MBConvOut, 1, 0, FD4, FD5, FD5, Conv2d_1_x_1,\n",
        "                 NO_ACTIVATION, 0, NULL);\n",
        "\n",
        "\n",
        "    // BatchNorm layer\n",
        "    BN_ALL_PRE_DEFINED(MBConvOut, NO_ACTIVATION, \n",
        "                       MBConv_project_conv_BN_mean,     MBConv_project_conv_BN_variance,\n",
        "                       MBConv_project_conv_BN_weights,  MBConv_project_conv_BN_bias);\n",
        "\n",
        "    // Skip identity layer\n",
        "    if(skip)\n",
        "    {\n",
        "      MBConv_SKIP_IDENTITY(MBConvOut, Input);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "void MBConv_SKIP_IDENTITY(Matrix *parent, Matrix *child)\n",
        "{\n",
        "    int nbx = (int)ceil((float)parent -> width / DYNAMIC_TILE);\n",
        "    int nby = (int)ceil((float)parent -> height / DYNAMIC_TILE);\n",
        "    int nbz = parent -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    // This is the only kernel that runs 3d Grid; \n",
        "    // Each block in z dimension controls 1 channel  \n",
        "    dim3 dim_Grid2(nbx, nby, nbz);\n",
        "    dim3 dim_Block2(DYNAMIC_TILE, DYNAMIC_TILE, 1);\n",
        "     \n",
        "    Identity_Skip <<<dim_Grid2, dim_Block2 >>> (parent -> elements,\n",
        "                                                  parent -> height,\n",
        "                                                  parent -> width,\n",
        "                                                  parent -> depth, \n",
        "                                                  child -> elements);\n",
        "}\n",
        "\n",
        "void BN_ALL_PRE_DEFINED(Matrix* D_input, int activate, Matrix *mean, Matrix *variance, Matrix *weights, Matrix *bias)\n",
        "{\n",
        "    /* The ptr matrix is a device matrix */\n",
        "     \n",
        "    /*\n",
        "      All weights, bias, running mean and running variance\n",
        "      are pre-defined. Just call the function and use the\n",
        "      matrices.\n",
        "      \n",
        "      All bias, weights, mean and bariance matrices are 1x1xC\n",
        "\n",
        "      Output Matrix is modified by the equation\n",
        "      (y = ((x - Mean) / (sqrt(variance) + epsilon)) * weights + bais)\n",
        "    */\n",
        "\n",
        "    int nbx = (int)ceil((float)D_input -> width / DYNAMIC_TILE);\n",
        "    int nby = (int)ceil((float)D_input -> height / DYNAMIC_TILE);\n",
        "    int nbz = D_input -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    // This is the only kernel that runs 3d Grid; \n",
        "    // Each block in z dimension controls 1 channel  \n",
        "    dim3 dim_Grid3(nbx, nby, nbz);\n",
        "    dim3 dim_Block3(DYNAMIC_TILE, DYNAMIC_TILE, 1);\n",
        "\n",
        "    BN_Kernel_Final_Layer <<< dim_Grid3, dim_Block3 >>> (D_input -> elements,\n",
        "                                                         D_input -> height,\n",
        "                                                         D_input -> width,\n",
        "                                                         D_input -> depth,\n",
        "                                                         mean -> elements, variance -> elements,\n",
        "                                                         weights -> elements, bias -> elements,\n",
        "                                                         activate);\n",
        "}\n",
        "\n",
        "void Padding_Zeros_Function(Matrix* Original_Matrix_Before, int padding_Value, Matrix* padded_Matrix)\n",
        "{\n",
        "    /* \n",
        "      Note: Matrix coming is a device elemente matrix;\n",
        "            Original Matrix is a Device input that needs padding\n",
        "            padded_Matrix is the return of this function;\n",
        "\n",
        "      Warning: Padded_Matrix has a different size than the Original \n",
        "                non padded matrix and it's not allocated in device yet.\n",
        "                The allocateion is done inside this function.\n",
        "    */    \n",
        "\n",
        "    Set_DeviceMatrix(Original_Matrix_Before->height + 2 * padding_Value,\n",
        "                      Original_Matrix_Before->width + 2 * padding_Value,\n",
        "                      Original_Matrix_Before->depth,\n",
        "                      padded_Matrix,\n",
        "                      \"Padded Matrix is allocated in device memory.\");\n",
        "\n",
        "    // 1st: Set padded Matrix with all zeros\n",
        "    cudaMemset(padded_Matrix -> elements,\n",
        "               0, padded_Matrix->height * padded_Matrix->width * padded_Matrix->depth * sizeof(float)); \n",
        "\n",
        "    int nbx = (int)ceil((float)padded_Matrix -> width / DYNAMIC_TILE);\n",
        "    int nby = (int)ceil((float)padded_Matrix -> height / DYNAMIC_TILE);\n",
        "    int nbz = padded_Matrix -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    dim3 dim_Grid2(nbx, nby, nbz);\n",
        "    dim3 dim_Block2(DYNAMIC_TILE, DYNAMIC_TILE, 1);\n",
        "\n",
        "    // Pass to the copying strided kernel to complete the padding process\n",
        " \n",
        "    Complete_Padding_Process <<< dim_Grid2, dim_Block2 >>> (padded_Matrix -> elements,\n",
        "                                                            padded_Matrix -> height,\n",
        "                                                            padded_Matrix -> width,\n",
        "                                                            padded_Matrix -> depth,\n",
        "                                                            Original_Matrix_Before -> elements,\n",
        "                                                            Original_Matrix_Before -> height,\n",
        "                                                            Original_Matrix_Before -> width,\n",
        "                                                            Original_Matrix_Before -> depth,\n",
        "                                                            padding_Value);\n",
        "}\n",
        "\n",
        "\n",
        "// Call this function directly for 1x1 conv2d. Don't call for DWConv\n",
        "void Conv_vidMultiplier(Matrix* out_11, Matrix* D_2, Matrix* D_1,\n",
        "                        int ReconstructOutHieght, int ReconstructOutWidth, int ReconstructOutDepth,\n",
        "                        int ConvType, int stride_DW, int activation_type, int BIASED_CHOISE, Matrix *biasMat)\n",
        "{\n",
        "    /* Note: Out_11, XXX_Trans and Host_Conv_Filter are device matrices */\n",
        " \n",
        "    // The multiplication kernel is used for the 1x1 Conv2d and kxk Conv2d\n",
        "    if (ConvType == Conv2d_1_x_1 || ConvType == Regular_Conv)\n",
        "    {    \n",
        "        // Get number of blocks\n",
        "        int nbx = (int)ceil((float)out_11 -> width / (THREAD_GRANULARITY_BLOCKS * Tile_GEMM));\n",
        "        int nby = (int)ceil((float)out_11 -> height / Tile_GEMM);\n",
        "        int num_block_for_phases = (int)ceil((float)D_1 -> width / Tile_GEMM);\n",
        "\n",
        "        // Check for zero blocks to make sure code runs correctly\n",
        "        if (nbx == 0) nbx = 1;\n",
        "        if (nby == 0) nby = 1;\n",
        "\n",
        "        dim3 dim_Grid2(nbx, nby, 1);\n",
        "        dim3 dim_Block2(Tile_GEMM, Tile_GEMM, 1);\n",
        "     \n",
        "        if (BIASED_CHOISE == BIASED)\n",
        "        {\n",
        "          Set_HostMatrix(out_11 -> height, 1, 1, biasMat);\n",
        "\n",
        "          // Call shared memory tiled Multiplication  algorithm\n",
        "          MatrixMulKernel <<< dim_Grid2, dim_Block2 >>> (D_1 -> elements, D_1 -> height, D_1 -> width, D_1 -> depth,\n",
        "                                                         D_2 -> elements, D_2 -> height, D_2 -> width, D_2 -> depth,\n",
        "                                                         out_11 -> elements, out_11 -> height, out_11 -> width, out_11 -> depth,\n",
        "                                                         num_block_for_phases, activation_type,\n",
        "                                                         BIASED_CHOISE, biasMat -> elements);         \n",
        "        }\n",
        "        else\n",
        "        {\n",
        "          MatrixMulKernel <<< dim_Grid2, dim_Block2 >>> (D_1 -> elements, D_1 -> height, D_1 -> width, D_1 -> depth,\n",
        "                                                         D_2 -> elements, D_2 -> height, D_2 -> width, D_2 -> depth,\n",
        "                                                         out_11 -> elements, out_11 -> height, out_11 -> width, out_11 -> depth,\n",
        "                                                         num_block_for_phases, activation_type,\n",
        "                                                         BIASED_CHOISE, NULL);        \n",
        "         }    \n",
        "    }\n",
        "\n",
        "    // This case is for DWConv2d\n",
        "    else\n",
        "    {\n",
        "        int nbx = (int)ceil((float)out_11 -> width / TileDW);\n",
        "        int nby = (int)ceil((float)out_11 -> height / TileDW);\n",
        "        int nbz = out_11 -> depth;\n",
        "     \n",
        "        if (nbx == 0) nbx = 1;\n",
        "        if (nby == 0) nby = 1;\n",
        "\n",
        "        // This is the only kernel that runs 3d Grid; \n",
        "        // Each block in z dimension controls 1 channel  \n",
        "        dim3 dim_Grid2(nbx, nby, nbz);\n",
        "        dim3 dim_Block2(TileDW, TileDW, 1);\n",
        "\n",
        "\n",
        "        DWConv2d_kernel << < dim_Grid2, dim_Block2 >> > (D_2 -> elements, D_2 -> height, D_2 -> width, D_2 -> depth,\n",
        "                                                         D_1 -> elements, D_1 -> height, D_1 -> width, D_1 -> depth,\n",
        "                                                         out_11 -> elements, out_11 -> height, out_11 -> width, out_11 -> depth,\n",
        "                                                         stride_DW);          \n",
        "    }\n",
        " \n",
        "    // Reset the output dimensions to continue in the network\n",
        "    Set_HostMatrix(ReconstructOutHieght, ReconstructOutWidth, ReconstructOutDepth, out_11);\n",
        "}\n",
        "\n",
        "void Input_Unroll_gpu(int st_stride, Matrix* Device_Input, Matrix* Device_Unrolled, int O_H, int O_W, int Filter_Size)\n",
        "{   \n",
        "    /* Note: All the function input matrices are device matrices.\n",
        "            Device_Input matrix is already allocated and ready.\n",
        "            Device_Unrolled matrix is already allocated and ready. \n",
        "    */\n",
        "    \n",
        "    int nbx = (int)ceil((float)O_W / TileDW);\n",
        "    int nby = (int)ceil((float)O_H / TileDW);\n",
        "    int nbz = Device_Input -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "\n",
        "    if (nby == 0) nby = 1;\n",
        " \n",
        "    dim3 dim_Grid2(nbx, nby, nbz);\n",
        "    dim3 dim_Block2(TileDW, TileDW, 1);\n",
        "\n",
        "    // You need to use cudaDeviceSynchronize if the kernel isn't working\n",
        "\n",
        "    INPUT_UNROLLING <<< dim_Grid2, dim_Block2 >>> (st_stride, Filter_Size,\n",
        "                                                   \n",
        "                                                   Device_Input -> elements,\n",
        "                                                   Device_Input -> height,\n",
        "                                                   Device_Input -> width,\n",
        "                                                   Device_Input -> depth,\n",
        "\n",
        "                                                   Device_Unrolled -> elements,\n",
        "                                                   Device_Unrolled -> height,\n",
        "                                                   Device_Unrolled -> width,\n",
        "                                                   Device_Unrolled -> depth,\n",
        "\n",
        "                                                   O_H, O_W);\n",
        "\n",
        "    \n",
        "    //cudaDeviceSynchronize(); \n",
        "\n",
        "    cudaError err = cudaGetLastError();\n",
        "\n",
        "    if ( err != cudaSuccess )\n",
        "    {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "      exit(-1);\n",
        "    } \n",
        "}\n",
        "\n",
        "void DEFINE_FILTERS_FOR_MBCONV_BN(  Matrix *EXP_MEAN, \t\t  float *filter1, int size_1,\n",
        "                                    Matrix *EXP_VARIANCE, \tfloat *filter2, int size_2,\n",
        "                                    Matrix *EXP_WEIGHTS, \t  float *filter3, int size_3,\n",
        "                                    Matrix *EXP_BIAS, \t\t  float *filter4, int size_4,\n",
        "                                  \n",
        "                                    Matrix *DW_MEAN, \t\t    float *filter5, int size_5,\n",
        "                                    Matrix *DW_VARIANCE, \t  float *filter6, int size_6,\n",
        "                                    Matrix *DW_WEIGHTS, \t\tfloat *filter7, int size_7,\n",
        "                                    Matrix *DW_BIAS, \t\t    float *filter8, int size_8,\n",
        "                                    \n",
        "                                    Matrix *PRJ_MEAN, \t\t  float *filter9,  int size_9,\n",
        "                                    Matrix *PRJ_VARIANCE, \tfloat *filter10, int size_10,\n",
        "                                    Matrix *PRJ_WEIGHTS, \t  float *filter11, int size_11,\n",
        "                                    Matrix *PRJ_BIAS, \t\t  float *filter12, int size_12)\n",
        "{\n",
        "  if (MBCONV1_0_flag);\n",
        "  else\n",
        "  {\n",
        "    set_allocate_copy_array_Device(EXP_MEAN, filter1,\n",
        "                      size_1, 1, 1,\n",
        "                      \"expand mean\"); \n",
        "    set_allocate_copy_array_Device(EXP_VARIANCE, filter2,\n",
        "                      size_2, 1, 1,\n",
        "                      \"expand variance\"); \n",
        "    set_allocate_copy_array_Device(EXP_WEIGHTS, filter3,\n",
        "                      size_3, 1, 1,\n",
        "                      \"expand weights\"); \n",
        "    set_allocate_copy_array_Device(EXP_BIAS, filter4,\n",
        "                      size_4, 1, 1,\n",
        "                      \"expand bias\");\n",
        "  } \n",
        "\t\t\t\t\t\t\t\t\t  \n",
        "\tset_allocate_copy_array_Device(DW_MEAN, filter5,\n",
        "\t\t\t\t\t\t\t\t\t  size_5, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW mean\"); \n",
        "\tset_allocate_copy_array_Device(DW_VARIANCE, filter6,\n",
        "\t\t\t\t\t\t\t\t\t  size_6, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW variance\"); \n",
        "\tset_allocate_copy_array_Device(DW_WEIGHTS, filter7,\n",
        "\t\t\t\t\t\t\t\t\t  size_7, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW weights\"); \n",
        "\tset_allocate_copy_array_Device(DW_BIAS, filter8,\n",
        "\t\t\t\t\t\t\t\t\t  size_8, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"expand bias\"); \n",
        "\n",
        "\tset_allocate_copy_array_Device(PRJ_MEAN, filter9,\n",
        "\t\t\t\t\t\t\t\t\t  size_9, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW mean\"); \n",
        "\tset_allocate_copy_array_Device(PRJ_VARIANCE, filter10,\n",
        "\t\t\t\t\t\t\t\t\t  size_10, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW variance\"); \n",
        "\tset_allocate_copy_array_Device(PRJ_WEIGHTS, filter11,\n",
        "\t\t\t\t\t\t\t\t\t  size_11, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW weights\"); \n",
        "\tset_allocate_copy_array_Device(PRJ_BIAS, filter12,\n",
        "\t\t\t\t\t\t\t\t\t  size_12, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"expand bias\"); \n",
        "}\n",
        "\n",
        "// 3 Sequential Operations: Same as \"set_allocate_copy_Matrix_Device\",\n",
        "// However, it uses a pointer to float as a parent.\n",
        "void set_allocate_copy_array_Device(Matrix *child, float *parent,\n",
        "\t\t\t\t\t\t\t\t\tint height, int width, int depth,\n",
        "\t\t\t\t\t\t\t\t\tchar *notification)\n",
        "{\n",
        "\tSet_DeviceMatrix(height, width, depth, child, notification);\n",
        "\n",
        "\tsize_t size = height * width * depth * sizeof(float);\n",
        " \n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent, size,\n",
        "\t\t\t\t\t\t\t\tcudaMemcpyHostToDevice);\n",
        "  \n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "// 3 Sequential Operations: Set dimensions, allocate device memory and copy.\n",
        "void set_allocate_copy_Matrix_Device(Matrix *child, Matrix *parent, char *notification)\n",
        "{\n",
        "\tSet_DeviceMatrix(parent -> height, parent -> width, parent -> depth,\n",
        "\t\t\t\t\t          child, notification);\n",
        "\n",
        "\tsize_t size = parent -> height * parent -> width * parent -> depth * sizeof(float);\n",
        "\t\n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent -> elements,\n",
        "\t\t\t\t\t\t\t\t              size, cudaMemcpyHostToDevice);\n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "void set_allocate_copy_Matrix_Device_specific(Matrix *child, Matrix *parent, char *notification, int height, int width, int depth)\n",
        "{\n",
        "\tSet_DeviceMatrix(height, width, depth, child, notification);\n",
        "\n",
        "\tsize_t size = child -> height * child -> width * child -> depth * sizeof(float);\n",
        "\t\n",
        "\n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent -> elements,\n",
        "\t\t\t\t\t\t\t\t            size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  \n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "void just_copy_HTD(Matrix *child, Matrix *parent, char *notification)\n",
        "{\n",
        "    // Read C from device memory\n",
        "  size_t size = parent -> width * parent -> height * parent -> depth * sizeof(float);\n",
        "    \n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent -> elements, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  \n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "void just_copy_DTH(Matrix *child, Matrix *parent, char *notification)\n",
        "{\n",
        "  // Read C from device memory\n",
        "  size_t size = parent -> width * parent -> height * parent -> depth * sizeof(float);\n",
        "  \n",
        "\n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent -> elements, size, cudaMemcpyDeviceToHost);\n",
        "  \n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "void set_allocate_Host(Matrix *ptr, int height, int width, int depth)\n",
        "{\n",
        "\t// Note this function allocates memory, remember to free \n",
        "\tSet_HostMatrix(height, width, depth, ptr);\n",
        "\t\n",
        "\tint Fsize = height * width * depth* sizeof(float);\n",
        " \n",
        "\tptr -> elements = (float *) malloc(Fsize);\n",
        "}\n",
        "\n",
        "void FreeHost_Allocated(Matrix *ptr)\n",
        "{\n",
        "\tfree(ptr -> elements);\n",
        "}\n",
        "\n",
        "// Allocations for Device matrices\n",
        "void Set_DeviceMatrix(int height, int width, int depth, Matrix* ptr, char* NamePtr)\n",
        "{\n",
        "    ptr->width = width;\n",
        "    ptr->height = height;\n",
        "    ptr->depth = depth;\n",
        "\n",
        "    size_t size = width * height * depth * sizeof(float);\n",
        "    cudaError err = cudaMalloc((void **)&(ptr->elements), size);\n",
        "    CheckCudaError(NamePtr, err);\n",
        "}\n",
        "\n",
        "void Set_HostMatrix(int height, int width, int depth, Matrix* ptr)\n",
        "{\n",
        "    ptr->width = width;\n",
        "    ptr->height = height;\n",
        "    ptr->depth = depth;\n",
        "}\n",
        "\n",
        "void CheckCudaError(char* ptr, cudaError err)\n",
        "{\n",
        "    if (err == cudaSuccess);\n",
        "    else\n",
        "        printf(\"CUDA error in %s: %s\\n\", ptr, cudaGetErrorString(err));\n",
        "}\n",
        "\n",
        "\n",
        "void show_me_enhanced(Matrix* ptr, char* NamePtr)\n",
        "{\n",
        "    if(show_out == 1)\n",
        "    {\n",
        "      setvbuf(stdout, NULL, _IOLBF, 0);\n",
        "\n",
        "          printf(\"%s,\"\n",
        "              \"it has height = %d, \"\n",
        "              \"width = %d, \"\n",
        "              \"depth = %d \\n\",\n",
        "              NamePtr, ptr->height, ptr->width, ptr->depth);\n",
        "\n",
        "          printf(\"{\\n\");\n",
        "          for (int i = 0; i < ptr -> height * ptr -> width * ptr -> depth; i++)\n",
        "          {\n",
        "              if (i % ptr->width == 0 && i >= ptr->width)\n",
        "                  printf(\"\\n\");\n",
        "\n",
        "              if (i % (ptr->width * ptr->height) == 0 && i >= (ptr->width * ptr->height));\n",
        "                  //printf(\"\\n\");\n",
        "\n",
        "              printf(\"%.8f\", ptr->elements[i]);\n",
        "              if (i + 1 == ptr->height * ptr->width * ptr->depth);\n",
        "              else\n",
        "                  printf(\", \");\n",
        "          }\n",
        "\n",
        "          printf(\"} \\n\");\n",
        "          printf(\"\\n\");\n",
        "\n",
        "          setvbuf(stdout, NULL, _IOLBF, 0);        \n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "void start()\n",
        "{\n",
        "  HANDLE_ERROR(cudaEventCreate(&start_timing));\n",
        "  HANDLE_ERROR(cudaEventCreate(&stop_timing));\n",
        "  HANDLE_ERROR(cudaEventRecord(start_timing, 0));\n",
        "}\n",
        "\n",
        "void stop(char *notification, int pause_time)\n",
        "{\n",
        "  HANDLE_ERROR(cudaEventRecord(stop_timing, 0));\n",
        "  HANDLE_ERROR(cudaEventSynchronize(stop_timing));\n",
        "  HANDLE_ERROR(cudaEventElapsedTime(&time_defined, start_timing, stop_timing));\n",
        " \n",
        "  if(pause_time)\n",
        " {\n",
        "    tmp_time += time_defined; \n",
        " }   \n",
        " \n",
        "  else\n",
        "  {\n",
        "    tmp_time = 0;\n",
        "    printf(\"Time elapsed for %s:  %.8f ms\\n\", notification, time_defined);  \n",
        "    total_time_for_layer += time_defined;\n",
        "  }\n",
        "}\n",
        "\n",
        "void after_pause(char *notification)\n",
        "{\n",
        "  printf(\"Time elapsed for %s: %.8f ms\\n\", notification, tmp_time); \n",
        "  total_time_for_layer += tmp_time;\n",
        " \n",
        "  tmp_time = 0;         \n",
        "}\n",
        "\n",
        "void reset_time()\n",
        "{\n",
        "  printf(\"Total time: %.8f ms\\n\", total_time_for_layer); \n",
        "  total_time_for_layer = 0;\n",
        "}\n",
        "\n",
        "void show_me_enhanced_from_devince(Matrix *ptr, char *notification)\n",
        "{\n",
        "    Matrix H_OUT;\n",
        "\n",
        "    set_allocate_Host(&H_OUT, ptr -> height, ptr -> width, ptr -> depth);\n",
        "\n",
        "    just_copy_DTH(&H_OUT, ptr, \"show_device_elements\");\n",
        "  \n",
        "    show_out = 1;\n",
        "    show_me_enhanced(&H_OUT, notification);\n",
        "    show_out = 0;  \n",
        "}"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/FUNCTIONS.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dxEa1LxA0H1"
      },
      "source": [
        "!nvcc -o /content/src/EfficientNet /content/src/APP.cu /content/src/KERNELS.cu /content/src/FUNCTIONS.cu --use_fast_math "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im2j8WyEBLl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3a68b2-a53b-4432-be8e-b85e3c80e5e5"
      },
      "source": [
        "!/content/src/EfficientNet"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed for Model: :  7.98169613 ms\n",
            "Model final output::,it has height = 1, width = 1000, depth = 1 \n",
            "{\n",
            "1.08116734, -0.15231955, 0.81180447, -0.55637485, -1.72109163, -0.12775655, -0.30983409, -0.72759855, -0.36455533, -1.96505380, -1.22603118, 0.09439833, -0.24272297, -0.90570623, 0.13351761, -1.01413095, -1.73747325, -1.51516759, 0.19024637, 0.31977376, -0.67285043, -0.78116024, 0.08444787, -0.50209820, -1.27981591, 0.44497553, 0.14523719, 0.15833744, 0.28457651, 2.25681019, -0.87878931, -0.80018413, -0.09799896, -0.37915513, -0.84588838, -0.61278945, 0.65202796, 0.74403727, 0.40012741, 0.17943129, 0.69742870, 0.06787872, -0.85715145, -0.03864693, 0.56585681, 0.79732269, -0.64108318, 0.22881541, 0.24225605, -0.01618855, -1.18664181, 0.80330795, 0.29770195, 0.04999758, 0.31598836, -1.34917235, -0.24388976, -1.53631532, 0.42537394, -0.64515626, -0.65929657, -0.46719217, -0.87873405, 0.10817172, 0.04329031, -0.44704410, -0.63170409, -0.59761018, -0.32319057, 0.09391501, 0.04296068, -0.38255876, -0.68369651, 0.30698502, -0.26186210, 0.36588490, -0.01970093, -0.32218274, -0.54701781, 0.12218911, -0.00730747, 0.53209287, -0.39587826, 0.85396385, -0.70596308, -0.57065302, -0.29145670, 0.23970193, -1.07988858, 1.89217293, -0.72293037, -0.50496906, -1.79624832, -0.52610278, -0.68044144, -1.06997395, 0.03811143, -0.11606984, -1.02640259, 0.52018631, -0.52902657, 1.82255149, -0.57853103, -1.28836489, -1.18241644, -0.12438285, 1.52431881, -0.21521969, -0.22333983, -0.30725840, 0.93030757, -0.23318020, -0.49969050, -0.33659548, 0.21579616, 1.03495705, -0.19889930, -0.66911799, -0.33264142, 0.23129815, 0.33657923, 0.08655876, 0.48192978, 1.12858462, -0.23784727, 1.32134748, 0.14186549, 1.19760334, 0.90510142, -0.87118387, -0.86793387, -0.71087813, 0.19077103, -1.93308437, -1.13316464, 0.14551386, -0.40984762, -0.68425214, -1.55115962, -0.82753015, -1.47525966, -1.79133916, -1.32406640, -0.57240534, 1.53162503, -0.27995884, 1.35820854, -1.91720200, 1.48743892, 1.56093752, 0.98087448, 0.90320826, 0.31132320, 1.34967041, -0.05091245, -0.30428460, -0.48533782, -0.11091920, 1.75953090, 0.02635701, -2.16923285, -0.86354154, -0.85414660, -1.12586904, -0.25386569, -0.84464902, -0.03024822, -0.22019909, 0.28952053, -0.30204675, -1.93764257, -0.42278239, 0.07447796, -1.29111707, -0.34903038, -1.51364136, -1.75469446, -0.79723400, -1.81725121, 3.41761446, 2.69172239, 1.34278619, -0.04456538, -0.05068892, -0.54870844, 1.30321634, 1.78722644, 0.80837107, 1.01870978, 1.59054792, 2.81196713, 0.35146490, -0.07794821, -0.83843559, 0.44940412, 1.83266640, 0.09200017, -0.24769396, -1.77151310, 0.76424074, -1.03878903, 0.69157833, 0.12907256, 1.61477113, -1.03223348, -0.39180171, -0.27537408, 0.35925746, 1.26997519, -0.09748206, 0.51838946, -2.00592899, 0.42898452, -0.50001848, -0.20220582, 0.15129073, -0.58888173, 0.75221413, -2.27680612, 0.51551682, -0.05713737, -1.33300316, 3.58699250, 0.29685771, 0.22987846, 0.31018817, -1.17988753, 0.49596894, 0.01141410, 1.20258307, -1.59358335, 0.23805895, 1.90079153, -1.28765404, 0.07232960, 0.49670753, -0.52285314, 0.10965091, -1.79278362, -0.48387271, -0.23390798, -0.54724842, 1.71383083, 1.68420100, -1.51388335, 3.15004969, 0.37620476, 0.22780828, 0.02209680, -1.09214330, 0.01004962, 2.11820364, -0.76864755, -0.63906676, 0.86322296, -1.05352199, 0.49265602, 1.68171191, 2.59200883, 0.32119635, 0.84426212, -0.38674092, 0.52996004, -0.53107560, 0.11029957, 0.33385396, 0.69773978, -1.79669774, -1.10632336, -0.81782341, 1.82750130, 0.09072961, -0.46369582, 1.75300109, -1.92919064, -1.18255734, -0.17649719, 0.40325117, -1.23669159, 2.60432029, -1.31690252, -0.63032049, -0.79110920, -1.64871240, 1.13489878, -0.58635676, 0.08182821, -0.10957293, 0.35911241, 0.06463654, 1.64088523, -0.90901679, 1.11500609, -0.04614562, 1.92913139, 1.43888330, 4.23951054, 0.47899196, 0.81749016, 0.48004219, 0.01763327, 0.30185920, -0.74402636, -0.77130717, -0.24040844, -0.73641008, -0.87199116, -0.12122323, -0.51096398, -0.86299479, 0.30563086, -0.84945786, -1.84584558, 0.38316977, 0.63807166, 1.02217269, -1.11186969, -0.14674914, 0.12112083, -0.98141098, 1.30837011, -1.18032694, -1.10315788, -0.11119574, 0.61409599, 0.67634511, -0.42152849, 0.18642704, 0.43490899, -0.11618605, 0.11382242, -0.24799773, 1.23735738, 0.57085949, 0.87120587, 0.43733272, -0.45275560, 0.92515510, 2.55177784, 0.17125812, -0.06408758, 2.94992375, 1.18833709, -0.35063848, 0.75033575, 0.50602889, 0.29074100, 2.03911757, 2.47899771, 0.64260483, -0.45805985, -1.41492295, -1.33993614, -0.70419890, -0.77108860, 0.93697590, 1.45098889, 2.94787073, 0.71422607, 0.25423852, 2.06056261, 2.30473661, 1.97350109, 1.61848009, 0.05065062, 0.89390242, 0.62985873, 0.32047117, -0.47775736, -0.37208527, -0.74151033, -0.82945794, -0.41727424, -1.73862064, 0.13579598, 0.55055970, -1.38205385, 0.86010605, -0.56030619, 0.06596933, -0.43630993, -0.65254205, -0.51258749, -0.18913177, 1.62751865, 0.96285832, 0.91862959, 3.40617394, 9.69681835, 0.63264406, -0.90223920, -0.35947520, 1.04829895, 0.34326783, 0.61816269, -0.07463692, 0.35988408, 0.02318768, 0.04304666, -0.23347709, 0.67084640, -0.36172402, 0.46471587, 0.89403123, 0.55008167, 1.10066342, -0.22152846, 0.96960199, 1.17445219, 0.54465634, -0.56186938, -1.01155198, 1.35987771, -0.15128359, 0.62765682, 0.59639466, 1.96000218, 0.32338029, 0.11372179, -0.07059525, 1.01811016, -0.12139993, -0.85510373, -0.63124251, -1.10359526, 0.98560506, 0.80961823, -0.23752221, -0.04279266, 0.14294916, -0.24762563, -1.42030907, -0.59518021, 1.03698254, 0.16429843, 0.15993190, -0.52674896, 0.13563515, 0.45846727, -0.44657061, -0.68128133, 0.00824691, 0.13423355, -0.27325466, -0.63405436, 0.49880996, 0.19507881, -0.12953497, 1.22720861, 0.57078505, -0.44462514, 1.04128826, 1.04294682, -0.36258081, -0.96794516, -0.01328720, -0.67289686, 0.46720073, 0.26261181, -0.25023887, -0.22975861, -0.50412321, -0.64393115, 2.06510997, -0.32909784, -0.85985458, 1.35054719, -0.50150329, 0.34165174, 0.86145234, 0.20227776, 0.69860905, -0.38164422, 0.14372446, -0.13210957, 0.36216223, 0.53733981, -0.72549742, 0.56438613, 0.33891764, 0.51213938, -0.25991663, 0.01602088, -0.43414867, 0.03556691, 0.70524651, -0.10295606, -0.25224471, -0.71028018, 1.27815473, 0.37283993, -0.81238228, 0.21124774, -0.34130386, -1.17505717, 1.28921854, 0.13778150, -0.32317364, -0.31023192, -0.02949124, -0.61338174, 0.15532801, -0.01402552, -1.40221822, -0.29894996, -0.10470797, -0.76341277, -0.95861149, -0.20682022, -0.46159831, 0.04868640, 0.05547776, -0.23071030, 0.36443135, -0.10642615, 0.25510079, -0.55130017, 1.75676203, 0.19422774, 0.88490593, 0.47605932, 0.24608546, -0.61394566, -1.98033822, 0.58028185, 0.24775603, 0.90017116, -0.84366149, 0.62099671, -1.47806633, 0.47622943, -0.12078601, -0.25155848, 0.06777258, 0.26082563, 0.12700799, 0.35632363, -0.79278952, 0.26092571, 0.47492909, 0.57693887, -0.21073875, -0.61838323, -1.03769815, 0.19025591, -0.99969953, 0.84428668, 0.38164419, -0.74621135, -0.94288480, 0.16252229, 0.26473957, 0.08100840, -0.88873887, -0.04974807, -1.20220244, -0.01958347, 0.73946911, -0.50584996, -1.19265068, 0.81656283, 1.25349545, -0.12790908, -0.53073120, 0.64449996, 0.61400616, 0.36590776, -0.70648938, -1.13736725, -0.73081321, -0.36819628, -1.49680483, 0.19582269, 0.58488333, 0.31176889, 0.32676283, -0.09625159, 1.47881162, 0.59063679, -0.61169702, 0.69011974, -0.29818022, -1.79837096, 0.73668879, -0.73091096, -2.12555003, 0.67621034, 0.90844697, 0.24999359, -1.10062718, 0.04442795, -0.14623246, -0.82981372, 0.32436445, 0.27397364, 0.42356175, 1.40459621, 0.01141170, -0.54063487, 0.26950336, -0.37897232, -1.23662221, 0.23522086, -0.81866795, 0.96859598, 0.10207838, -1.48835099, 1.09160495, -2.20521712, -0.37226558, -0.85148978, -0.12919447, 0.22296447, -0.49812579, 0.25500047, -0.97039145, 0.26409408, -0.45792678, 1.39069676, 0.60502887, -1.56887257, 0.77937055, 0.23533395, 0.39575848, 0.33992314, -0.26597080, -0.38327211, -0.05631234, -0.25114682, -0.78921038, -0.68798792, -1.15456510, 0.70627362, -1.58124542, 1.85847914, -0.14217860, 0.70423955, -0.39370415, 0.12743078, -0.74756956, 0.35739964, -0.92136681, 0.05030705, 2.27445102, -1.35163236, -1.31584764, -0.93062472, -0.56445044, -0.49846777, 0.60417688, -1.48097444, -0.19788960, -0.16916713, 0.09773457, 0.10061385, -1.43178225, -0.70666045, -0.19558290, -1.96091831, 0.20139268, 0.83433580, 0.55558461, -0.54436958, 0.56220102, 0.65646964, -1.00793099, -0.74387628, 1.20267975, -0.32257292, -0.49834934, -0.13488768, -0.29061177, -0.76799226, 0.97821134, 0.77547693, 0.33199394, 1.53393483, -0.52980107, 0.20646243, -0.69411266, -0.32704383, -0.68954366, -0.28954685, -0.83503026, 0.57498205, -0.26724982, 0.07588346, -0.42106569, 1.42799413, -0.41412714, 0.65116268, -0.65662360, -0.08461202, 0.20315275, -0.05505241, 0.26209325, 1.64326489, 0.50052416, 0.25009045, 0.12800016, -0.02002618, -0.74533850, -1.14922142, 0.90666389, -1.49703920, 0.56113893, 0.14525786, 2.11976957, -1.44782186, 0.42363080, 0.33289796, -1.10303652, -1.33344066, 0.34694973, 0.38546541, -0.14159268, 0.27499712, 0.78158146, 1.06072474, 1.80956781, -0.33181599, -0.40223306, -0.96418029, -0.90231335, -0.42137367, 1.35344934, -0.48386496, 0.14629602, 0.26669651, -0.76378059, -0.66669333, -1.02724326, 0.14145690, 0.25532538, 0.24127258, 0.03387174, 0.17767629, 0.62542754, 0.81398004, 0.23950043, -0.95024580, -0.08737203, -1.05521750, 0.57802880, -1.03386152, 0.32912719, 0.32963219, -1.34037840, 0.10756531, 0.09672257, -0.37689742, 1.29714501, 0.27191681, 0.38486841, 0.83081239, -0.21771809, -0.86291236, 0.32737654, -0.06368713, 0.32425532, -0.21274851, -0.67923039, 0.26135826, 0.33902463, 1.41011906, -0.32318619, -0.03080922, 0.49033177, -0.70459342, 1.15543413, -1.00283265, 0.29049852, 0.24056539, -0.60990626, -0.98213202, -2.60843492, 0.21225449, 1.76962686, 0.76427507, 1.42417860, -1.56153166, 0.38377216, 0.79952389, 0.18485422, -0.82524049, 0.72829598, -0.34779203, -1.28550684, -1.29742134, 1.46186185, 0.38664824, 0.49467853, -1.09904146, -0.28036582, -0.27970815, -1.00667894, 0.50897443, -0.73261493, -0.02969680, 0.30996695, 0.44201905, -1.24689424, -0.50091118, -1.15054631, -0.74503386, 2.61353993, 0.36909550, -0.46856365, 0.09542785, -0.36550286, 0.54352385, 0.52131391, -0.37590295, -0.14583987, -0.08558674, 1.02340162, -0.97024465, -0.88058215, -0.89927220, -0.85028946, -0.53320879, 0.61580873, -1.15334654, 0.64526910, -0.52153653, 0.22224206, -0.47151858, 0.19739032, 0.89866191, -0.58083081, -0.57716209, -0.92688686, -0.19612584, 0.40721250, -0.18781619, -0.94657421, -0.05138658, -0.30009946, -0.89291453, 0.19995664, -0.34936935, -1.25443673, -0.30597216, 0.02535858, -0.23933730, -1.09019506, -0.49824810, 0.97069317, 1.03324485, -0.38042009, 3.20551872, -0.94490081, 1.30276918, -0.02128967, -0.42898041, -0.58658350, 0.48423338, -0.65532976, 1.25422239, -0.50352454, -0.44186151, -0.45169613, 0.61067808, 0.12786148, 0.19066584, 1.81209695, 0.05641922, 1.46771801, 0.88601273, -0.99466240, 0.20256372, -1.03406727, 0.89081502, -1.84277582, -0.01781495, 0.10185537, 1.11063600, -0.40911078, 0.31937802, 0.19372225, -1.35808647, 1.25887644, 0.04658484, -0.20082799, 0.20174438, 0.13973886, 1.28501225, -0.24141686, 0.32996160, -0.27609649, -1.17939758, -0.30122894, -0.22946531, 0.30850554, 0.20990565, 0.46664581, -2.08642960, -0.57010144, 1.37255573, -0.25541776, -0.12493705, -0.07319301, 0.13080075, -1.13541114, 1.50886953, 0.51043910, -0.07433233, -1.55501544, -1.29047883, -1.66037726, 1.12846971, -0.80921912, 1.97605479, 0.07073539, -1.54384196, -0.71551043, -0.42112038, 0.14975581, -0.04178675, 1.57151592, 0.12689397, 0.21067847, -0.65869462, 0.03297326, 0.05888396, 0.86915916, -0.89716345, -0.52648997, -0.78396070, 0.05188833, -0.16567209, 0.40633279, -0.67648256, 0.67214394, -1.33155298, -0.01022018, 0.27076268, 0.08393169, -0.13635693, -0.08690844, 0.21166202, -0.29931182, 1.81966794, 0.23086518, -0.51876390, -1.23209310, -0.38720769, -0.03822089, 0.40861574, -0.99371397, -1.22159541, -0.28316477, -0.01065648, 0.63642061, 1.04526162, -0.98162466, 1.24590302, -0.61525345, -0.09450084, 0.50424707, 0.55227143, -0.49183419, -1.53272855, 0.18621397, -0.82858926, 0.67260456, -0.67586023, 0.72695410, -0.34304059, -1.18066537, -0.29247782, 0.60907006, 0.03738581, -0.54702085, -0.75311691, -0.48208883, -0.39655524, -0.28730452, -0.15788710, -0.54663473, -1.21096301, 0.06332980, -1.33183646, -0.48970893, -0.33381969, 0.37858847, -0.18105252, -1.11412930, -0.60220838, -0.85695577, 0.16558126, 1.28138781, -0.80572248, -0.71694297, 0.20722184, 0.96363539, -0.17073855, -0.33256370, 0.78065842, -0.05295639} \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWNUsvTZzdFb"
      },
      "source": [
        "!nvprof /content/src/EfficientNet\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9be79iSOhq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782b09ab-3199-4300-b46e-d8097b0ce3ee"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h> \n",
        "\n",
        "int main() {\n",
        "  int nDevices;\n",
        "\n",
        "  cudaGetDeviceCount(&nDevices);\n",
        "  for (int i = 0; i < nDevices; i++) {\n",
        "    cudaDeviceProp prop;\n",
        "    cudaGetDeviceProperties(&prop, i);\n",
        "    printf(\"Device Number: %d\\n\", i);\n",
        "    printf(\"  Device name: %s\\n\", prop.name);\n",
        "    printf(\"  Memory Clock Rate (KHz): %d\\n\",             prop.memoryClockRate);\n",
        "    printf(\"  Memory Bus Width (bits): %d\\n\",             prop.memoryBusWidth);\n",
        "    printf(\"  Number of totalGlobalMem %lu\\n\",            prop.totalGlobalMem); \n",
        "    printf(\"  Number of sharedMemPerBlock %lu\\n\",         prop.sharedMemPerBlock); \n",
        "\n",
        "    printf(\"\\n  Number of warpSize %d\\n\",                   prop.warpSize); \n",
        "    printf(\"  Number of maxThreadsPerBlock %d\\n\",         prop.maxThreadsPerBlock); \n",
        "    printf(\"  Number of maxBlocksPerMultiProcessor %d\\n\", prop.maxBlocksPerMultiProcessor); \n",
        "    printf(\"  Number of multiProcessorCount %d\\n\",        prop.multiProcessorCount); \n",
        "    printf(\"  Number of maxThreadsPerMultiProcessor %lu\\n\",prop.maxThreadsPerMultiProcessor); \n",
        "\n",
        "    printf(\"\\n  Number of maxThreadsDim %d\\n\",              prop.maxThreadsDim[0]); \n",
        "    printf(\"  Number of maxGridSize %d\\n\",                prop.maxGridSize[0]); \n",
        "    printf(\"  Number of totalConstMem %d\\n\",              prop.totalConstMem); \n",
        "    printf(\"  Number of sharedMemPerMultiprocessor %d\\n\", prop.sharedMemPerMultiprocessor); \n",
        "             \n",
        "    printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\", 2.0 * prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    printf(\"deviceOverlap is 1 if the device can concurrently copy memory between host and device while executing a kernel. It's: %d \\n\", prop.deviceOverlap);\n",
        "    printf(\"asyncEngineCount: %d\", prop.asyncEngineCount);\n",
        "  }\n",
        "}"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Number of totalGlobalMem 15843721216\n",
            "  Number of sharedMemPerBlock 49152\n",
            "\n",
            "  Number of warpSize 32\n",
            "  Number of maxThreadsPerBlock 1024\n",
            "  Number of maxBlocksPerMultiProcessor 16\n",
            "  Number of multiProcessorCount 40\n",
            "  Number of maxThreadsPerMultiProcessor 1024\n",
            "\n",
            "  Number of maxThreadsDim 1024\n",
            "  Number of maxGridSize 2147483647\n",
            "  Number of totalConstMem 65536\n",
            "  Number of sharedMemPerMultiprocessor 65536\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "deviceOverlap is 1 if the device can concurrently copy memory between host and device while executing a kernel. It's: 1 \n",
            "asyncEngineCount: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlIi5dGoReOM"
      },
      "source": [
        "#  struct cudaDeviceProp {\n",
        "#               int major;\n",
        "#               int minor;\n",
        "#               size_t textureAlignment;\n",
        "#               size_t texturePitchAlignment;\n",
        "#               int canMapHostMemory;\n",
        "#               int computeMode;\n",
        "#               int maxTexture1D;\n",
        "#               int maxTexture1DMipmap;\n",
        "#               int maxTexture1DLinear;\n",
        "#               int maxTexture2D[2];\n",
        "#               int maxTexture2DMipmap[2];\n",
        "#               int maxTexture2DLinear[3];\n",
        "#               int maxTexture2DGather[2];\n",
        "#               int maxTexture3D[3];\n",
        "#               int maxTexture3DAlt[3];\n",
        "#               int maxTextureCubemap;\n",
        "#               int maxTexture1DLayered[2];\n",
        "#               int maxTexture2DLayered[3];\n",
        "#               int maxTextureCubemapLayered[2];\n",
        "#               int maxSurface1D;\n",
        "#               int maxSurface2D[2];\n",
        "#               int maxSurface3D[3];\n",
        "#               int maxSurface1DLayered[2];\n",
        "#               int maxSurface2DLayered[3];\n",
        "#               int maxSurfaceCubemap;\n",
        "#               int maxSurfaceCubemapLayered[2];\n",
        "#               size_t surfaceAlignment;\n",
        "#               int concurrentKernels;\n",
        "#               int ECCEnabled;\n",
        "#               int pciBusID;\n",
        "#               int pciDeviceID;\n",
        "#               int pciDomainID;\n",
        "#               int tccDriver;\n",
        "#               int asyncEngineCount;\n",
        "#               int unifiedAddressing;\n",
        "#               int memoryClockRate;\n",
        "#               int memoryBusWidth;\n",
        "#               int l2CacheSize;\n",
        "#               int persistingL2CacheMaxSize;\n",
        "#               int maxThreadsPerMultiProcessor;\n",
        "#               int streamPrioritiesSupported;\n",
        "#               int globalL1CacheSupported;\n",
        "#               int localL1CacheSupported;\n",
        "#               size_t sharedMemPerMultiprocessor;\n",
        "#               int regsPerMultiprocessor;\n",
        "#               int managedMemory;\n",
        "#               int isMultiGpuBoard;\n",
        "#               int multiGpuBoardGroupID;\n",
        "#               int singleToDoublePrecisionPerfRatio;\n",
        "#               int pageableMemoryAccess;\n",
        "#               int concurrentManagedAccess;\n",
        "#               int computePreemptionSupported;\n",
        "#               int canUseHostPointerForRegisteredMem;\n",
        "#               int cooperativeLaunch;\n",
        "#               int cooperativeMultiDeviceLaunch;\n",
        "#               int pageableMemoryAccessUsesHostPageTables;\n",
        "#               int directManagedMemAccessFromHost;\n",
        "#               int accessPolicyMaxWindowSize;"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15W3r0XXMx4B"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}