{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Reference42_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfp2HUnz6CR1"
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_ALHmgw7F6L"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehCqOlQ8dmG"
      },
      "source": [
        "!nvcc --version "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bog6uNQT8f9Q"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xua-cpZQ8lt1"
      },
      "source": [
        "%load_ext nvcc_plugin\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "K8xAh2jVyUSx",
        "outputId": "41733636-ce10-4b25-c917-83e85a6a582c"
      },
      "source": [
        "%%cuda --name KERNELS.cu \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <cusolverDn.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/functionsV2.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/KERNELSH.h\"\n",
        "\n",
        "/* Kernel definitions */\n",
        "__global__ void INPUT_UNROLLING(int stride, int Filter_Height,\n",
        "                                float *Input, int H1, int W1, int D1,\n",
        "                                float *X_unrolled, int H2, int W2, int D2,\n",
        "                                int Output_Height, int Output_Width)\n",
        "{  \n",
        "    int bx = blockIdx.x, by = blockIdx.y, bz = blockIdx.z;\n",
        "    int tx = threadIdx.x, ty = threadIdx.y;\n",
        " \n",
        "    // Select row and column values \n",
        "    int row =  by * TileDW + ty;\n",
        "    int col = bx * TileDW + tx;\n",
        "    int depth = bz;\n",
        " \n",
        "    int col_no_strided = col, row_no_strided = row;\n",
        "    int depth_offset = depth * W2 * Filter_Height * Filter_Height;\n",
        "\n",
        "    /* \n",
        "      Note for bx, by and bz= 0, stride = 2: \n",
        "          @ tx = 0, ty = 0 -> First multiply the col * stride, row * stride; = 0, 0\n",
        "                            you are shifting in x direction using local col\n",
        "                            you are shifting in y direction using local row;\n",
        "          @ tx = 1, ty = 0 -> First multiply the col * stride, row * stride; = 2, 0 \n",
        "                            you are shifting in x direction using local col\n",
        "                            you are shifting in y direction using local row;   \n",
        "          @ tx = 0, ty = 1 -> First multiply the col * stride, row * stride; = 0, 2 \n",
        "                            you are shifting in x direction using local col\n",
        "                            you are shifting in y direction using local row;                   \n",
        "    */ \n",
        "  \n",
        "    col *= stride; row *= stride;\n",
        " \n",
        "    // Limit number of threads \n",
        "    if (row_no_strided < Output_Height && col_no_strided < Output_Width && depth < D1)\n",
        "    {   \n",
        "      // Each thread unrolls k x k elements\n",
        "      for (int local_row = 0; local_row < Filter_Height; local_row++)\n",
        "      {\n",
        "        for (int local_col = 0; local_col < Filter_Height; local_col++)\n",
        "        {                                  \n",
        "          // 1. local row and column shifts affect the locations in Unrolled matrix\n",
        "          // 2. For each col and row non strided values -> you are adding an offset to columns and rows in Unrolled matrix\n",
        "          // 3. Offset the depth using \"depth_offset\" variable\n",
        "          X_unrolled[local_col * W2 + local_row * Filter_Height * W2 + col_no_strided + row_no_strided * Output_Width + depth_offset] = \n",
        "          Input[(row + local_row) * W1 + (col + local_col) + depth * H1 * W1];\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void DWConv2d_kernel(float *Input, int H1, int W1, int D1,\n",
        "                                float *Filter, int H2, int W2, int D2,\n",
        "                                float *Output, int H3, int W3, int D3,\n",
        "                                int stride)\n",
        "{\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int bz = blockIdx.z;\n",
        "\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int row = by * TileDW + ty;\n",
        "    int col = bx * TileDW + tx;\n",
        "    int dep = bz;\n",
        "\n",
        "    float Pvalue = 0;\n",
        "\n",
        "    if (row < H3 && col < W3 && dep < D3)\n",
        "    {\n",
        "      // 1 thread unrolls kxk section\n",
        "      for (int j = 0; j < H2; j++)\n",
        "      {\n",
        "        for (int i = 0; i < W2; i++)\n",
        "        {\n",
        "            Pvalue += Filter[j * W2 + i + dep * H2 * W2] *\n",
        "                Input[(j * W1 + row * stride * W1) + (i + col * stride) + dep * H1 * W1];\n",
        "        }\n",
        "      }\n",
        "      Output[row * W3 + col + dep * H3 * W3] = Pvalue;\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void MatrixMulKernel(float *M, int H1, int W1, int D1,\n",
        "                                float *N, int H2, int W2, int D2,\n",
        "                                float *P, int H3, int W3, int D3,\n",
        "                                int num_blocks, int activation, \n",
        "                                int IS_BIASED, float *bias_mat)\n",
        "{\n",
        "  __shared__ float Mds[Tile_GEMM][Tile_GEMM];\n",
        "  __shared__ float Nds[Tile_GEMM][THREAD_GRANULARITY_BLOCKS * Tile_GEMM];\n",
        "\n",
        "  int bx = blockIdx.x * THREAD_GRANULARITY_BLOCKS;\n",
        "  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x;\n",
        "  int ty = threadIdx.y;\n",
        "\n",
        "  // Identify the row and column of the d_P element to work on\n",
        "  int Row = by * Tile_GEMM + ty;\n",
        "  int Col = bx * Tile_GEMM + tx;\n",
        "  float Pvalue = 0;\n",
        "  float Pvalue_2 = 0;\n",
        "\n",
        "  // Loop over the d_M and d_N tiles required to compute d_P element\n",
        "  for (int ph = 0; ph < num_blocks; ++ph)\n",
        "  {\n",
        "    // Collaborative loading of d_M and d_N tiles into shared memory\n",
        "    if ((Row < H1) && (ph * Tile_GEMM + tx) < W1)\n",
        "    {\n",
        "      Mds[ty][tx] = M[Row * W1 + ph * Tile_GEMM + tx];\n",
        "    }\n",
        "\n",
        "    if ((ph * Tile_GEMM + ty) < H2 && Col < W2)\n",
        "    {\n",
        "      Nds[ty][tx] = N[(ph * Tile_GEMM + ty) * W2 + Col];\n",
        "    }\n",
        "\n",
        "    if ((ph * Tile_GEMM + ty) < H2 && Col + Tile_GEMM < W2)\n",
        "    {\n",
        "      Nds[ty][tx + Tile_GEMM] = N[(ph * Tile_GEMM + ty) * W2 + Col + Tile_GEMM];\n",
        "    }     \n",
        "   \n",
        "    __syncthreads();\n",
        "\n",
        "    for (int k = 0; k < Tile_GEMM && (ph * Tile_GEMM) + k < W1; ++k)\n",
        "    {\n",
        "      Pvalue += Mds[ty][k] * Nds[k][tx];\n",
        "    }\n",
        "\n",
        "    if (Col + Tile_GEMM < W2)\n",
        "    {\n",
        "      for (int k = 0; k < Tile_GEMM && (ph * Tile_GEMM) + k < W1; ++k)\n",
        "      {\n",
        "        Pvalue_2 += Mds[ty][k] * Nds[k][tx + Tile_GEMM];\n",
        "      } \n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "  }\n",
        "\n",
        "  if ((Row < H1) && (Col < W2))\n",
        "  {\n",
        "    P[Row * W3 + Col] = Pvalue;\n",
        "    \n",
        "    switch (IS_BIASED) \n",
        "    {\n",
        "      case BIASED:\n",
        "        Pvalue = Pvalue + bias_mat[Row];\n",
        "        break;\n",
        "      \n",
        "      default:\n",
        "        break;\n",
        "    } \n",
        "            \n",
        "    switch (activation) \n",
        "    {\n",
        "      case SWISH_ACTIVATION:\n",
        "        // Swish activation function\n",
        "        P[Row * W3 + Col] = Pvalue / (1.0f + expf(-1.0f * Pvalue));\n",
        "        break;\n",
        "\n",
        "      case SIGMOID_ACTIVATION:\n",
        "        // Sigmoid activation function\n",
        "        P[Row * W3 + Col] = 1.0f / (1.0f + expf(-1.0f * Pvalue));\n",
        "        break;\n",
        "\n",
        "      default:\n",
        "        break;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if ((Row < H1) && (Col + Tile_GEMM < W2))\n",
        "    {\n",
        "      P[Row * W3 + Col + Tile_GEMM] = Pvalue_2;\n",
        "      \n",
        "      switch (IS_BIASED) \n",
        "      {\n",
        "        case BIASED:\n",
        "          Pvalue_2 = Pvalue_2 + bias_mat[Row];\n",
        "          break;\n",
        "        \n",
        "        default:\n",
        "          break;\n",
        "      } \n",
        "              \n",
        "      switch (activation) \n",
        "      {\n",
        "        case SWISH_ACTIVATION:\n",
        "          // Swish activation function\n",
        "          P[Row * W3 + Col + Tile_GEMM] = Pvalue_2 / (1.0f + expf(-1.0f * Pvalue_2));\n",
        "          break;\n",
        "\n",
        "        case SIGMOID_ACTIVATION:\n",
        "          // Sigmoid activation function\n",
        "          P[Row * W3 + Col + Tile_GEMM] = 1.0f / (1.0f + expf(-1.0f * Pvalue_2));\n",
        "          break;\n",
        "\n",
        "        default:\n",
        "          break;\n",
        "      }\n",
        "    }    \n",
        "}\n",
        "\n",
        "\n",
        "__global__ void ConvChannelElementWiseMultiplication(float *A, int H1, int W1, int D1,\n",
        "                                                     float *B)\n",
        "{\n",
        "    int row = blockIdx.y * Tile_GEMM + threadIdx.y;\n",
        "    int col = blockIdx.x * Tile_GEMM + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "\n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = A[index] * B[depth];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Used with MBConv layers that has skip identity = true\n",
        "__global__ void Identity_Skip(float *A,  int H1, int W1, int D1,\n",
        "                              float *B)\n",
        "{\n",
        "    int row = blockIdx.y * Tile_GEMM + threadIdx.y;\n",
        "    int col = blockIdx.x * Tile_GEMM + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "\n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = A[index] + B[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void Complete_Padding_Process(float *Original_Padded, int H1, int W1, int D1, \n",
        "                                         float *Original,        int H2, int W2, int D2,\n",
        "                                         int padding_value)\n",
        "{   \n",
        "    // There must be a constant shift between indeces in 2 matrices\n",
        "    // The code is based on x axis only\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int depth = blockIdx.z * blockDim.z + threadIdx.z;\n",
        "\n",
        "    int index = depth * W2 * H2 + row * W2 + col;\n",
        "    int Padding_Index = depth * W1 * H1 + (row + padding_value) * W1 + (col + padding_value);\n",
        "\n",
        "    if ((row < (H2)) && (col < (W2)) && (depth < (D2)))\n",
        "    {\n",
        "        Original_Padded[Padding_Index] = Original[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Batch Normalization Kernels */\n",
        "const int BLOCK_SIZE = 16;\n",
        "\n",
        "__global__ void BN_Kernel_Mean_Reduction(float *input, int H1, int W1, int D1,\n",
        "                                         float *Mean, int W2)\n",
        "{\n",
        "    /*\n",
        "        This code works on 2 * Block_Size elements.\n",
        "        i.e. for 512 Block_Size -> we are reducing 1024 elements.\n",
        "        Each thread loads 2 elements, one at tx and the\n",
        "        other shifted by blockIdx.x.\n",
        "    */\n",
        "\n",
        "    __shared__ float partialSum[2 * BLOCK_SIZE];\n",
        "    float tmp = 0;\n",
        "\n",
        "    unsigned int tx = threadIdx.x;\n",
        "    int bx = blockDim.x;\n",
        "\n",
        "    int by_index = blockIdx.y;\n",
        "    int bx_index = blockIdx.x;\n",
        "\n",
        "    // The start variable is to get offset for input matrix in loading\n",
        "    unsigned int start = blockIdx.x * (2 * blockDim.x);\n",
        "    int start_yDir = blockIdx.y * W1;\n",
        "\n",
        "    if (start + tx < W1 && start_yDir < H1 * W1)\n",
        "        // Load 2 elements in the shared memory\n",
        "        partialSum[tx] = input[start + tx + start_yDir];\n",
        "    else\n",
        "        partialSum[tx] = tmp;\n",
        "\n",
        "    if (tx + bx + start < W1 && start_yDir < H1 * W1)\n",
        "        partialSum[bx + tx] = input[start + bx + tx + start_yDir];\n",
        "    else\n",
        "        partialSum[bx + tx] = tmp;\n",
        "\n",
        "\n",
        "    unsigned int stride = 0;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    for (stride = blockDim.x; stride > 0; stride = stride / 2)\n",
        "    {\n",
        "        __syncthreads();\n",
        "        if (tx < stride)\n",
        "            partialSum[tx] += partialSum[tx + stride];\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "\n",
        "    if (tx == 0)\n",
        "        Mean[bx_index + by_index * W2] = partialSum[tx];\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void ElementWiseSquaring(float *A, int H1, int W1, int D1)\n",
        "{\n",
        "    int row = blockIdx.y * Tile_GEMM + threadIdx.y;\n",
        "    int col = blockIdx.x * Tile_GEMM + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "\n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = A[index] * A[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void ElementWiseSubtraction(float *A, int H1, int W1, int D1,\n",
        "                                       float *mean)\n",
        "{\n",
        "    int row = blockIdx.y * Tile_GEMM + threadIdx.y;\n",
        "    int col = blockIdx.x * Tile_GEMM + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "\n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = A[index] - mean[depth];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void BN_Kernel_Final_Layer(float *A, int H1, int W1, int D1, \n",
        "                                      float *D_mean, float *D_variance,\n",
        "                                      float *D_weight, float *D_bias,\n",
        "                                      int activate)\n",
        "{\n",
        "    // Activate values are assigned as follow\n",
        "    /*\n",
        "      0 -> no activation, 1 -> swish, 2 -> sigmoid\n",
        "    */\n",
        "    int row = blockIdx.y * Tile_GEMM + threadIdx.y;\n",
        "    int col = blockIdx.x * Tile_GEMM + threadIdx.x;\n",
        "    int depth = blockIdx.z;\n",
        "\n",
        "    int index = depth * W1 * H1 + row * W1 + col;\n",
        "    int index3 = depth;\n",
        "\n",
        "    float tmp = 0;\n",
        " \n",
        "    if ((row < H1) && (col < W1) && (depth < D1))\n",
        "    {\n",
        "        A[index] = ((A[index] - D_mean[index3]) / (sqrtf(D_variance[index3] + 0.001f))) * D_weight[index3] + D_bias[index3];\n",
        "        tmp = A[index];\n",
        "\n",
        "        switch (activate) {\n",
        "                  case 1:\n",
        "                      // Swish activation function\n",
        "                      A[index] = tmp / (1.0f + expf(-1.0f * tmp));\n",
        "                      break;\n",
        "                  case 2:\n",
        "                      // Sigmoid activation function\n",
        "                      A[index] = 1.0f / (1.0f + expf(-1.0f * tmp));\n",
        "                      break;\n",
        "                  default:\n",
        "                      break;\n",
        "                    }\n",
        "    }\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/KERNELS.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0b4nSRha8tBJ",
        "outputId": "21d3c2a3-144a-48a0-d2bc-898b6c67cb47"
      },
      "source": [
        "%%cuda --name APP.cu \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <cusolverDn.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/Input_For_Stem_Layer.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/Stem/Stem_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/functionsV2.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/CONFIG.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/Input_Matrix.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/KERNELSH.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MBConv1_0/MBConv1_0_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MBConv1_0/MBConv1_0_project_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MBConv1_0/MBConv1_0_squeeze_excitation_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_1/MBConv6_1_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_1/MBConv6_1_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_1/MBConv6_1_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_1/MBConv6_1_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_2/MBConv6_2_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_2/MBConv6_2_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_2/MBConv6_2_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_2/MBConv6_2_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_3/MBConv6_3_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_3/MBConv6_3_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_3/MBConv6_3_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_3/MBConv6_3_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_4/MBConv6_4_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_4/MBConv6_4_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_4/MBConv6_4_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_4/MBConv6_4_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_5/MBConv6_5_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_5/MBConv6_5_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_5/MBConv6_5_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_5/MBConv6_5_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_6/MBConv6_6_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_6/MBConv6_6_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_6/MBConv6_6_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_6/MBConv6_6_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_7/MBConv6_7_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_7/MBConv6_7_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_7/MBConv6_7_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_7/MBConv6_7_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_8/MBConv6_8_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_8/MBConv6_8_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_8/MBConv6_8_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_8/MBConv6_8_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_9/MBConv6_9_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_9/MBConv6_9_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_9/MBConv6_9_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_9/MBConv6_9_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_10/MBConv6_10_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_10/MBConv6_10_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_10/MBConv6_10_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_10/MBConv6_10_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_11/MBConv6_11_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_11/MBConv6_11_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_11/MBConv6_11_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_11/MBConv6_11_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_12/MBConv6_12_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_12/MBConv6_12_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_12/MBConv6_12_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_12/MBConv6_12_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_13/MBConv6_13_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_13/MBConv6_13_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_13/MBConv6_13_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_13/MBConv6_13_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_14/MBConv6_14_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_14/MBConv6_14_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_14/MBConv6_14_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_14/MBConv6_14_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_15/MBConv6_15_expansion_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_15/MBConv6_15_depthwise_conv_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_15/MBConv6_15_squeeze_excitation_parameters.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/MbConv6_15/MBConv6_15_project_conv_parameters.h\"\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/Head/Head_conv_parameters.h\"\n",
        "\n",
        "\n",
        "int MBCONV1_0_flag = 0;\n",
        "\n",
        "int main()\n",
        "{\n",
        "  // 1. Define dimensions for input image.\n",
        "  set_allocate_copy_array_Device(&DInput_Mat, Input_for_stem_conv,\n",
        "                                 INPUT_IMAGE_HEIGHT, INPUT_IMAGE_WIDTH, \n",
        "                                 INPUT_IMAGE_DEPTH,\n",
        "                                 \"Input Image is allocated in device memory\");  \n",
        "\n",
        "  // 2. Get layers' filters ready\n",
        "  set_allocate_copy_array_Device(&F_STEM, Stem_conv2d_weights,\n",
        "                                 STEM_FILTER_HEIGHT, STEM_FILTER_WIDTH, \n",
        "                                 STEM_FILTER_DEPTH * STEM_FILTER_DENSITY,\n",
        "                                 \"Stem Filter  is allocated in device memory\");\n",
        "  \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_1_0_EXPD_WEIGHTS, NULL, \n",
        "                            MBCONV_1_0_EXPD_F_HEIGHT,   MBCONV_1_0_EXPD_F_WIDTH, \n",
        "                            MBCONV_1_0_EXPD_F_DEPTH * MBCONV_1_0_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_1_0_DW_WEIGHTS, MBConv1_0_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_1_0_DW_F_HEIGHT, MBCONV_1_0_DW_F_WIDTH, \n",
        "                            MBCONV_1_0_DW_F_DEPTH * MBCONV_1_0_DW_F_DENSITY,\n",
        "                            &D_MBConv_1_0_SQZ_1_WEIGHTS, MBConv1_0_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_1_0_SQZ_1_F_HEIGHT, MBCONV_1_0_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_1_0_SQZ_1_F_DEPTH * MBCONV_1_0_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_1_0_SQZ_2_WEIGHTS, MBConv1_0_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_1_0_SQZ_2_F_HEIGHT, MBCONV_1_0_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_1_0_SQZ_2_F_DEPTH * MBCONV_1_0_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_1_0_PRJ_WEIGHTS, MBConv1_0_project_conv_conv2d_weights, \n",
        "                            MBCONV_1_0_PRJ_F_HEIGHT, MBCONV_1_0_PRJ_F_WIDTH, \n",
        "                            MBCONV_1_0_PRJ_F_DEPTH * MBCONV_1_0_PRJ_F_DENSITY); \n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_1_EXPD_WEIGHTS, MBConv6_1_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_1_EXPD_F_HEIGHT,   MBCONV_6_1_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_1_EXPD_F_DEPTH * MBCONV_6_1_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_1_DW_WEIGHTS, MBConv6_1_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_1_DW_F_HEIGHT, MBCONV_6_1_DW_F_WIDTH, \n",
        "                            MBCONV_6_1_DW_F_DEPTH * MBCONV_6_1_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_1_SQZ_1_WEIGHTS, MBConv6_1_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_1_SQZ_1_F_HEIGHT, MBCONV_6_1_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_1_SQZ_1_F_DEPTH * MBCONV_6_1_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_1_SQZ_2_WEIGHTS, MBConv6_1_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_1_SQZ_2_F_HEIGHT, MBCONV_6_1_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_1_SQZ_2_F_DEPTH * MBCONV_6_1_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_1_PRJ_WEIGHTS, MBConv6_1_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_1_PRJ_F_HEIGHT, MBCONV_6_1_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_1_PRJ_F_DEPTH * MBCONV_6_1_PRJ_F_DENSITY); \n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_2_EXPD_WEIGHTS, MBConv6_2_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_2_EXPD_F_HEIGHT,   MBCONV_6_2_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_2_EXPD_F_DEPTH * MBCONV_6_2_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_2_DW_WEIGHTS, MBConv6_2_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_2_DW_F_HEIGHT, MBCONV_6_2_DW_F_WIDTH, \n",
        "                            MBCONV_6_2_DW_F_DEPTH * MBCONV_6_2_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_2_SQZ_1_WEIGHTS, MBConv6_2_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_2_SQZ_1_F_HEIGHT, MBCONV_6_2_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_2_SQZ_1_F_DEPTH * MBCONV_6_2_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_2_SQZ_2_WEIGHTS, MBConv6_2_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_2_SQZ_2_F_HEIGHT, MBCONV_6_2_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_2_SQZ_2_F_DEPTH * MBCONV_6_2_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_2_PRJ_WEIGHTS, MBConv6_2_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_2_PRJ_F_HEIGHT, MBCONV_6_2_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_2_PRJ_F_DEPTH * MBCONV_6_2_PRJ_F_DENSITY);\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_3_EXPD_WEIGHTS, MBConv6_3_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_3_EXPD_F_HEIGHT,   MBCONV_6_3_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_3_EXPD_F_DEPTH * MBCONV_6_3_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_3_DW_WEIGHTS, MBConv6_3_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_3_DW_F_HEIGHT, MBCONV_6_3_DW_F_WIDTH, \n",
        "                            MBCONV_6_3_DW_F_DEPTH * MBCONV_6_3_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_3_SQZ_1_WEIGHTS, MBConv6_3_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_3_SQZ_1_F_HEIGHT, MBCONV_6_3_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_3_SQZ_1_F_DEPTH * MBCONV_6_3_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_3_SQZ_2_WEIGHTS, MBConv6_3_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_3_SQZ_2_F_HEIGHT, MBCONV_6_3_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_3_SQZ_2_F_DEPTH * MBCONV_6_3_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_3_PRJ_WEIGHTS, MBConv6_3_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_3_PRJ_F_HEIGHT, MBCONV_6_3_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_3_PRJ_F_DEPTH * MBCONV_6_3_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_4_EXPD_WEIGHTS, MBConv6_4_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_4_EXPD_F_HEIGHT,   MBCONV_6_4_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_4_EXPD_F_DEPTH * MBCONV_6_4_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_4_DW_WEIGHTS, MBConv6_4_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_4_DW_F_HEIGHT, MBCONV_6_4_DW_F_WIDTH, \n",
        "                            MBCONV_6_4_DW_F_DEPTH * MBCONV_6_4_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_4_SQZ_1_WEIGHTS, MBConv6_4_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_4_SQZ_1_F_HEIGHT, MBCONV_6_4_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_4_SQZ_1_F_DEPTH * MBCONV_6_4_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_4_SQZ_2_WEIGHTS, MBConv6_4_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_4_SQZ_2_F_HEIGHT, MBCONV_6_4_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_4_SQZ_2_F_DEPTH * MBCONV_6_4_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_4_PRJ_WEIGHTS, MBConv6_4_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_4_PRJ_F_HEIGHT, MBCONV_6_4_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_4_PRJ_F_DEPTH * MBCONV_6_4_PRJ_F_DENSITY);\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_5_EXPD_WEIGHTS, MBConv6_5_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_5_EXPD_F_HEIGHT,   MBCONV_6_5_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_5_EXPD_F_DEPTH * MBCONV_6_5_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_5_DW_WEIGHTS, MBConv6_5_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_5_DW_F_HEIGHT, MBCONV_6_5_DW_F_WIDTH, \n",
        "                            MBCONV_6_5_DW_F_DEPTH * MBCONV_6_5_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_5_SQZ_1_WEIGHTS, MBConv6_5_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_5_SQZ_1_F_HEIGHT, MBCONV_6_5_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_5_SQZ_1_F_DEPTH * MBCONV_6_5_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_5_SQZ_2_WEIGHTS, MBConv6_5_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_5_SQZ_2_F_HEIGHT, MBCONV_6_5_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_5_SQZ_2_F_DEPTH * MBCONV_6_5_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_5_PRJ_WEIGHTS, MBConv6_5_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_5_PRJ_F_HEIGHT, MBCONV_6_5_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_5_PRJ_F_DEPTH * MBCONV_6_5_PRJ_F_DENSITY);\n",
        "     \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_6_EXPD_WEIGHTS, MBConv6_6_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_6_EXPD_F_HEIGHT,   MBCONV_6_6_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_6_EXPD_F_DEPTH * MBCONV_6_6_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_6_DW_WEIGHTS, MBConv6_6_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_6_DW_F_HEIGHT, MBCONV_6_6_DW_F_WIDTH, \n",
        "                            MBCONV_6_6_DW_F_DEPTH * MBCONV_6_6_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_6_SQZ_1_WEIGHTS, MBConv6_6_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_6_SQZ_1_F_HEIGHT, MBCONV_6_6_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_6_SQZ_1_F_DEPTH * MBCONV_6_6_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_6_SQZ_2_WEIGHTS, MBConv6_6_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_6_SQZ_2_F_HEIGHT, MBCONV_6_6_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_6_SQZ_2_F_DEPTH * MBCONV_6_6_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_6_PRJ_WEIGHTS, MBConv6_6_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_6_PRJ_F_HEIGHT, MBCONV_6_6_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_6_PRJ_F_DEPTH * MBCONV_6_6_PRJ_F_DENSITY);\n",
        "     \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_7_EXPD_WEIGHTS, MBConv6_7_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_7_EXPD_F_HEIGHT,   MBCONV_6_7_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_7_EXPD_F_DEPTH * MBCONV_6_7_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_7_DW_WEIGHTS, MBConv6_7_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_7_DW_F_HEIGHT, MBCONV_6_7_DW_F_WIDTH, \n",
        "                            MBCONV_6_7_DW_F_DEPTH * MBCONV_6_7_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_7_SQZ_1_WEIGHTS, MBConv6_7_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_7_SQZ_1_F_HEIGHT, MBCONV_6_7_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_7_SQZ_1_F_DEPTH * MBCONV_6_7_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_7_SQZ_2_WEIGHTS, MBConv6_7_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_7_SQZ_2_F_HEIGHT, MBCONV_6_7_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_7_SQZ_2_F_DEPTH * MBCONV_6_7_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_7_PRJ_WEIGHTS, MBConv6_7_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_7_PRJ_F_HEIGHT, MBCONV_6_7_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_7_PRJ_F_DEPTH * MBCONV_6_7_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_8_EXPD_WEIGHTS, MBConv6_8_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_8_EXPD_F_HEIGHT,   MBCONV_6_8_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_8_EXPD_F_DEPTH * MBCONV_6_8_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_8_DW_WEIGHTS, MBConv6_8_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_8_DW_F_HEIGHT, MBCONV_6_8_DW_F_WIDTH, \n",
        "                            MBCONV_6_8_DW_F_DEPTH * MBCONV_6_8_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_8_SQZ_1_WEIGHTS, MBConv6_8_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_8_SQZ_1_F_HEIGHT, MBCONV_6_8_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_8_SQZ_1_F_DEPTH * MBCONV_6_8_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_8_SQZ_2_WEIGHTS, MBConv6_8_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_8_SQZ_2_F_HEIGHT, MBCONV_6_8_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_8_SQZ_2_F_DEPTH * MBCONV_6_8_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_8_PRJ_WEIGHTS, MBConv6_8_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_8_PRJ_F_HEIGHT, MBCONV_6_8_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_8_PRJ_F_DEPTH * MBCONV_6_8_PRJ_F_DENSITY);\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_9_EXPD_WEIGHTS, MBConv6_9_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_9_EXPD_F_HEIGHT,   MBCONV_6_9_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_9_EXPD_F_DEPTH * MBCONV_6_9_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_9_DW_WEIGHTS, MBConv6_9_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_9_DW_F_HEIGHT, MBCONV_6_9_DW_F_WIDTH, \n",
        "                            MBCONV_6_9_DW_F_DEPTH * MBCONV_6_9_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_9_SQZ_1_WEIGHTS, MBConv6_9_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_9_SQZ_1_F_HEIGHT, MBCONV_6_9_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_9_SQZ_1_F_DEPTH * MBCONV_6_9_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_9_SQZ_2_WEIGHTS, MBConv6_9_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_9_SQZ_2_F_HEIGHT, MBCONV_6_9_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_9_SQZ_2_F_DEPTH * MBCONV_6_9_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_9_PRJ_WEIGHTS, MBConv6_9_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_9_PRJ_F_HEIGHT, MBCONV_6_9_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_9_PRJ_F_DEPTH * MBCONV_6_9_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_10_EXPD_WEIGHTS, MBConv6_10_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_10_EXPD_F_HEIGHT,   MBCONV_6_10_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_10_EXPD_F_DEPTH * MBCONV_6_10_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_10_DW_WEIGHTS, MBConv6_10_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_10_DW_F_HEIGHT, MBCONV_6_10_DW_F_WIDTH, \n",
        "                            MBCONV_6_10_DW_F_DEPTH * MBCONV_6_10_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_10_SQZ_1_WEIGHTS, MBConv6_10_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_10_SQZ_1_F_HEIGHT, MBCONV_6_10_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_10_SQZ_1_F_DEPTH * MBCONV_6_10_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_10_SQZ_2_WEIGHTS, MBConv6_10_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_10_SQZ_2_F_HEIGHT, MBCONV_6_10_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_10_SQZ_2_F_DEPTH * MBCONV_6_10_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_10_PRJ_WEIGHTS, MBConv6_10_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_10_PRJ_F_HEIGHT, MBCONV_6_10_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_10_PRJ_F_DEPTH * MBCONV_6_10_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_11_EXPD_WEIGHTS, MBConv6_11_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_11_EXPD_F_HEIGHT,   MBCONV_6_11_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_11_EXPD_F_DEPTH * MBCONV_6_11_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_11_DW_WEIGHTS, MBConv6_11_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_11_DW_F_HEIGHT, MBCONV_6_11_DW_F_WIDTH, \n",
        "                            MBCONV_6_11_DW_F_DEPTH * MBCONV_6_11_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_11_SQZ_1_WEIGHTS, MBConv6_11_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_11_SQZ_1_F_HEIGHT, MBCONV_6_11_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_11_SQZ_1_F_DEPTH * MBCONV_6_11_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_11_SQZ_2_WEIGHTS, MBConv6_11_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_11_SQZ_2_F_HEIGHT, MBCONV_6_11_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_11_SQZ_2_F_DEPTH * MBCONV_6_11_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_11_PRJ_WEIGHTS, MBConv6_11_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_11_PRJ_F_HEIGHT, MBCONV_6_11_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_11_PRJ_F_DEPTH * MBCONV_6_11_PRJ_F_DENSITY);\n",
        "\n",
        " \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_12_EXPD_WEIGHTS, MBConv6_12_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_12_EXPD_F_HEIGHT,   MBCONV_6_12_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_12_EXPD_F_DEPTH * MBCONV_6_12_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_12_DW_WEIGHTS, MBConv6_12_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_12_DW_F_HEIGHT, MBCONV_6_12_DW_F_WIDTH, \n",
        "                            MBCONV_6_12_DW_F_DEPTH * MBCONV_6_12_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_12_SQZ_1_WEIGHTS, MBConv6_12_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_12_SQZ_1_F_HEIGHT, MBCONV_6_12_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_12_SQZ_1_F_DEPTH * MBCONV_6_12_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_12_SQZ_2_WEIGHTS, MBConv6_12_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_12_SQZ_2_F_HEIGHT, MBCONV_6_12_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_12_SQZ_2_F_DEPTH * MBCONV_6_12_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_12_PRJ_WEIGHTS, MBConv6_12_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_12_PRJ_F_HEIGHT, MBCONV_6_12_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_12_PRJ_F_DEPTH * MBCONV_6_12_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_13_EXPD_WEIGHTS, MBConv6_13_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_13_EXPD_F_HEIGHT,   MBCONV_6_13_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_13_EXPD_F_DEPTH * MBCONV_6_13_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_13_DW_WEIGHTS, MBConv6_13_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_13_DW_F_HEIGHT, MBCONV_6_13_DW_F_WIDTH, \n",
        "                            MBCONV_6_13_DW_F_DEPTH * MBCONV_6_13_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_13_SQZ_1_WEIGHTS, MBConv6_13_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_13_SQZ_1_F_HEIGHT, MBCONV_6_13_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_13_SQZ_1_F_DEPTH * MBCONV_6_13_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_13_SQZ_2_WEIGHTS, MBConv6_13_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_13_SQZ_2_F_HEIGHT, MBCONV_6_13_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_13_SQZ_2_F_DEPTH * MBCONV_6_13_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_13_PRJ_WEIGHTS, MBConv6_13_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_13_PRJ_F_HEIGHT, MBCONV_6_13_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_13_PRJ_F_DEPTH * MBCONV_6_13_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_14_EXPD_WEIGHTS, MBConv6_14_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_14_EXPD_F_HEIGHT,   MBCONV_6_14_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_14_EXPD_F_DEPTH * MBCONV_6_14_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_14_DW_WEIGHTS, MBConv6_14_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_14_DW_F_HEIGHT, MBCONV_6_14_DW_F_WIDTH, \n",
        "                            MBCONV_6_14_DW_F_DEPTH * MBCONV_6_14_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_14_SQZ_1_WEIGHTS, MBConv6_14_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_14_SQZ_1_F_HEIGHT, MBCONV_6_14_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_14_SQZ_1_F_DEPTH * MBCONV_6_14_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_14_SQZ_2_WEIGHTS, MBConv6_14_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_14_SQZ_2_F_HEIGHT, MBCONV_6_14_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_14_SQZ_2_F_DEPTH * MBCONV_6_14_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_14_PRJ_WEIGHTS, MBConv6_14_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_14_PRJ_F_HEIGHT, MBCONV_6_14_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_14_PRJ_F_DEPTH * MBCONV_6_14_PRJ_F_DENSITY);\n",
        "     \n",
        "  DEFINE_FILTERS_FOR_MBCONV(&D_MBConv_6_15_EXPD_WEIGHTS, MBConv6_15_expansion_conv_conv2d_weights, \n",
        "                            MBCONV_6_15_EXPD_F_HEIGHT,   MBCONV_6_15_EXPD_F_WIDTH, \n",
        "                            MBCONV_6_15_EXPD_F_DEPTH * MBCONV_6_15_EXPD_F_DENSITY,\n",
        "                            &D_MBConv_6_15_DW_WEIGHTS, MBConv6_15_depthwise_conv_conv2d_weights, \n",
        "                            MBCONV_6_15_DW_F_HEIGHT, MBCONV_6_15_DW_F_WIDTH, \n",
        "                            MBCONV_6_15_DW_F_DEPTH * MBCONV_6_15_DW_F_DENSITY,\n",
        "                            &D_MBConv_6_15_SQZ_1_WEIGHTS, MBConv6_15_squeeze_excitation1_conv2d_weights,\n",
        "                            MBCONV_6_15_SQZ_1_F_HEIGHT, MBCONV_6_15_SQZ_1_F_WIDTH, \n",
        "                            MBCONV_6_15_SQZ_1_F_DEPTH * MBCONV_6_15_SQZ_1_F_DENSITY,\n",
        "                            &D_MBConv_6_15_SQZ_2_WEIGHTS, MBConv6_15_squeeze_excitation2_conv2d_weights, \n",
        "                            MBCONV_6_15_SQZ_2_F_HEIGHT, MBCONV_6_15_SQZ_2_F_WIDTH, \n",
        "                            MBCONV_6_15_SQZ_2_F_DEPTH * MBCONV_6_15_SQZ_2_F_DENSITY,\n",
        "                            &D_MBConv_6_15_PRJ_WEIGHTS, MBConv6_15_project_conv_conv2d_weights, \n",
        "                            MBCONV_6_15_PRJ_F_HEIGHT, MBCONV_6_15_PRJ_F_WIDTH, \n",
        "                            MBCONV_6_15_PRJ_F_DEPTH * MBCONV_6_15_PRJ_F_DENSITY);\n",
        "\n",
        "\n",
        "  set_allocate_copy_array_Device(&HEAD_CONV_WEIGHTS, Head_conv2d_weights,\n",
        "                                  HEAD_CONV_F_HEIGHT, HEAD_CONV_F_WIDTH, HEAD_CONV_F_DEPTH * HEAD_CONV_F_DENSITY,\n",
        "                                \"Head Filter  is allocated in device memory\");   \n",
        " \n",
        "  set_allocate_copy_array_Device(&HEAD_FC_WEIGHTS, Head_linear_weights,\n",
        "                                HEAD_FC_F_HEIGHT, HEAD_FC_F_WIDTH, 1,\n",
        "                                \"Fully Connected weights matrix is allocated in device memory\");  \n",
        "  \n",
        "  // Define bias matrices for all squeeze layers\n",
        "  set_allocate_copy_array_Device(&MBConv6_15_SQZ_1_bias, MBConv6_15_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_15_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #15\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_14_SQZ_1_bias, MBConv6_14_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_14_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #14\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_13_SQZ_1_bias, MBConv6_13_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_13_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #13\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_12_SQZ_1_bias, MBConv6_12_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_12_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #12\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_11_SQZ_1_bias, MBConv6_11_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_11_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #11\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_10_SQZ_1_bias, MBConv6_10_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_10_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #10\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_9_SQZ_1_bias, MBConv6_9_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_9_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #9\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_8_SQZ_1_bias, MBConv6_8_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_8_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #8\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_7_SQZ_1_bias, MBConv6_7_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_7_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #7\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_6_SQZ_1_bias, MBConv6_6_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_6_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #6\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_5_SQZ_1_bias, MBConv6_5_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_5_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #5\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_4_SQZ_1_bias, MBConv6_4_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_4_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #4\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_3_SQZ_1_bias, MBConv6_3_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_3_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #3\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_2_SQZ_1_bias, MBConv6_2_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_2_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #2\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_1_SQZ_1_bias, MBConv6_1_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv6_1_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #1\");\n",
        "  set_allocate_copy_array_Device(&MBConv1_0_SQZ_1_bias, MBConv1_0_squeeze_excitation1_conv2d_bias,\n",
        "                                  sizeof(MBConv1_0_squeeze_excitation1_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 1 layer #0\");   \n",
        "  set_allocate_copy_array_Device(&MBConv6_15_SQZ_2_bias, MBConv6_15_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_15_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #15\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_14_SQZ_2_bias, MBConv6_14_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_14_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #14\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_13_SQZ_2_bias, MBConv6_13_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_13_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #13\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_12_SQZ_2_bias, MBConv6_12_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_12_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #12\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_11_SQZ_2_bias, MBConv6_11_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_11_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #11\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_10_SQZ_2_bias, MBConv6_10_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_10_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #10\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_9_SQZ_2_bias, MBConv6_9_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_9_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #9\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_8_SQZ_2_bias, MBConv6_8_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_8_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #8\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_7_SQZ_2_bias, MBConv6_7_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_7_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #7\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_6_SQZ_2_bias, MBConv6_6_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_6_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #6\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_5_SQZ_2_bias, MBConv6_5_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_5_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #5\");  \n",
        "  set_allocate_copy_array_Device(&MBConv6_4_SQZ_2_bias, MBConv6_4_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_4_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #4\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_3_SQZ_2_bias, MBConv6_3_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_3_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #3\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_2_SQZ_2_bias, MBConv6_2_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_2_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #2\");\n",
        "  set_allocate_copy_array_Device(&MBConv6_1_SQZ_2_bias, MBConv6_1_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv6_1_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #1\");\n",
        "  set_allocate_copy_array_Device(&MBConv1_0_SQZ_2_bias, MBConv1_0_squeeze_excitation2_conv2d_bias,\n",
        "                                  sizeof(MBConv1_0_squeeze_excitation2_conv2d_bias)/sizeof(float), 1, 1,\n",
        "                                  \"Bias for squeeze 2 layer #0\");    \n",
        " \n",
        "// 3. Define BN mean,variance, weights and bias\n",
        "MBCONV1_0_flag = 1;\n",
        " \n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_EXPD_BN_MEAN,      NULL, 0,\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_EXPD_BN_VARIANCE,\tNULL, 0,\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_EXPD_BN_WEIGHTS,\t\tNULL, 0,\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_EXPD_BN_BIAS,\t\t\tNULL, 0,\n",
        "\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_DW_BN_MEAN,        MBConv1_0_depthwise_conv_BN_mean,\t\t  sizeof(MBConv1_0_depthwise_conv_BN_mean) / sizeof(float), \t\t\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_DW_BN_VARIANCE,\t\tMBConv1_0_depthwise_conv_BN_variance,\tsizeof(MBConv1_0_depthwise_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_DW_BN_WEIGHTS,     MBConv1_0_depthwise_conv_BN_weights,\tsizeof(MBConv1_0_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_DW_BN_BIAS,\t\t\t\tMBConv1_0_depthwise_conv_BN_bias,\t\t  sizeof(MBConv1_0_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_PRJ_BN_MEAN,       MBConv1_0_project_conv_BN_mean,\t\t\t  sizeof(MBConv1_0_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_PRJ_BN_VARIANCE,\t\tMBConv1_0_project_conv_BN_variance,\t\tsizeof(MBConv1_0_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_PRJ_BN_WEIGHTS,    MBConv1_0_project_conv_BN_weights,\t\tsizeof(MBConv1_0_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv1_0_PRJ_BN_BIAS,\t\t\t\tMBConv1_0_project_conv_BN_bias, \t\t  sizeof(MBConv1_0_project_conv_BN_bias) / sizeof(float));\n",
        "\n",
        "MBCONV1_0_flag = 0;\n",
        " \n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_EXPD_BN_MEAN,      MBConv6_1_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_1_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_EXPD_BN_VARIANCE,\tMBConv6_1_expansion_conv_BN_variance,\tsizeof(MBConv6_1_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_EXPD_BN_WEIGHTS,   MBConv6_1_expansion_conv_BN_weights,\tsizeof(MBConv6_1_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_EXPD_BN_BIAS,\t\t\tMBConv6_1_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_1_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_DW_BN_MEAN,        MBConv6_1_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_1_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_DW_BN_VARIANCE,\t\tMBConv6_1_depthwise_conv_BN_variance,\tsizeof(MBConv6_1_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_DW_BN_WEIGHTS,     MBConv6_1_depthwise_conv_BN_weights,\tsizeof(MBConv6_1_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_DW_BN_BIAS,\t\t\t\tMBConv6_1_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_1_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_PRJ_BN_MEAN,       MBConv6_1_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_1_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_PRJ_BN_VARIANCE,\t\tMBConv6_1_project_conv_BN_variance,\t\tsizeof(MBConv6_1_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_PRJ_BN_WEIGHTS,    MBConv6_1_project_conv_BN_weights,\t\tsizeof(MBConv6_1_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_1_PRJ_BN_BIAS,\t\t\t\tMBConv6_1_project_conv_BN_bias, \t\t  sizeof(MBConv6_1_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_EXPD_BN_MEAN,      MBConv6_2_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_2_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_EXPD_BN_VARIANCE,\tMBConv6_2_expansion_conv_BN_variance,\tsizeof(MBConv6_2_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_EXPD_BN_WEIGHTS,   MBConv6_2_expansion_conv_BN_weights,\tsizeof(MBConv6_2_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_EXPD_BN_BIAS,\t\t\tMBConv6_2_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_2_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_DW_BN_MEAN,        MBConv6_2_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_2_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_DW_BN_VARIANCE,\t\tMBConv6_2_depthwise_conv_BN_variance,\tsizeof(MBConv6_2_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_DW_BN_WEIGHTS,     MBConv6_2_depthwise_conv_BN_weights,\tsizeof(MBConv6_2_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_DW_BN_BIAS,\t\t\t  MBConv6_2_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_2_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_PRJ_BN_MEAN,       MBConv6_2_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_2_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_PRJ_BN_VARIANCE,\t\tMBConv6_2_project_conv_BN_variance,\t\tsizeof(MBConv6_2_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_PRJ_BN_WEIGHTS,    MBConv6_2_project_conv_BN_weights,\t\tsizeof(MBConv6_2_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_2_PRJ_BN_BIAS,\t\t\t\tMBConv6_2_project_conv_BN_bias, \t\t  sizeof(MBConv6_2_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_EXPD_BN_MEAN,      MBConv6_3_expansion_conv_BN_mean, \t\tsizeof(MBConv6_3_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_EXPD_BN_VARIANCE,\tMBConv6_3_expansion_conv_BN_variance,\tsizeof(MBConv6_3_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_EXPD_BN_WEIGHTS,   MBConv6_3_expansion_conv_BN_weights,\tsizeof(MBConv6_3_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_EXPD_BN_BIAS,\t\t\tMBConv6_3_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_3_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_DW_BN_MEAN,        MBConv6_3_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_3_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_DW_BN_VARIANCE,\t\tMBConv6_3_depthwise_conv_BN_variance,\tsizeof(MBConv6_3_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_DW_BN_WEIGHTS,     MBConv6_3_depthwise_conv_BN_weights,\tsizeof(MBConv6_3_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_DW_BN_BIAS,\t\t\t\tMBConv6_3_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_3_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_PRJ_BN_MEAN,       MBConv6_3_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_3_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_PRJ_BN_VARIANCE,\t\tMBConv6_3_project_conv_BN_variance,\t\tsizeof(MBConv6_3_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_PRJ_BN_WEIGHTS,    MBConv6_3_project_conv_BN_weights,\t\tsizeof(MBConv6_3_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_3_PRJ_BN_BIAS,\t\t\t\tMBConv6_3_project_conv_BN_bias, \t\t  sizeof(MBConv6_3_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_EXPD_BN_MEAN,      MBConv6_4_expansion_conv_BN_mean, \t\tsizeof(MBConv6_4_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_EXPD_BN_VARIANCE,\tMBConv6_4_expansion_conv_BN_variance,\tsizeof(MBConv6_4_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_EXPD_BN_WEIGHTS,   MBConv6_4_expansion_conv_BN_weights,\tsizeof(MBConv6_4_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_EXPD_BN_BIAS,\t\t\tMBConv6_4_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_4_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_DW_BN_MEAN,        MBConv6_4_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_4_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_DW_BN_VARIANCE,\t\tMBConv6_4_depthwise_conv_BN_variance,\tsizeof(MBConv6_4_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_DW_BN_WEIGHTS,     MBConv6_4_depthwise_conv_BN_weights,\tsizeof(MBConv6_4_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_DW_BN_BIAS,\t\t\t\tMBConv6_4_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_4_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_PRJ_BN_MEAN,       MBConv6_4_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_4_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_PRJ_BN_VARIANCE,\t\tMBConv6_4_project_conv_BN_variance,\t\tsizeof(MBConv6_4_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_4_PRJ_BN_WEIGHTS,    MBConv6_4_project_conv_BN_weights,\t\tsizeof(MBConv6_4_project_conv_BN_weights) / sizeof(float),\n",
        "                &MBConv6_4_PRJ_BN_BIAS,\t\t\t\tMBConv6_4_project_conv_BN_bias, \t\t  sizeof(MBConv6_4_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_EXPD_BN_MEAN,      MBConv6_5_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_5_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_EXPD_BN_VARIANCE,\tMBConv6_5_expansion_conv_BN_variance,\tsizeof(MBConv6_5_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_EXPD_BN_WEIGHTS,   MBConv6_5_expansion_conv_BN_weights,\tsizeof(MBConv6_5_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_EXPD_BN_BIAS,\t\t\tMBConv6_5_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_5_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_DW_BN_MEAN,        MBConv6_5_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_5_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_DW_BN_VARIANCE,\t\tMBConv6_5_depthwise_conv_BN_variance,\tsizeof(MBConv6_5_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_DW_BN_WEIGHTS,     MBConv6_5_depthwise_conv_BN_weights,\tsizeof(MBConv6_5_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_DW_BN_BIAS,\t\t\t\tMBConv6_5_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_5_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_PRJ_BN_MEAN,       MBConv6_5_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_5_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_PRJ_BN_VARIANCE,\t\tMBConv6_5_project_conv_BN_variance,\t\tsizeof(MBConv6_5_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_PRJ_BN_WEIGHTS,    MBConv6_5_project_conv_BN_weights,\t\tsizeof(MBConv6_5_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_5_PRJ_BN_BIAS,\t\t\t\tMBConv6_5_project_conv_BN_bias, \t\t  sizeof(MBConv6_5_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_EXPD_BN_MEAN,      MBConv6_6_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_6_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_EXPD_BN_VARIANCE,\tMBConv6_6_expansion_conv_BN_variance,\tsizeof(MBConv6_6_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_EXPD_BN_WEIGHTS,   MBConv6_6_expansion_conv_BN_weights,\tsizeof(MBConv6_6_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_EXPD_BN_BIAS,\t\t\tMBConv6_6_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_6_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_DW_BN_MEAN,        MBConv6_6_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_6_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_DW_BN_VARIANCE,\t\tMBConv6_6_depthwise_conv_BN_variance,\tsizeof(MBConv6_6_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_DW_BN_WEIGHTS,     MBConv6_6_depthwise_conv_BN_weights,\tsizeof(MBConv6_6_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_DW_BN_BIAS,\t\t\t\tMBConv6_6_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_6_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_PRJ_BN_MEAN,       MBConv6_6_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_6_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_PRJ_BN_VARIANCE,\t\tMBConv6_6_project_conv_BN_variance,\t\tsizeof(MBConv6_6_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_PRJ_BN_WEIGHTS,    MBConv6_6_project_conv_BN_weights,\t\tsizeof(MBConv6_6_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_6_PRJ_BN_BIAS,\t\t\t\tMBConv6_6_project_conv_BN_bias, \t\t  sizeof(MBConv6_6_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_EXPD_BN_MEAN,      MBConv6_7_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_7_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_EXPD_BN_VARIANCE,\tMBConv6_7_expansion_conv_BN_variance,\tsizeof(MBConv6_7_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_EXPD_BN_WEIGHTS,   MBConv6_7_expansion_conv_BN_weights,\tsizeof(MBConv6_7_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_EXPD_BN_BIAS,\t\t\tMBConv6_7_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_7_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_DW_BN_MEAN,        MBConv6_7_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_7_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_DW_BN_VARIANCE,\t\tMBConv6_7_depthwise_conv_BN_variance,\tsizeof(MBConv6_7_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_DW_BN_WEIGHTS,     MBConv6_7_depthwise_conv_BN_weights,\tsizeof(MBConv6_7_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_DW_BN_BIAS,\t\t\t\tMBConv6_7_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_7_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_PRJ_BN_MEAN,       MBConv6_7_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_7_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_PRJ_BN_VARIANCE,\t\tMBConv6_7_project_conv_BN_variance,\t\tsizeof(MBConv6_7_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_PRJ_BN_WEIGHTS,    MBConv6_7_project_conv_BN_weights,\t\tsizeof(MBConv6_7_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_7_PRJ_BN_BIAS,\t\t\t\tMBConv6_7_project_conv_BN_bias, \t\t  sizeof(MBConv6_7_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_EXPD_BN_MEAN,      MBConv6_8_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_8_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_EXPD_BN_VARIANCE,\tMBConv6_8_expansion_conv_BN_variance,\tsizeof(MBConv6_8_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_EXPD_BN_WEIGHTS,   MBConv6_8_expansion_conv_BN_weights,\tsizeof(MBConv6_8_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_EXPD_BN_BIAS,\t\t\tMBConv6_8_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_8_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_DW_BN_MEAN,        MBConv6_8_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_8_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_DW_BN_VARIANCE,\t\tMBConv6_8_depthwise_conv_BN_variance,\tsizeof(MBConv6_8_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_DW_BN_WEIGHTS,     MBConv6_8_depthwise_conv_BN_weights,\tsizeof(MBConv6_8_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_DW_BN_BIAS,\t\t\t\tMBConv6_8_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_8_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_PRJ_BN_MEAN,       MBConv6_8_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_8_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_PRJ_BN_VARIANCE,\t\tMBConv6_8_project_conv_BN_variance,\t\tsizeof(MBConv6_8_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_PRJ_BN_WEIGHTS,    MBConv6_8_project_conv_BN_weights,\t\tsizeof(MBConv6_8_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_8_PRJ_BN_BIAS,\t\t\t\tMBConv6_8_project_conv_BN_bias, \t\t  sizeof(MBConv6_8_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_EXPD_BN_MEAN,      MBConv6_9_expansion_conv_BN_mean,\t\t  sizeof(MBConv6_9_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_EXPD_BN_VARIANCE,\tMBConv6_9_expansion_conv_BN_variance,\tsizeof(MBConv6_9_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_EXPD_BN_WEIGHTS,   MBConv6_9_expansion_conv_BN_weights,\tsizeof(MBConv6_9_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_EXPD_BN_BIAS,\t\t\tMBConv6_9_expansion_conv_BN_bias,\t\t  sizeof(MBConv6_9_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_DW_BN_MEAN,        MBConv6_9_depthwise_conv_BN_mean,\t\t  sizeof(MBConv6_9_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_DW_BN_VARIANCE,\t\tMBConv6_9_depthwise_conv_BN_variance,\tsizeof(MBConv6_9_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_DW_BN_WEIGHTS,     MBConv6_9_depthwise_conv_BN_weights,\tsizeof(MBConv6_9_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_DW_BN_BIAS,\t\t\t\tMBConv6_9_depthwise_conv_BN_bias,\t\t  sizeof(MBConv6_9_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_PRJ_BN_MEAN,       MBConv6_9_project_conv_BN_mean,\t\t\t  sizeof(MBConv6_9_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_PRJ_BN_VARIANCE,\t\tMBConv6_9_project_conv_BN_variance,\t\tsizeof(MBConv6_9_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_PRJ_BN_WEIGHTS,    MBConv6_9_project_conv_BN_weights,\t\tsizeof(MBConv6_9_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_9_PRJ_BN_BIAS,\t\t\t\tMBConv6_9_project_conv_BN_bias, \t\t  sizeof(MBConv6_9_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_EXPD_BN_MEAN,     MBConv6_10_expansion_conv_BN_mean,    sizeof(MBConv6_10_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_EXPD_BN_VARIANCE,\tMBConv6_10_expansion_conv_BN_variance,sizeof(MBConv6_10_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_EXPD_BN_WEIGHTS,  MBConv6_10_expansion_conv_BN_weights,\tsizeof(MBConv6_10_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_EXPD_BN_BIAS,\t\t\tMBConv6_10_expansion_conv_BN_bias,\t\tsizeof(MBConv6_10_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_DW_BN_MEAN,       MBConv6_10_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_10_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_DW_BN_VARIANCE,\t\tMBConv6_10_depthwise_conv_BN_variance,sizeof(MBConv6_10_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_DW_BN_WEIGHTS,    MBConv6_10_depthwise_conv_BN_weights,\tsizeof(MBConv6_10_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_DW_BN_BIAS,\t\t\t\tMBConv6_10_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_10_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_PRJ_BN_MEAN,      MBConv6_10_project_conv_BN_mean,\t\t  sizeof(MBConv6_10_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_PRJ_BN_VARIANCE,\tMBConv6_10_project_conv_BN_variance,\tsizeof(MBConv6_10_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_PRJ_BN_WEIGHTS,   MBConv6_10_project_conv_BN_weights,\t\tsizeof(MBConv6_10_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_10_PRJ_BN_BIAS,\t\t\tMBConv6_10_project_conv_BN_bias, \t\t  sizeof(MBConv6_10_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_EXPD_BN_MEAN,     MBConv6_11_expansion_conv_BN_mean,\t\tsizeof(MBConv6_11_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_EXPD_BN_VARIANCE,\tMBConv6_11_expansion_conv_BN_variance,sizeof(MBConv6_11_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_EXPD_BN_WEIGHTS,  MBConv6_11_expansion_conv_BN_weights,\tsizeof(MBConv6_11_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_EXPD_BN_BIAS,\t\t\tMBConv6_11_expansion_conv_BN_bias,\t\tsizeof(MBConv6_11_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_DW_BN_MEAN,       MBConv6_11_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_11_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_DW_BN_VARIANCE,\t\tMBConv6_11_depthwise_conv_BN_variance,sizeof(MBConv6_11_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_DW_BN_WEIGHTS,    MBConv6_11_depthwise_conv_BN_weights,\tsizeof(MBConv6_11_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_DW_BN_BIAS,\t\t\t\tMBConv6_11_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_11_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_PRJ_BN_MEAN,      MBConv6_11_project_conv_BN_mean,\t\t  sizeof(MBConv6_11_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_PRJ_BN_VARIANCE,\tMBConv6_11_project_conv_BN_variance,\tsizeof(MBConv6_11_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_PRJ_BN_WEIGHTS,   MBConv6_11_project_conv_BN_weights,\t\tsizeof(MBConv6_11_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_11_PRJ_BN_BIAS,\t\t\tMBConv6_11_project_conv_BN_bias, \t\t  sizeof(MBConv6_11_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_EXPD_BN_MEAN,     MBConv6_12_expansion_conv_BN_mean,\t\tsizeof(MBConv6_12_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_EXPD_BN_VARIANCE,\tMBConv6_12_expansion_conv_BN_variance,sizeof(MBConv6_12_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_EXPD_BN_WEIGHTS,  MBConv6_12_expansion_conv_BN_weights,\tsizeof(MBConv6_12_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_EXPD_BN_BIAS,\t\t\tMBConv6_12_expansion_conv_BN_bias,\t\tsizeof(MBConv6_12_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_DW_BN_MEAN,       MBConv6_12_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_12_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_DW_BN_VARIANCE,\t\tMBConv6_12_depthwise_conv_BN_variance,sizeof(MBConv6_12_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_DW_BN_WEIGHTS,    MBConv6_12_depthwise_conv_BN_weights,\tsizeof(MBConv6_12_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_DW_BN_BIAS,\t\t\t\tMBConv6_12_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_12_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_PRJ_BN_MEAN,      MBConv6_12_project_conv_BN_mean,\t\t  sizeof(MBConv6_12_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_PRJ_BN_VARIANCE,\tMBConv6_12_project_conv_BN_variance,\tsizeof(MBConv6_12_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_PRJ_BN_WEIGHTS,   MBConv6_12_project_conv_BN_weights,\t\tsizeof(MBConv6_12_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_12_PRJ_BN_BIAS,\t\t\tMBConv6_12_project_conv_BN_bias, \t\t  sizeof(MBConv6_12_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_EXPD_BN_MEAN,     MBConv6_13_expansion_conv_BN_mean,\t\tsizeof(MBConv6_13_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_EXPD_BN_VARIANCE,\tMBConv6_13_expansion_conv_BN_variance,sizeof(MBConv6_13_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_EXPD_BN_WEIGHTS,  MBConv6_13_expansion_conv_BN_weights,\tsizeof(MBConv6_13_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_EXPD_BN_BIAS,\t\t\tMBConv6_13_expansion_conv_BN_bias,\t\tsizeof(MBConv6_13_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_DW_BN_MEAN,       MBConv6_13_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_13_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_DW_BN_VARIANCE,\t\tMBConv6_13_depthwise_conv_BN_variance,sizeof(MBConv6_13_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_DW_BN_WEIGHTS,    MBConv6_13_depthwise_conv_BN_weights,\tsizeof(MBConv6_13_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_DW_BN_BIAS,\t\t\t\tMBConv6_13_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_13_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_PRJ_BN_MEAN,      MBConv6_13_project_conv_BN_mean,\t\t  sizeof(MBConv6_13_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_PRJ_BN_VARIANCE,\tMBConv6_13_project_conv_BN_variance,\tsizeof(MBConv6_13_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_PRJ_BN_WEIGHTS,   MBConv6_13_project_conv_BN_weights,\t\tsizeof(MBConv6_13_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_13_PRJ_BN_BIAS,\t\t\tMBConv6_13_project_conv_BN_bias, \t\t  sizeof(MBConv6_13_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_EXPD_BN_MEAN,     MBConv6_14_expansion_conv_BN_mean,\t\tsizeof(MBConv6_14_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_EXPD_BN_VARIANCE,\tMBConv6_14_expansion_conv_BN_variance,sizeof(MBConv6_14_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_EXPD_BN_WEIGHTS,  MBConv6_14_expansion_conv_BN_weights,\tsizeof(MBConv6_14_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_EXPD_BN_BIAS,\t\t\tMBConv6_14_expansion_conv_BN_bias,\t\tsizeof(MBConv6_14_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_DW_BN_MEAN,       MBConv6_14_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_14_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_DW_BN_VARIANCE,\t\tMBConv6_14_depthwise_conv_BN_variance,sizeof(MBConv6_14_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_DW_BN_WEIGHTS,    MBConv6_14_depthwise_conv_BN_weights,\tsizeof(MBConv6_14_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_DW_BN_BIAS,\t\t\t\tMBConv6_14_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_14_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_PRJ_BN_MEAN,      MBConv6_14_project_conv_BN_mean,\t\t  sizeof(MBConv6_14_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_PRJ_BN_VARIANCE,\tMBConv6_14_project_conv_BN_variance,\tsizeof(MBConv6_14_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_PRJ_BN_WEIGHTS,   MBConv6_14_project_conv_BN_weights,\t\tsizeof(MBConv6_14_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_14_PRJ_BN_BIAS,\t\t\tMBConv6_14_project_conv_BN_bias, \t\t  sizeof(MBConv6_14_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "DEFINE_FILTERS_FOR_MBCONV_BN(\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_EXPD_BN_MEAN,     MBConv6_15_expansion_conv_BN_mean,\t\tsizeof(MBConv6_15_expansion_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_EXPD_BN_VARIANCE,\tMBConv6_15_expansion_conv_BN_variance,sizeof(MBConv6_15_expansion_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_EXPD_BN_WEIGHTS,  MBConv6_15_expansion_conv_BN_weights,\tsizeof(MBConv6_15_expansion_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_EXPD_BN_BIAS,\t\t\tMBConv6_15_expansion_conv_BN_bias,\t\tsizeof(MBConv6_15_expansion_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_DW_BN_MEAN,       MBConv6_15_depthwise_conv_BN_mean,\t\tsizeof(MBConv6_15_depthwise_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_DW_BN_VARIANCE,\t\tMBConv6_15_depthwise_conv_BN_variance,sizeof(MBConv6_15_depthwise_conv_BN_variance) / sizeof(float),\t\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_DW_BN_WEIGHTS,    MBConv6_15_depthwise_conv_BN_weights,\tsizeof(MBConv6_15_depthwise_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_DW_BN_BIAS,\t\t\t\tMBConv6_15_depthwise_conv_BN_bias,\t\tsizeof(MBConv6_15_depthwise_conv_BN_bias) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_PRJ_BN_MEAN,      MBConv6_15_project_conv_BN_mean,\t\t  sizeof(MBConv6_15_project_conv_BN_mean) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_PRJ_BN_VARIANCE,\tMBConv6_15_project_conv_BN_variance,\tsizeof(MBConv6_15_project_conv_BN_variance) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_PRJ_BN_WEIGHTS,   MBConv6_15_project_conv_BN_weights,\t\tsizeof(MBConv6_15_project_conv_BN_weights) / sizeof(float),\n",
        "\t\t\t\t\t\t\t\t&MBConv6_15_PRJ_BN_BIAS,\t\t\tMBConv6_15_project_conv_BN_bias, \t\t  sizeof(MBConv6_15_project_conv_BN_bias) / sizeof(float));\n",
        "\t\t\t\t\t\t\t\t\n",
        "\n",
        "set_allocate_copy_array_Device(&D_STEM_BN_MEAN, Stem_BN_mean,\n",
        "                sizeof(Stem_BN_mean)/sizeof(float), 1, 1,\n",
        "                \"STEM MEAN\"); \n",
        "set_allocate_copy_array_Device(&D_STEM_BN_VARIANCE, Stem_BN_variance,\n",
        "                sizeof(Stem_BN_variance)/sizeof(float), 1, 1,\n",
        "                \"STEAM VARIANCE\"); \n",
        "set_allocate_copy_array_Device(&D_STEM_BN_WEIGHTS, Stem_BN_weights,\n",
        "                sizeof(Stem_BN_weights)/sizeof(float), 1, 1,\n",
        "                \"STEM WEIGHTS\"); \n",
        "set_allocate_copy_array_Device(&D_STEM_BN_BIAS, Stem_BN_bias,\n",
        "                sizeof(Stem_BN_bias)/sizeof(float), 1, 1,\n",
        "                \"STEM BIAS\"); \n",
        "                \n",
        "\n",
        "set_allocate_copy_array_Device(&D_HEAD_BN_MEAN, Head_BN_mean,\n",
        "                sizeof(Head_BN_mean)/sizeof(float), 1, 1,\n",
        "                \"HEAD MEAN\"); \n",
        "set_allocate_copy_array_Device(&D_HEAD_BN_VARIANCE, Head_BN_variance,\n",
        "                sizeof(Head_BN_variance)/sizeof(float), 1, 1,\n",
        "                \"HEAD VARIANCE\"); \n",
        "set_allocate_copy_array_Device(&D_HEAD_BN_WEIGHTS, Head_BN_weights,\n",
        "                sizeof(Head_BN_weights)/sizeof(float), 1, 1,\n",
        "                \"HEAD WEIGHTS\"); \n",
        "set_allocate_copy_array_Device(&D_HEAD_BN_BIAS, Head_BN_bias,\n",
        "                sizeof(Head_BN_bias)/sizeof(float), 1, 1,\n",
        "                \"HEAD BIAS\"); \n",
        "\n",
        "\n",
        "start();\n",
        "  // 3. Move through all layers starting from stem layer till head layer\n",
        "  Matrix ConvOutStem;\n",
        "  STEM_LAYER(&DInput_Mat, &F_STEM,\n",
        "              INPUT_IMAGE_HEIGHT, INPUT_IMAGE_WIDTH, INPUT_IMAGE_DEPTH,\n",
        "              STEM_FILTER_HEIGHT, STEM_FILTER_WIDTH, STEM_FILTER_DEPTH, STEM_FILTER_DENSITY,\n",
        "              STEM_PADDING, STEM_STRIDE,\n",
        "              &ConvOutStem);\n",
        "\n",
        "\n",
        "  Matrix ConvOut1_0;\n",
        "  MBCONV1_0_flag = 1;  \n",
        "\n",
        "  MBConv_Layer(&ConvOutStem, &ConvOut1_0,\n",
        "                &D_MBConv_1_0_EXPD_WEIGHTS,       &D_MBConv_1_0_DW_WEIGHTS,\n",
        "                &D_MBConv_1_0_SQZ_1_WEIGHTS,      &D_MBConv_1_0_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_1_0_PRJ_WEIGHTS,\n",
        "                MBCONV_1_0_EXPD_F_DENSITY,        MBCONV_1_0_DW_F_DENSITY, \n",
        "                MBCONV_1_0_SQZ_1_F_DENSITY,       MBCONV_1_0_SQZ_2_F_DENSITY, \n",
        "                MBCONV_1_0_PRJ_F_DENSITY,\n",
        "                ConvOutStem.depth,                MBCONV_1_0_PRJ_F_DENSITY, MBCONV_1_0_DW_F_HEIGHT,\n",
        "                MBCONV_1_0_STRIDE,                MBCONV_1_0_PADDING, MBCONV_1_0_SKIP,\n",
        "                &MBConv1_0_SQZ_1_bias, \t          &MBConv1_0_SQZ_2_bias,\n",
        "                NULL, NULL,\n",
        "                NULL, NULL,\n",
        "                &MBConv1_0_DW_BN_MEAN,           \t&MBConv1_0_DW_BN_VARIANCE,\n",
        "                &MBConv1_0_DW_BN_WEIGHTS,        \t&MBConv1_0_DW_BN_BIAS,\n",
        "                &MBConv1_0_PRJ_BN_MEAN,           &MBConv1_0_PRJ_BN_VARIANCE,\n",
        "                &MBConv1_0_PRJ_BN_WEIGHTS,        &MBConv1_0_PRJ_BN_BIAS);\n",
        "  MBCONV1_0_flag = 0;\n",
        "  \n",
        "\n",
        "  Matrix ConvOut;\n",
        "  MBConv_Layer(&ConvOut1_0, &ConvOut,\n",
        "                &D_MBConv_6_1_EXPD_WEIGHTS,       &D_MBConv_6_1_DW_WEIGHTS,\n",
        "                &D_MBConv_6_1_SQZ_1_WEIGHTS,      &D_MBConv_6_1_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_1_PRJ_WEIGHTS,\n",
        "                MBCONV_6_1_EXPD_F_DENSITY,        MBCONV_6_1_DW_F_DENSITY, \n",
        "                MBCONV_6_1_SQZ_1_F_DENSITY,       MBCONV_6_1_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_1_PRJ_F_DENSITY,\n",
        "                ConvOut1_0.depth,                 MBCONV_6_1_PRJ_F_DENSITY, MBCONV_6_1_DW_F_HEIGHT,\n",
        "                MBCONV_6_1_STRIDE,                MBCONV_6_1_PADDING, MBCONV_6_1_SKIP,\n",
        "                &MBConv6_1_SQZ_1_bias, \t          &MBConv6_1_SQZ_2_bias,\n",
        "                &MBConv6_1_EXPD_BN_MEAN,          &MBConv6_1_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_1_EXPD_BN_WEIGHTS,       &MBConv6_1_EXPD_BN_BIAS,\n",
        "                &MBConv6_1_DW_BN_MEAN,           \t&MBConv6_1_DW_BN_VARIANCE,\n",
        "                &MBConv6_1_DW_BN_WEIGHTS,        \t&MBConv6_1_DW_BN_BIAS,\n",
        "                &MBConv6_1_PRJ_BN_MEAN,           &MBConv6_1_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_1_PRJ_BN_WEIGHTS,        &MBConv6_1_PRJ_BN_BIAS);\n",
        "\n",
        "\n",
        "  Matrix ConvOut2;\n",
        "  MBConv_Layer(&ConvOut, &ConvOut2,\n",
        "                &D_MBConv_6_2_EXPD_WEIGHTS,       &D_MBConv_6_2_DW_WEIGHTS,\n",
        "                &D_MBConv_6_2_SQZ_1_WEIGHTS,      &D_MBConv_6_2_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_2_PRJ_WEIGHTS,\n",
        "                MBCONV_6_2_EXPD_F_DENSITY,        MBCONV_6_2_DW_F_DENSITY, \n",
        "                MBCONV_6_2_SQZ_1_F_DENSITY,       MBCONV_6_2_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_2_PRJ_F_DENSITY,\n",
        "                ConvOut.depth,                    MBCONV_6_2_PRJ_F_DENSITY, MBCONV_6_2_DW_F_HEIGHT,\n",
        "                MBCONV_6_2_STRIDE,                MBCONV_6_2_PADDING, MBCONV_6_2_SKIP,\n",
        "                &MBConv6_2_SQZ_1_bias, \t          &MBConv6_2_SQZ_2_bias,\n",
        "                &MBConv6_2_EXPD_BN_MEAN,          &MBConv6_2_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_2_EXPD_BN_WEIGHTS,       &MBConv6_2_EXPD_BN_BIAS,\n",
        "                &MBConv6_2_DW_BN_MEAN,           \t&MBConv6_2_DW_BN_VARIANCE,\n",
        "                &MBConv6_2_DW_BN_WEIGHTS,        \t&MBConv6_2_DW_BN_BIAS,\n",
        "                &MBConv6_2_PRJ_BN_MEAN,           &MBConv6_2_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_2_PRJ_BN_WEIGHTS,        &MBConv6_2_PRJ_BN_BIAS); \n",
        "\n",
        "\n",
        "  Matrix ConvOut3;\n",
        "\tMBConv_Layer(&ConvOut2, &ConvOut3,\n",
        "                  &D_MBConv_6_3_EXPD_WEIGHTS,       &D_MBConv_6_3_DW_WEIGHTS,\n",
        "                  &D_MBConv_6_3_SQZ_1_WEIGHTS,      &D_MBConv_6_3_SQZ_2_WEIGHTS,\n",
        "                  &D_MBConv_6_3_PRJ_WEIGHTS,\n",
        "                  MBCONV_6_3_EXPD_F_DENSITY,        MBCONV_6_3_DW_F_DENSITY, \n",
        "                  MBCONV_6_3_SQZ_1_F_DENSITY,       MBCONV_6_3_SQZ_2_F_DENSITY, \n",
        "                  MBCONV_6_3_PRJ_F_DENSITY,\n",
        "                  ConvOut2.depth,                   MBCONV_6_3_PRJ_F_DENSITY, MBCONV_6_3_DW_F_HEIGHT,\n",
        "                  MBCONV_6_3_STRIDE,                MBCONV_6_3_PADDING, MBCONV_6_3_SKIP,\n",
        "                  &MBConv6_3_SQZ_1_bias,  \t        &MBConv6_3_SQZ_2_bias,\n",
        "\t\t\t\t\t\t\t\t\t&MBConv6_3_EXPD_BN_MEAN,          &MBConv6_3_EXPD_BN_VARIANCE,\n",
        "\t\t\t\t\t\t\t\t\t&MBConv6_3_EXPD_BN_WEIGHTS,       &MBConv6_3_EXPD_BN_BIAS,\n",
        "\t\t\t\t\t\t\t\t\t&MBConv6_3_DW_BN_MEAN,           \t&MBConv6_3_DW_BN_VARIANCE,\n",
        "\t\t\t\t\t\t\t\t\t&MBConv6_3_DW_BN_WEIGHTS,        \t&MBConv6_3_DW_BN_BIAS,\n",
        "\t\t\t\t\t\t\t\t\t&MBConv6_3_PRJ_BN_MEAN,           &MBConv6_3_PRJ_BN_VARIANCE,\n",
        "\t\t\t\t\t\t\t\t\t&MBConv6_3_PRJ_BN_WEIGHTS,        &MBConv6_3_PRJ_BN_BIAS);  \n",
        " \n",
        "\n",
        "  // MBConv6_4 layer implementation\n",
        "\n",
        "  Matrix ConvOut4;\n",
        "  MBConv_Layer(&ConvOut3, &ConvOut4,\n",
        "                &D_MBConv_6_4_EXPD_WEIGHTS,       &D_MBConv_6_4_DW_WEIGHTS,\n",
        "                &D_MBConv_6_4_SQZ_1_WEIGHTS,      &D_MBConv_6_4_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_4_PRJ_WEIGHTS,\n",
        "                MBCONV_6_4_EXPD_F_DENSITY,        MBCONV_6_4_DW_F_DENSITY, \n",
        "                MBCONV_6_4_SQZ_1_F_DENSITY,       MBCONV_6_4_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_4_PRJ_F_DENSITY,\n",
        "                ConvOut3.depth,                   MBCONV_6_4_PRJ_F_DENSITY, MBCONV_6_4_DW_F_HEIGHT,\n",
        "                MBCONV_6_4_STRIDE,                MBCONV_6_4_PADDING, MBCONV_6_4_SKIP,\n",
        "                &MBConv6_4_SQZ_1_bias,  \t        &MBConv6_4_SQZ_2_bias,\n",
        "                &MBConv6_4_EXPD_BN_MEAN,          &MBConv6_4_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_4_EXPD_BN_WEIGHTS,       &MBConv6_4_EXPD_BN_BIAS,\n",
        "                &MBConv6_4_DW_BN_MEAN,           \t&MBConv6_4_DW_BN_VARIANCE,\n",
        "                &MBConv6_4_DW_BN_WEIGHTS,        \t&MBConv6_4_DW_BN_BIAS,\n",
        "                &MBConv6_4_PRJ_BN_MEAN,           &MBConv6_4_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_4_PRJ_BN_WEIGHTS,        &MBConv6_4_PRJ_BN_BIAS);   \n",
        "  \n",
        "\n",
        "  Matrix ConvOut5;\n",
        "  MBConv_Layer(&ConvOut4, &ConvOut5,\n",
        "                &D_MBConv_6_5_EXPD_WEIGHTS,       &D_MBConv_6_5_DW_WEIGHTS,\n",
        "                &D_MBConv_6_5_SQZ_1_WEIGHTS,      &D_MBConv_6_5_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_5_PRJ_WEIGHTS,\n",
        "                MBCONV_6_5_EXPD_F_DENSITY,        MBCONV_6_5_DW_F_DENSITY, \n",
        "                MBCONV_6_5_SQZ_1_F_DENSITY,       MBCONV_6_5_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_5_PRJ_F_DENSITY,\n",
        "                ConvOut4.depth,                   MBCONV_6_5_PRJ_F_DENSITY, MBCONV_6_5_DW_F_HEIGHT,\n",
        "                MBCONV_6_5_STRIDE,                MBCONV_6_5_PADDING, MBCONV_6_5_SKIP,\n",
        "                &MBConv6_5_SQZ_1_bias,  \t        &MBConv6_5_SQZ_2_bias,\n",
        "                &MBConv6_5_EXPD_BN_MEAN,          &MBConv6_5_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_5_EXPD_BN_WEIGHTS,       &MBConv6_5_EXPD_BN_BIAS,\n",
        "                &MBConv6_5_DW_BN_MEAN,           \t&MBConv6_5_DW_BN_VARIANCE,\n",
        "                &MBConv6_5_DW_BN_WEIGHTS,        \t&MBConv6_5_DW_BN_BIAS,\n",
        "                &MBConv6_5_PRJ_BN_MEAN,           &MBConv6_5_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_5_PRJ_BN_WEIGHTS,        &MBConv6_5_PRJ_BN_BIAS); \n",
        "            \n",
        "\n",
        "\n",
        "  // MBConv6_6 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut6;\n",
        "  MBConv_Layer(&ConvOut5, &ConvOut6,\n",
        "                &D_MBConv_6_6_EXPD_WEIGHTS,       &D_MBConv_6_6_DW_WEIGHTS,\n",
        "                &D_MBConv_6_6_SQZ_1_WEIGHTS,      &D_MBConv_6_6_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_6_PRJ_WEIGHTS,\n",
        "                MBCONV_6_6_EXPD_F_DENSITY,        MBCONV_6_6_DW_F_DENSITY, \n",
        "                MBCONV_6_6_SQZ_1_F_DENSITY,       MBCONV_6_6_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_6_PRJ_F_DENSITY,\n",
        "                ConvOut5.depth,                   MBCONV_6_6_PRJ_F_DENSITY, MBCONV_6_6_DW_F_HEIGHT,\n",
        "                MBCONV_6_6_STRIDE,                MBCONV_6_6_PADDING, MBCONV_6_6_SKIP,\n",
        "                &MBConv6_6_SQZ_1_bias, \t          &MBConv6_6_SQZ_2_bias,\n",
        "                &MBConv6_6_EXPD_BN_MEAN,          &MBConv6_6_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_6_EXPD_BN_WEIGHTS,       &MBConv6_6_EXPD_BN_BIAS,\n",
        "                &MBConv6_6_DW_BN_MEAN,           \t&MBConv6_6_DW_BN_VARIANCE,\n",
        "                &MBConv6_6_DW_BN_WEIGHTS,        \t&MBConv6_6_DW_BN_BIAS,\n",
        "                &MBConv6_6_PRJ_BN_MEAN,           &MBConv6_6_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_6_PRJ_BN_WEIGHTS,        &MBConv6_6_PRJ_BN_BIAS);  \n",
        "            \n",
        "\n",
        "\n",
        "  // MBConv6_7 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut7;\n",
        "  MBConv_Layer(&ConvOut6, &ConvOut7,\n",
        "                &D_MBConv_6_7_EXPD_WEIGHTS,       &D_MBConv_6_7_DW_WEIGHTS,\n",
        "                &D_MBConv_6_7_SQZ_1_WEIGHTS,      &D_MBConv_6_7_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_7_PRJ_WEIGHTS,\n",
        "                MBCONV_6_7_EXPD_F_DENSITY,        MBCONV_6_7_DW_F_DENSITY, \n",
        "                MBCONV_6_7_SQZ_1_F_DENSITY,       MBCONV_6_7_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_7_PRJ_F_DENSITY,\n",
        "                ConvOut6.depth,                   MBCONV_6_7_PRJ_F_DENSITY, MBCONV_6_7_DW_F_HEIGHT,                   \n",
        "                MBCONV_6_7_STRIDE,                MBCONV_6_7_PADDING, MBCONV_6_7_SKIP,\n",
        "                &MBConv6_7_SQZ_1_bias,  \t        &MBConv6_7_SQZ_2_bias,\n",
        "                &MBConv6_7_EXPD_BN_MEAN,          &MBConv6_7_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_7_EXPD_BN_WEIGHTS,       &MBConv6_7_EXPD_BN_BIAS,\n",
        "                &MBConv6_7_DW_BN_MEAN,           \t&MBConv6_7_DW_BN_VARIANCE,\n",
        "                &MBConv6_7_DW_BN_WEIGHTS,        \t&MBConv6_7_DW_BN_BIAS,\n",
        "                &MBConv6_7_PRJ_BN_MEAN,           &MBConv6_7_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_7_PRJ_BN_WEIGHTS,        &MBConv6_7_PRJ_BN_BIAS);  \n",
        "          \n",
        "\n",
        "\n",
        "  // MBConv6_8 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut8;\n",
        "  MBConv_Layer(&ConvOut7, &ConvOut8,\n",
        "                &D_MBConv_6_8_EXPD_WEIGHTS,       &D_MBConv_6_8_DW_WEIGHTS,\n",
        "                &D_MBConv_6_8_SQZ_1_WEIGHTS,      &D_MBConv_6_8_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_8_PRJ_WEIGHTS,\n",
        "                MBCONV_6_8_EXPD_F_DENSITY,        MBCONV_6_8_DW_F_DENSITY, \n",
        "                MBCONV_6_8_SQZ_1_F_DENSITY,       MBCONV_6_8_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_8_PRJ_F_DENSITY,\n",
        "                ConvOut7.depth,                   MBCONV_6_8_PRJ_F_DENSITY, MBCONV_6_8_DW_F_HEIGHT,    \n",
        "                MBCONV_6_8_STRIDE,                MBCONV_6_8_PADDING, MBCONV_6_8_SKIP,\n",
        "                &MBConv6_8_SQZ_1_bias,  \t        &MBConv6_8_SQZ_2_bias,\n",
        "                &MBConv6_8_EXPD_BN_MEAN,          &MBConv6_8_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_8_EXPD_BN_WEIGHTS,       &MBConv6_8_EXPD_BN_BIAS,\n",
        "                &MBConv6_8_DW_BN_MEAN,           \t&MBConv6_8_DW_BN_VARIANCE,\n",
        "                &MBConv6_8_DW_BN_WEIGHTS,        \t&MBConv6_8_DW_BN_BIAS,\n",
        "                &MBConv6_8_PRJ_BN_MEAN,           &MBConv6_8_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_8_PRJ_BN_WEIGHTS,        &MBConv6_8_PRJ_BN_BIAS); \n",
        "        \n",
        "\n",
        "\n",
        "  // MBConv6_9 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut9;\n",
        "  MBConv_Layer(&ConvOut8, &ConvOut9,\n",
        "                &D_MBConv_6_9_EXPD_WEIGHTS,       &D_MBConv_6_9_DW_WEIGHTS,\n",
        "                &D_MBConv_6_9_SQZ_1_WEIGHTS,      &D_MBConv_6_9_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_9_PRJ_WEIGHTS,\n",
        "                MBCONV_6_9_EXPD_F_DENSITY,        MBCONV_6_9_DW_F_DENSITY, \n",
        "                MBCONV_6_9_SQZ_1_F_DENSITY,       MBCONV_6_9_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_9_PRJ_F_DENSITY,\n",
        "                ConvOut8.depth,                   MBCONV_6_9_PRJ_F_DENSITY, MBCONV_6_9_DW_F_HEIGHT,\n",
        "                MBCONV_6_9_STRIDE,                MBCONV_6_9_PADDING, MBCONV_6_9_SKIP,\n",
        "                &MBConv6_9_SQZ_1_bias,  \t        &MBConv6_9_SQZ_2_bias,\n",
        "                &MBConv6_9_EXPD_BN_MEAN,          &MBConv6_9_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_9_EXPD_BN_WEIGHTS,       &MBConv6_9_EXPD_BN_BIAS,\n",
        "                &MBConv6_9_DW_BN_MEAN,           \t&MBConv6_9_DW_BN_VARIANCE,\n",
        "                &MBConv6_9_DW_BN_WEIGHTS,        \t&MBConv6_9_DW_BN_BIAS,\n",
        "                &MBConv6_9_PRJ_BN_MEAN,           &MBConv6_9_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_9_PRJ_BN_WEIGHTS,        &MBConv6_9_PRJ_BN_BIAS);  \t\t\t\t  \n",
        "\n",
        "\n",
        "\n",
        "  // MBConv6_10 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut10;\n",
        "\tMBConv_Layer(&ConvOut9, &ConvOut10,\n",
        "                &D_MBConv_6_10_EXPD_WEIGHTS,      &D_MBConv_6_10_DW_WEIGHTS,\n",
        "                &D_MBConv_6_10_SQZ_1_WEIGHTS,     &D_MBConv_6_10_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_10_PRJ_WEIGHTS,\n",
        "                MBCONV_6_10_EXPD_F_DENSITY,       MBCONV_6_10_DW_F_DENSITY, \n",
        "                MBCONV_6_10_SQZ_1_F_DENSITY,      MBCONV_6_10_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_10_PRJ_F_DENSITY,\n",
        "                ConvOut9.depth,                   MBCONV_6_10_PRJ_F_DENSITY, MBCONV_6_10_DW_F_HEIGHT,\n",
        "                MBCONV_6_10_STRIDE,               MBCONV_6_10_PADDING, MBCONV_6_10_SKIP,\n",
        "                &MBConv6_10_SQZ_1_bias, \t        &MBConv6_10_SQZ_2_bias,\n",
        "                &MBConv6_10_EXPD_BN_MEAN,         &MBConv6_10_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_10_EXPD_BN_WEIGHTS,      &MBConv6_10_EXPD_BN_BIAS,\n",
        "                &MBConv6_10_DW_BN_MEAN,           &MBConv6_10_DW_BN_VARIANCE,\n",
        "                &MBConv6_10_DW_BN_WEIGHTS,        &MBConv6_10_DW_BN_BIAS,\n",
        "                &MBConv6_10_PRJ_BN_MEAN,          &MBConv6_10_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_10_PRJ_BN_WEIGHTS,       &MBConv6_10_PRJ_BN_BIAS);   \n",
        "  \n",
        "\n",
        "\n",
        "  // MBConv6_11 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut11;\n",
        "  MBConv_Layer(&ConvOut10, &ConvOut11,\n",
        "                &D_MBConv_6_11_EXPD_WEIGHTS,    &D_MBConv_6_11_DW_WEIGHTS,\n",
        "                &D_MBConv_6_11_SQZ_1_WEIGHTS,   &D_MBConv_6_11_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_11_PRJ_WEIGHTS,\n",
        "                MBCONV_6_11_EXPD_F_DENSITY,     MBCONV_6_11_DW_F_DENSITY, \n",
        "                MBCONV_6_11_SQZ_1_F_DENSITY,    MBCONV_6_11_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_11_PRJ_F_DENSITY,  \n",
        "                ConvOut10.depth,                MBCONV_6_11_PRJ_F_DENSITY, MBCONV_6_11_DW_F_HEIGHT,\n",
        "                MBCONV_6_11_STRIDE,             MBCONV_6_11_PADDING, MBCONV_6_11_SKIP,\n",
        "                &MBConv6_11_SQZ_1_bias,         &MBConv6_11_SQZ_2_bias,\n",
        "                &MBConv6_11_EXPD_BN_MEAN,       &MBConv6_11_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_11_EXPD_BN_WEIGHTS,    &MBConv6_11_EXPD_BN_BIAS,\n",
        "                &MBConv6_11_DW_BN_MEAN,         &MBConv6_11_DW_BN_VARIANCE,\n",
        "                &MBConv6_11_DW_BN_WEIGHTS,      &MBConv6_11_DW_BN_BIAS,\n",
        "                &MBConv6_11_PRJ_BN_MEAN,        &MBConv6_11_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_11_PRJ_BN_WEIGHTS,     &MBConv6_11_PRJ_BN_BIAS);  \n",
        "  \n",
        "\n",
        "\n",
        "  // MBConv6_12 layer implementation\n",
        "\n",
        "\n",
        "  Matrix ConvOut12;\n",
        "  MBConv_Layer(&ConvOut11, &ConvOut12,\n",
        "                &D_MBConv_6_12_EXPD_WEIGHTS,  &D_MBConv_6_12_DW_WEIGHTS,\n",
        "                &D_MBConv_6_12_SQZ_1_WEIGHTS, &D_MBConv_6_12_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_12_PRJ_WEIGHTS,\n",
        "                MBCONV_6_12_EXPD_F_DENSITY,   MBCONV_6_12_DW_F_DENSITY, \n",
        "                MBCONV_6_12_SQZ_1_F_DENSITY,  MBCONV_6_12_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_12_PRJ_F_DENSITY,\n",
        "                ConvOut11.depth,              MBCONV_6_12_PRJ_F_DENSITY, MBCONV_6_12_DW_F_HEIGHT,\n",
        "                MBCONV_6_12_STRIDE,           MBCONV_6_12_PADDING, MBCONV_6_12_SKIP,\n",
        "                &MBConv6_12_SQZ_1_bias,       &MBConv6_12_SQZ_2_bias,\n",
        "                &MBConv6_12_EXPD_BN_MEAN,     &MBConv6_12_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_12_EXPD_BN_WEIGHTS,  &MBConv6_12_EXPD_BN_BIAS,\n",
        "                &MBConv6_12_DW_BN_MEAN,       &MBConv6_12_DW_BN_VARIANCE,\n",
        "                &MBConv6_12_DW_BN_WEIGHTS,    &MBConv6_12_DW_BN_BIAS,\n",
        "                &MBConv6_12_PRJ_BN_MEAN,      &MBConv6_12_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_12_PRJ_BN_WEIGHTS,   &MBConv6_12_PRJ_BN_BIAS);   \n",
        "  \n",
        "\n",
        "\n",
        "  // MBConv6_13 layer implementation\n",
        "\n",
        "  Matrix ConvOut13;\n",
        "  MBConv_Layer(&ConvOut12, &ConvOut13,\n",
        "                &D_MBConv_6_13_EXPD_WEIGHTS,    &D_MBConv_6_13_DW_WEIGHTS,\n",
        "                &D_MBConv_6_13_SQZ_1_WEIGHTS,   &D_MBConv_6_13_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_13_PRJ_WEIGHTS,\n",
        "                MBCONV_6_13_EXPD_F_DENSITY,     MBCONV_6_13_DW_F_DENSITY, \n",
        "                MBCONV_6_13_SQZ_1_F_DENSITY,    MBCONV_6_13_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_13_PRJ_F_DENSITY,\n",
        "                ConvOut12.depth,                MBCONV_6_13_PRJ_F_DENSITY, MBCONV_6_13_DW_F_HEIGHT,\n",
        "                MBCONV_6_13_STRIDE,             MBCONV_6_13_PADDING, MBCONV_6_13_SKIP,\n",
        "                &MBConv6_13_SQZ_1_bias,         &MBConv6_13_SQZ_2_bias,\n",
        "                &MBConv6_13_EXPD_BN_MEAN,       &MBConv6_13_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_13_EXPD_BN_WEIGHTS,    &MBConv6_13_EXPD_BN_BIAS,\n",
        "                &MBConv6_13_DW_BN_MEAN,         &MBConv6_13_DW_BN_VARIANCE,\n",
        "                &MBConv6_13_DW_BN_WEIGHTS,      &MBConv6_13_DW_BN_BIAS,\n",
        "                &MBConv6_13_PRJ_BN_MEAN,        &MBConv6_13_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_13_PRJ_BN_WEIGHTS,     &MBConv6_13_PRJ_BN_BIAS);\n",
        "\n",
        "\n",
        "  Matrix ConvOut14;\n",
        "  MBConv_Layer(&ConvOut13, &ConvOut14,\n",
        "                &D_MBConv_6_14_EXPD_WEIGHTS,  &D_MBConv_6_14_DW_WEIGHTS,\n",
        "                &D_MBConv_6_14_SQZ_1_WEIGHTS, &D_MBConv_6_14_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_14_PRJ_WEIGHTS,\n",
        "                MBCONV_6_14_EXPD_F_DENSITY,   MBCONV_6_14_DW_F_DENSITY, \n",
        "                MBCONV_6_14_SQZ_1_F_DENSITY,  MBCONV_6_14_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_14_PRJ_F_DENSITY,\n",
        "                ConvOut13.depth,              MBCONV_6_14_PRJ_F_DENSITY, MBCONV_6_14_DW_F_HEIGHT,\n",
        "                MBCONV_6_14_STRIDE,           MBCONV_6_14_PADDING, MBCONV_6_14_SKIP,\n",
        "                &MBConv6_14_SQZ_1_bias, \t    &MBConv6_14_SQZ_2_bias,\n",
        "                &MBConv6_14_EXPD_BN_MEAN,     &MBConv6_14_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_14_EXPD_BN_WEIGHTS,  &MBConv6_14_EXPD_BN_BIAS,\n",
        "                &MBConv6_14_DW_BN_MEAN,       &MBConv6_14_DW_BN_VARIANCE,\n",
        "                &MBConv6_14_DW_BN_WEIGHTS,    &MBConv6_14_DW_BN_BIAS,\n",
        "                &MBConv6_14_PRJ_BN_MEAN,      &MBConv6_14_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_14_PRJ_BN_WEIGHTS,   &MBConv6_14_PRJ_BN_BIAS);  \n",
        "\n",
        "\n",
        "  Matrix ConvOut15;\n",
        "  MBConv_Layer(&ConvOut14, &ConvOut15,\n",
        "                &D_MBConv_6_15_EXPD_WEIGHTS,  &D_MBConv_6_15_DW_WEIGHTS,\n",
        "                &D_MBConv_6_15_SQZ_1_WEIGHTS, &D_MBConv_6_15_SQZ_2_WEIGHTS,\n",
        "                &D_MBConv_6_15_PRJ_WEIGHTS,\n",
        "                MBCONV_6_15_EXPD_F_DENSITY,   MBCONV_6_15_DW_F_DENSITY, \n",
        "                MBCONV_6_15_SQZ_1_F_DENSITY,  MBCONV_6_15_SQZ_2_F_DENSITY, \n",
        "                MBCONV_6_15_PRJ_F_DENSITY,\n",
        "                ConvOut14.depth,              MBCONV_6_15_PRJ_F_DENSITY, MBCONV_6_15_DW_F_HEIGHT,\n",
        "                MBCONV_6_15_STRIDE,           MBCONV_6_15_PADDING, MBCONV_6_15_SKIP,\n",
        "                &MBConv6_15_SQZ_1_bias,       &MBConv6_15_SQZ_2_bias,\n",
        "                &MBConv6_15_EXPD_BN_MEAN,     &MBConv6_15_EXPD_BN_VARIANCE,\n",
        "                &MBConv6_15_EXPD_BN_WEIGHTS,  &MBConv6_15_EXPD_BN_BIAS,\n",
        "                &MBConv6_15_DW_BN_MEAN,       &MBConv6_15_DW_BN_VARIANCE,\n",
        "                &MBConv6_15_DW_BN_WEIGHTS,    &MBConv6_15_DW_BN_BIAS,\n",
        "                &MBConv6_15_PRJ_BN_MEAN,      &MBConv6_15_PRJ_BN_VARIANCE,\n",
        "                &MBConv6_15_PRJ_BN_WEIGHTS,   &MBConv6_15_PRJ_BN_BIAS);   \n",
        "\n",
        "  // Head layer\n",
        "  Matrix HEAD_OUT;\n",
        "  HEAD_LAYER(&ConvOut15, &HEAD_CONV_WEIGHTS, &HEAD_FC_WEIGHTS,\n",
        "              HEAD_CONV_F_HEIGHT, HEAD_CONV_F_WIDTH, HEAD_CONV_F_DEPTH, HEAD_CONV_F_DENSITY,\n",
        "              0, 1,\n",
        "              &HEAD_OUT);\n",
        "\n",
        "  stop(\"Model: \", 0);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// The last layer in efficient net\n",
        "void HEAD_LAYER(Matrix *INPUT_MATRIX, Matrix *F_HEAD, Matrix *FC_WEIGHTS,\n",
        "                int filter_height, int filter_width, int filter_depth, int filter_density,\n",
        "                int padding, int stride,\n",
        "                Matrix *HEAD_OUT)\n",
        "{                \n",
        "  // Calculate output dimensions       \n",
        "  int out_height = (INPUT_MATRIX -> height + 2 * padding - filter_height) / stride + 1;\n",
        "  int out_width = (INPUT_MATRIX -> width + 2 * padding - filter_width) / stride + 1;\n",
        "  int out_depth = filter_density;\n",
        "\n",
        "  Set_DeviceMatrix(out_height, out_width, out_depth, HEAD_OUT,\n",
        "                   \"Output is allocated in device memory\"); \n",
        "\n",
        "  // 1st 3 layers: Conv2d 1x1: BN: Swish()\n",
        "  Conv2d_Layer(INPUT_MATRIX,  F_HEAD, HEAD_OUT,\n",
        "              stride, padding,\n",
        "              INPUT_MATRIX -> depth, out_depth, filter_density,\n",
        "              Conv2d_1_x_1, NO_ACTIVATION,\n",
        "              0, NULL);\n",
        " \n",
        "  BN_ALL_PRE_DEFINED(HEAD_OUT, SWISH_ACTIVATION, \n",
        "                      &D_HEAD_BN_MEAN,\t&D_HEAD_BN_VARIANCE ,\n",
        "                      &D_HEAD_BN_WEIGHTS, &D_HEAD_BN_BIAS);\n",
        "\n",
        "\n",
        "  // 4th layer: Average pooling layer which is just a reduction sum layer\n",
        "  // Get mean values for all channels; Dims(1 x 1 x InputDepth)\n",
        "  \n",
        "  Matrix MEAN, Result_Mean;\n",
        "\n",
        "  Set_DeviceMatrix(HEAD_OUT -> depth,\n",
        "                    (int)ceil((double)HEAD_OUT -> height * HEAD_OUT -> width / (2 * BLOCK_SIZE)),\n",
        "                    1, \n",
        "                    &Result_Mean, \n",
        "                    \"Reesult Mean matrix allocated in device memory\");\n",
        "\n",
        "  REDUCTION_SUM(HEAD_OUT, &MEAN, &Result_Mean);\n",
        "\n",
        "\n",
        "  // 5th layer: Fully connected layer::\n",
        "\n",
        "  // Set Output matrix details\n",
        "  Matrix Out1;\n",
        "  Set_DeviceMatrix(1, 1000, 1, &Out1, \"Setting Final Model Output matrix in device memory\");\n",
        "     \n",
        "  Conv_vidMultiplier(&Out1, FC_WEIGHTS, &Result_Mean,\n",
        "                      1, 1000, 1,\n",
        "                      Conv2d_1_x_1, 1,\n",
        "                      NO_ACTIVATION, \n",
        "                      0, NULL);\n",
        "  \n",
        "  Matrix tmp_out_host;\n",
        "  set_allocate_Host(&tmp_out_host, 1, 1000, 1);\n",
        "  just_copy_DTH(&tmp_out_host, &Out1, \"Copying to add bias\");\n",
        " \n",
        "  for (int i = 0; i < 1000; i++)\n",
        "  {\n",
        "    tmp_out_host.elements[i] += Head_linear_bias[i];\n",
        "  }\n",
        "/*\n",
        "  just_copy_HTD(&Out1, &tmp_out_host, \"Copying to add bias\");\n",
        "  show_me_enhanced_from_devince(&Out1, \"Model final output::\");*/\n",
        "}\n",
        "\n",
        "// The first layer in efficient net: \n",
        "// It reutnrs a pointer to matrix, its elements are allocated in device memory \n",
        "void STEM_LAYER(Matrix *DInput_Mat, Matrix *F_STEM,\n",
        "                  int image_height, int image_width, int image_depth,\n",
        "                  int filter_height, int filter_width, int filter_depth, int filter_density,\n",
        "                  int padding, int stride,\n",
        "                  Matrix *STEM_OUT)\n",
        "{\n",
        "\n",
        "  // Calculate output dimensions       \n",
        "  int out_height = (image_height + 2 * padding - filter_height) / stride + 1;\n",
        "  int out_width = (image_width + 2 * padding - filter_width) / stride + 1;\n",
        "  int out_depth = filter_density;\n",
        " \n",
        "\n",
        "  // Allow the output from this layer to go accross the next layer       \n",
        "  Set_DeviceMatrix(out_height, out_width, out_depth, STEM_OUT,\n",
        "                   \"Output is allocated in device memory\"); \n",
        " \n",
        "  Conv2d_Layer(DInput_Mat,  F_STEM, STEM_OUT,\n",
        "              stride, padding,\n",
        "              image_depth, out_depth, filter_density,\n",
        "              Regular_Conv, NO_ACTIVATION,\n",
        "              0, NULL);\n",
        " \n",
        "\n",
        "  BN_ALL_PRE_DEFINED(STEM_OUT, SWISH_ACTIVATION, \n",
        "                      &D_STEM_BN_MEAN, &D_STEM_BN_VARIANCE ,\n",
        "                      &D_STEM_BN_WEIGHTS, &D_STEM_BN_BIAS);  \n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/APP.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HPpV1Lk28NYo",
        "outputId": "ee65d742-1546-45b9-da45-4536a581f040"
      },
      "source": [
        "%%cuda --name FUNCTIONS.cu \n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <cusolverDn.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/functionsV2.h\"\n",
        "#include \"/content/drive/MyDrive/Colab_Notebooks/MBCONVS_float/KERNELSH.h\"\n",
        "\n",
        "static void HandleError( cudaError_t err,\n",
        "                         const char *file,\n",
        "                         int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))\n",
        "\n",
        "float time_defined = 0, tmp_time = 0, total_time_for_layer = 0;; \n",
        "cudaEvent_t start_timing, stop_timing;\n",
        "\n",
        "\n",
        "int show_out = 0;\n",
        "\n",
        "int total_constant_memory = 0;\n",
        "                \n",
        "// Device memory for filters\n",
        "void DEFINE_FILTERS_FOR_MBCONV(Matrix *D_f1, float *filter1, int h1, int w1, int dens1,\n",
        "                               Matrix *D_f2, float *filter2, int h2, int w2, int dens2,\n",
        "                               Matrix *D_f3, float *filter3, int h3, int w3, int dens3,\n",
        "                               Matrix *D_f4, float *filter4, int h4, int w4, int dens4,\n",
        "                               Matrix *D_f5, float *filter5, int h5, int w5, int dens5)\n",
        "{\n",
        "    // Note: No allocations are done, just pointers point to matrices pre-defined\n",
        "\n",
        "    // This condition is important as the float * is NULL\n",
        "    if (MBCONV1_0_flag == 1);\n",
        "    else\n",
        "      set_allocate_copy_array_Device(D_f1, filter1,\n",
        "                                    h1, w1, dens1,\n",
        "                                    \"1st filter allocated\");\n",
        " \n",
        "    set_allocate_copy_array_Device(D_f2, filter2,\n",
        "                                    h2, w2, dens2,\n",
        "                                    \"2nd filter allocated\");\n",
        " \n",
        "    set_allocate_copy_array_Device(D_f3, filter3,\n",
        "                                    h3, w3, dens3,\n",
        "                                    \"3rd filter allocated\");\n",
        "\n",
        "    set_allocate_copy_array_Device(D_f4, filter4,\n",
        "                                    h4, w4, dens4,\n",
        "                                    \"4th filter allocated\");\n",
        "\n",
        "    set_allocate_copy_array_Device(D_f5, filter5,\n",
        "                                    h5, w5, dens5,\n",
        "                                    \"5th filter allocated\");                                                         \n",
        "}\n",
        "\n",
        "// Free the device filters\n",
        "void FREE_FILTERS_FOR_MBCONV(Matrix *D_f1, Matrix *D_f2, \n",
        "                             Matrix *D_f3, Matrix *D_f4,\n",
        "                             Matrix *D_f5)\n",
        "{\n",
        "  cudaFree(D_f1 -> elements);\n",
        "  cudaFree(D_f2 -> elements);\n",
        "  cudaFree(D_f3 -> elements);\n",
        "  cudaFree(D_f4 -> elements);\n",
        "  cudaFree(D_f5 -> elements);\n",
        "}\n",
        "\n",
        "void REDUCTION_SUM(Matrix* Output_Modified, Matrix *sum, Matrix *DMean)\n",
        "{\n",
        "    /*\n",
        "      The mean will be a row vector of 1 x C;\n",
        "      where C is number of original matrix channels\n",
        "      All input matrices for this function are device matrices,\n",
        "      except for sum, it's just a transition that later can be removed \n",
        "    */\n",
        "\n",
        "    // Define number of blocks in different directions\n",
        "    int nbx = 0;\n",
        "    int nby = 0;\n",
        "    int nbz = 1;\n",
        "\n",
        "    size_t size;\n",
        "    cudaError err;\n",
        " \n",
        "    /*\n",
        "      Load input Matrix inot device t calculate mean for it\n",
        "      Unfortionately the code requires to copy the input matrix\n",
        "    */\n",
        " \n",
        "    Matrix DInputMat;\n",
        "    // Allocate and set its dimensions as needed from the algorithm\n",
        "    Set_DeviceMatrix(Output_Modified -> depth, Output_Modified -> height * Output_Modified -> width, 1,\n",
        "                     &DInputMat, \"Copyting Input of reduction mean function into Device memory\");\n",
        "\n",
        "    // Copy input from a device memory to device memory in order to process the elements\n",
        "    size = DInputMat.height * DInputMat.width * DInputMat.depth * sizeof(float);\n",
        "    err = cudaMemcpy(DInputMat.elements, Output_Modified -> elements, size, cudaMemcpyDeviceToDevice);\n",
        "    CheckCudaError(\"Copying mean matrix elements from \", err);\n",
        "\n",
        "    /* Starting reduction sum calculations */\n",
        "\n",
        "    // Note: All blocks are 1D threads. We use Block.x to reduce 1 channel elements'\n",
        "    // Diffferent block.y to address different number of channels\n",
        "    nbx = (int)ceil((double)DInputMat.width / (2 * BLOCK_SIZE));\n",
        "    nby = (int)ceil((double)DInputMat.height);\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    // For loop is held to maintain huge number of summations needed\n",
        "    for (int i = 0; DInputMat.width != 1; i++)\n",
        "    {\n",
        "        dim3 dim_Grid2(nbx, nby, nbz);\n",
        "        dim3 dim_Block2(BLOCK_SIZE, 1, 1);\n",
        "\n",
        "        // Make sure to synch between multiple runs\n",
        "       //cudaDeviceSynchronize();\n",
        "        \n",
        "        BN_Kernel_Mean_Reduction <<< dim_Grid2, dim_Block2 >>> (DInputMat.elements,\n",
        "                                                                DInputMat.height,\n",
        "                                                                DInputMat.width,\n",
        "                                                                DInputMat.depth,\n",
        "                                                                DMean -> elements,\n",
        "                                                                DMean -> width);\n",
        "\n",
        "        \n",
        "        // Save and copy mean values array into the filter array\n",
        "        size = DMean -> height * DMean -> width * DMean -> depth * sizeof(float);\n",
        "        err = cudaMemcpy(DInputMat.elements, DMean -> elements, size, cudaMemcpyDeviceToDevice);\n",
        "        CheckCudaError(\"Copying mean matrix elements from \", err);\n",
        "\n",
        "        // Modify filter width to fit into the new elements width\n",
        "        DInputMat.width = nbx;\n",
        "        DInputMat.height = nby;\n",
        "\n",
        "        // Recalculate number of blocks in x direction\n",
        "        nbx = (int)ceil((double)DInputMat.width / (2 * BLOCK_SIZE));\n",
        "        nby = (int)ceil((double)DInputMat.height);\n",
        "\n",
        "        if (nbx == 0) nbx = 1;\n",
        "        if (nby == 0) nby = 1;\n",
        "\n",
        "        // Set width of mean matrix to the new number of blocks\n",
        "        DMean -> width = nbx;\n",
        "        DMean -> height = nby;\n",
        "    }\n",
        "\n",
        "    \n",
        "    // Set mean matrix to 1 X C X 1 to ease further calculations\n",
        "    DMean -> height = 1; DMean -> width = Output_Modified -> depth; DMean -> depth = 1;\n",
        "\n",
        "    // Set the results back into the sum matrix to update the pointer\n",
        "    set_allocate_Host(sum, DMean -> height, DMean -> width, DMean -> depth);\n",
        "    \n",
        "    // Copy elements from device to host\n",
        "    just_copy_DTH(sum, DMean, \"Mean matrix copied back to host\");\n",
        "    \n",
        "    /* Mean calculation are done for all channels and the result is 1D row vector */\n",
        "\n",
        "    // Divide by number of pixels in 1 channel\n",
        "    int Divide_Mean_BY_ME = Output_Modified->height * Output_Modified->width;\n",
        "\n",
        "    // Divide all elements by Number of pixels\n",
        "    for (int i = 0; i < DMean -> width; i++)\n",
        "    {\n",
        "        sum -> elements[i] = sum -> elements[i] / Divide_Mean_BY_ME;\n",
        "    }\n",
        "\t\n",
        "    \n",
        "    just_copy_HTD(DMean, sum, \"Mean matrix copied back to Device\");\n",
        " \n",
        "   \n",
        "}\n",
        "\n",
        "\n",
        "/*  Squeeze_and_Excite(&tmp2, &SE_OUT, F3, F4,\n",
        "                      FD4, FD3, FD4, FD3);\n",
        "                      */\n",
        "// Note: input and output channels args represents the 2 Conv layers output channels respectively\n",
        "void Squeeze_and_Excite(Matrix* InputIMG, Matrix* Result,\n",
        "                        Matrix* Filter1, Matrix* Filter2,\n",
        "                        int FilterDensity2, int FilterDensity1,\n",
        "                        int input_channels, int output_channels,\n",
        "                        Matrix * First_bias, Matrix *Second_bias)\n",
        "{\n",
        "    /*\n",
        "       Steps in squeeze and excite layer:\n",
        "        1. Get mean value for a tensor\n",
        "        2. pass the mean to the covolution, swish, convolution, sigmoid\n",
        "        3. the result will be a 1 x 1 x C, multiply elementwise.\n",
        "          \"each element in a channel is multiplied by the result's corresponding channel element\"\n",
        "        \n",
        "        Filter Density means #filters used\n",
        " \n",
        "      Note: All input matrices are device allocated matrices\n",
        "    */\n",
        "\n",
        " \n",
        "    /*\n",
        "      Get mean values for all channels; Dims(1 x InputDepth x 1) \n",
        "      Note: Mean matrix is a host allocated memory in REDUCTION_SUM;\n",
        "            It's used to get the final summation from device and\n",
        "            then divide each element sequentially by total number \n",
        "            of elements. It's then later copied back to Result_Mean\n",
        "            Matrix which is a device matrix.\n",
        "            \"This can be later changed\"\n",
        "    */\n",
        " \n",
        "    Matrix MEAN, Result_Mean;\n",
        "\n",
        "    Set_DeviceMatrix(InputIMG -> depth,\n",
        "                      (int)ceil((double)InputIMG -> height * InputIMG -> width / (2 * BLOCK_SIZE)),\n",
        "                      1, \n",
        "                      &Result_Mean, \n",
        "                      \"Reesult Mean matrix allocated in device memory\");\n",
        "\n",
        "    REDUCTION_SUM(InputIMG, &MEAN, &Result_Mean);\n",
        " \n",
        "\n",
        "    // Tmp1 is used as a transition between 2 convolution layers; Dims(1 x 1 x FilterDensity3)\n",
        "    Matrix tmp1;\n",
        "    Set_DeviceMatrix(1, 1, FilterDensity1, &tmp1, \"Allocating tmp1 in device for transition\");\n",
        " \n",
        "    // tmp2 matrix is the result from sigmoid function: Dims(1 x 1 x FilterDensity4)\n",
        "    Matrix tmp2;\n",
        "    Set_DeviceMatrix( 1, 1, FilterDensity2, &tmp2, \"Allocating tmp2 in device for final output\");\n",
        " \n",
        "    // Sequence: Conv1x1, swish, Conv1x1, sigmoid \n",
        "    // Warning: Remember to pre-process Result_Mean matrix to match 1 x 1 x C as it's the input in this case to Conv2d\n",
        "    Set_HostMatrix(1, 1, InputIMG -> depth, &Result_Mean);\n",
        " \n",
        "    Conv2d_Layer(&Result_Mean, Filter1, &tmp1, 1, 0, input_channels, output_channels, FilterDensity1,\n",
        "                 Conv2d_1_x_1, SWISH_ACTIVATION,\n",
        "                 BIASED, First_bias);\n",
        "    \n",
        "    Conv2d_Layer(&tmp1, Filter2, &tmp2, 1, 0, output_channels, input_channels, FilterDensity2,\n",
        "                 Conv2d_1_x_1, SIGMOID_ACTIVATION,\n",
        "                 BIASED, Second_bias);\n",
        " \n",
        "\n",
        "    int nbx = (int)ceil((double)InputIMG -> width / Tile_GEMM);\n",
        "    int nby = (int)ceil((double)InputIMG -> height / Tile_GEMM);\n",
        "    int nbz = InputIMG -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    // This is the only kernel that runs 3d Grid; \n",
        "    // Each block in z dimension controls 1 channel  \n",
        "    dim3 dim_Grid2(nbx, nby, nbz);\n",
        "    dim3 dim_Block2(Tile_GEMM, Tile_GEMM, 1);\n",
        "\n",
        "    // C then D, the final multiplication is in C matrix\n",
        "    //cudaDeviceSynchronize();\n",
        " \n",
        "    ConvChannelElementWiseMultiplication <<< dim_Grid2, dim_Block2 >>> (InputIMG -> elements,\n",
        "                                                                        InputIMG -> height,\n",
        "                                                                        InputIMG -> width,\n",
        "                                                                        InputIMG -> depth,\n",
        "                                                                        tmp2.elements);\n",
        " \n",
        " \n",
        "    //cudaDeviceSynchronize();  \n",
        "\n",
        "   \n",
        "    cudaFree(tmp1.elements);\n",
        "    cudaFree(tmp2.elements);\n",
        "}\n",
        "\n",
        "// Warning: Fuction Input matrices are allocated in device memory directly\n",
        "// InputIMG, FilterK and ConvOut are device memory allocations\n",
        "void Conv2d_Layer(Matrix* InputIMG, Matrix* FilterK, Matrix* ConvOut,\n",
        "                  int stride, int padding,\n",
        "                  int InputChannels, int OutputChannels, int FilterDensity,\n",
        "                  int Conv_Type, int activation_type,\n",
        "                  int BIASED_CHOISE, Matrix *biasMat)\n",
        "{\n",
        "    //printf(\"The start of Conv2d layer\\n\\n\");\n",
        "    \n",
        "    int OutputHeight = 0, OutputWidth = 0, OutputDepth = 0;\n",
        "\n",
        "    // 1x1 Conv2d is a special case of Convolution\n",
        "    if (Conv_Type == Conv2d_1_x_1)\n",
        "    {\n",
        "        // Conv2d 1x1 has stride = 1, no padding and K = 1\n",
        "\n",
        "        /*\n",
        "          Input Dimensions is the same as Output dimensions\n",
        "          Only Depth of the output channels differ from input\n",
        "        */\n",
        "        OutputHeight = InputIMG -> height; OutputWidth = InputIMG -> width; OutputDepth = FilterDensity;\n",
        "\n",
        "        /*\n",
        "          Note: Set_HostMatrix function just changes the dimensions\n",
        "                so it's okey to use on a device memory\n",
        "        */\n",
        "     \n",
        "        // Modify Filter Matrix to have dimensions ((K^2 * M) x C x 1); K = 1\n",
        "        Set_HostMatrix(1 * 1 * FilterDensity, InputIMG -> depth, 1, FilterK);\n",
        "\n",
        "        // Modify Input matrix to have dimensions (C x (H * W) x 1)\n",
        "        Set_HostMatrix(InputIMG -> depth, InputIMG -> height * InputIMG -> width, 1, InputIMG);\n",
        "\n",
        "        // Modify Output Matrix preprocessing to have dimesions ((K^2 * M) x (H * W) x 1); K = 1\n",
        "        Set_HostMatrix(1 * 1 * FilterDensity, OutputWidth * OutputHeight, 1, ConvOut);\n",
        "\n",
        "        Conv_vidMultiplier(ConvOut, InputIMG, FilterK,\n",
        "                            OutputHeight, OutputWidth, OutputDepth,\n",
        "                            Conv2d_1_x_1, 1,\n",
        "                            activation_type, \n",
        "                            BIASED_CHOISE, biasMat);\n",
        "    }\n",
        "    else if (Conv_Type == DWConv_k_x_k)\n",
        "    {\n",
        "        // Ptr is used to alternate between input image and padding if needed\n",
        "        Matrix* ptr = InputIMG;\n",
        "\n",
        "        // DWConv2d has stride = s, padding = p and kernel = k\n",
        "        OutputHeight = ConvOut -> height; OutputWidth = ConvOut -> width; OutputDepth = ConvOut -> depth;\n",
        "\n",
        "        Matrix padded_matr;\n",
        "        if (padding != 0)\n",
        "        {\n",
        "            Padding_Zeros_Function(InputIMG, padding, &padded_matr);\n",
        "            ptr = &padded_matr;\n",
        "        }\n",
        "       \n",
        "        Conv_vidMultiplier(ConvOut, ptr, FilterK,\n",
        "                            OutputHeight, OutputWidth, OutputDepth,\n",
        "                            DWConv_k_x_k, stride,\n",
        "                            activation_type, \n",
        "                            BIASED_CHOISE, biasMat);\n",
        "\n",
        "        // Padded matrix is no longer needed as Convout has the final result\n",
        "    }\n",
        "    // Any other kernel size goes here\n",
        "    else\n",
        "    {        \n",
        "        // Regular convolution: Filter and input unrolling\n",
        "        Matrix* ptr = InputIMG;\n",
        "        OutputHeight = (ptr -> height + 2 * padding - FilterK -> height) / stride + 1;\n",
        "        OutputWidth = (ptr -> width + 2 * padding - FilterK -> width) / stride + 1;\n",
        "        OutputDepth = FilterDensity;\n",
        "\n",
        "        Matrix padded_matr;\n",
        "        if (padding != 0)\n",
        "        {\n",
        "            Padding_Zeros_Function(InputIMG, padding, &padded_matr);\n",
        "            ptr = &padded_matr;          \n",
        "        }\n",
        "\n",
        "        // 1st phase: Filter unrolling\n",
        "\n",
        "        // Unrolled filter has dimesnios (M x (C * k * k) x 1)\n",
        "        Set_HostMatrix(FilterDensity, FilterK -> depth / FilterDensity * FilterK -> height * FilterK -> width,\n",
        "                      1, FilterK);\n",
        "\n",
        "        // 2nd phase: Input unrolling\n",
        "\n",
        "        // The unrolled Input matrix has dimensions((C * k * k) x (H_out * W_out) x 1)\n",
        "        Matrix INPUT_MODIFIED;\n",
        "        \n",
        "        Set_DeviceMatrix(ptr -> depth * 3 * 3,\n",
        "                        OutputHeight * OutputWidth, 1,\n",
        "                        &INPUT_MODIFIED, \n",
        "                        \"Input unrolled Matrix allocated in device memory\");\n",
        "\n",
        "        Input_Unroll_gpu(stride, ptr, &INPUT_MODIFIED, OutputHeight, OutputWidth, 3);\n",
        "\n",
        "        // Convolution output has dimensions of (M x (H_out * W_out) x 1)\n",
        "        Set_HostMatrix(FilterDensity, OutputWidth * OutputHeight, 1, ConvOut);\n",
        "\n",
        "          \n",
        "        // Perform Multiplication and re-edit the dimensions of output\n",
        "        Conv_vidMultiplier(ConvOut, &INPUT_MODIFIED, FilterK,\n",
        "                            OutputHeight, OutputWidth, OutputDepth,\n",
        "                            Regular_Conv, stride,\n",
        "                            activation_type,\n",
        "                            BIASED_CHOISE, biasMat);\n",
        "\n",
        "    }\n",
        " }\n",
        "\n",
        "// 5 Filters needed to run the 4 layers sequentially\n",
        "void MBConv_Layer(Matrix* Input, Matrix* MBConvOut,\n",
        "    Matrix* F1, Matrix* F2, Matrix* F3, Matrix* F4, Matrix* F5,\n",
        "    int FD1, int FD2, int FD3, int FD4, int FD5,\n",
        "    int input_channels, int output_channels, int FilterSizeDW,\n",
        "    int Stride, int padding, int skip,\n",
        "    Matrix *bias1, Matrix *bias2,\n",
        "    Matrix *MBConv_expansion_conv_BN_mean,     Matrix *MBConv_expansion_conv_BN_variance,\n",
        "    Matrix *MBConv_expansion_conv_BN_weights,  Matrix *MBConv_expansion_conv_BN_bias,\n",
        "    Matrix *MBConv_depthwise_conv_BN_mean,     Matrix *MBConv_depthwise_conv_BN_variance,\n",
        "    Matrix *MBConv_depthwise_conv_BN_weights,  Matrix *MBConv_depthwise_conv_BN_bias,\n",
        "    Matrix *MBConv_project_conv_BN_mean,       Matrix *MBConv_project_conv_BN_variance,\n",
        "    Matrix *MBConv_project_conv_BN_weights,    Matrix *MBConv_project_conv_BN_bias)\n",
        "{\n",
        "    /*\n",
        "      Note: MBConv1_0 doesn't have the expansion conv function;\n",
        "            The input matrices to this function are device matrices;\n",
        "            including all the filters, you don't need to allocate or\n",
        "            copy any thing; just pass to the functions\n",
        "    */\n",
        "\n",
        "    /*\n",
        "      ptr_mat is the pointer that gets past expansion conv;\n",
        "      Meaning: in case of MBconv1_0 the pointer is same as input matrix;\n",
        "                in case of any other MBConv6_! it's the output of Conv2d \n",
        "                and BN with swish\n",
        "    */\n",
        "    \n",
        "    Matrix H_OUT;\n",
        "    Matrix tmp1; Matrix *ptr_mat; \n",
        " \n",
        "    if (MBCONV1_0_flag == 1)\n",
        "      ptr_mat = Input;\n",
        "    else\n",
        "    {     \n",
        "      Set_DeviceMatrix(Input -> height, Input -> width , FD1, \n",
        "                       &tmp1,\n",
        "                       \"Output_1 is allocated in device memory\"); \n",
        "               \n",
        "      // 1st layer: 1x1 Conv2d, stride = 1, padding = 0, K = 1\n",
        "      Conv2d_Layer(Input, F1, &tmp1, 1, 0,\n",
        "                   input_channels, FD1, FD1,\n",
        "                   Conv2d_1_x_1,\n",
        "                   NO_ACTIVATION, 0, NULL);\n",
        "  \n",
        "      BN_ALL_PRE_DEFINED(&tmp1, SWISH_ACTIVATION, \n",
        "                          MBConv_expansion_conv_BN_mean,    MBConv_expansion_conv_BN_variance,\n",
        "                          MBConv_expansion_conv_BN_weights, MBConv_expansion_conv_BN_bias);\n",
        "      ptr_mat = &tmp1;\n",
        "    }\n",
        "\n",
        "   // 2nd Layer: KxK DWconv, stride = s, padding = p, K = k\n",
        "\n",
        "    // Height and width changes, Only depth remains still\n",
        "    int OutputHeight = (ptr_mat -> height + 2 * padding - FilterSizeDW)/Stride + 1;\n",
        "    int OutputWidth = (ptr_mat -> width + 2 * padding - FilterSizeDW)/Stride + 1;\n",
        "    int OutputDepth = ptr_mat -> depth;\n",
        " \n",
        "    // Set and allocate tmp2 matrix; it's a transistion between expansion and squeeze\n",
        "    Matrix tmp2;\n",
        "    Set_DeviceMatrix(OutputHeight, OutputWidth, OutputDepth, &tmp2,\n",
        "                    \"Output_2 is allocated in device memory\");    \n",
        "\n",
        "    Conv2d_Layer(ptr_mat, F2, &tmp2,\n",
        "                 Stride, padding, FD1, FD2, FD2, DWConv_k_x_k,\n",
        "                 NO_ACTIVATION, 0, NULL);\n",
        "  \n",
        "\n",
        "    BN_ALL_PRE_DEFINED(&tmp2, SWISH_ACTIVATION, \n",
        "                       MBConv_depthwise_conv_BN_mean,     MBConv_depthwise_conv_BN_variance,\n",
        "                       MBConv_depthwise_conv_BN_weights,  MBConv_depthwise_conv_BN_bias);\n",
        "  \n",
        "    // 3rd Layer: squeeze and excitation\n",
        "\n",
        "    /*\n",
        "      Squeeze excite layer doesn't change the final output dimensions;\n",
        "      SE_OUT can be removed; Do so later\n",
        "    */\n",
        " \n",
        "    Matrix *SE_OUT;\n",
        "    Squeeze_and_Excite(&tmp2, SE_OUT, F3, F4,\n",
        "                        FD4, FD3, FD4, FD3,\n",
        "                        bias1, bias2);\n",
        "\n",
        "    // 4th Layer: 1x1 Conv2d\n",
        "    // MBConv output pointer is set and finally updated after this layer execution\n",
        "    Set_DeviceMatrix(tmp2.height, tmp2.width, FD5, MBConvOut,\n",
        "                     \"Matrix final output is allocated in device memory\");\n",
        " \n",
        "\n",
        "    // 1x1 Conv2d layer\n",
        "    Conv2d_Layer(&tmp2, F5, MBConvOut, 1, 0, FD4, FD5, FD5, Conv2d_1_x_1,\n",
        "                 NO_ACTIVATION, 0, NULL);\n",
        "\n",
        "\n",
        "    // BatchNorm layer\n",
        "    BN_ALL_PRE_DEFINED(MBConvOut, NO_ACTIVATION, \n",
        "                       MBConv_project_conv_BN_mean,     MBConv_project_conv_BN_variance,\n",
        "                       MBConv_project_conv_BN_weights,  MBConv_project_conv_BN_bias);\n",
        "\n",
        " \n",
        "    // Skip identity layer\n",
        "    if(skip)\n",
        "    {\n",
        "      MBConv_SKIP_IDENTITY(MBConvOut, Input);\n",
        "    }\n",
        "\n",
        "      \n",
        "/*    if (MBCONV1_0_flag == 0) \n",
        "      cudaFree(tmp1.elements);\n",
        "    */\n",
        "    /*\n",
        "    free(tmp2.elements);\n",
        "    free(SE_OUT.elements);\n",
        "\n",
        "    reset_time();\n",
        "    */\n",
        " \n",
        "    /*\n",
        "      Always remember to free the input pointer as\n",
        "      it's a device memory from the previous function\n",
        "    */\n",
        "    //cudaFree(Input -> elements);\n",
        "}\n",
        "\n",
        "\n",
        "void MBConv_SKIP_IDENTITY(Matrix *parent, Matrix *child)\n",
        "{\n",
        "    //printf(\"The start of Skip connection\\n\\n\");\n",
        "    \n",
        "    int nbx = (int)ceil((double)parent -> width / Tile_GEMM);\n",
        "    int nby = (int)ceil((double)parent -> height / Tile_GEMM);\n",
        "    int nbz = parent -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    // This is the only kernel that runs 3d Grid; \n",
        "    // Each block in z dimension controls 1 channel  \n",
        "    dim3 dim_Grid2(nbx, nby, nbz);\n",
        "    dim3 dim_Block2(Tile_GEMM, Tile_GEMM, 1);\n",
        "    \n",
        "    Identity_Skip <<<dim_Grid2, dim_Block2 >>> (parent -> elements,\n",
        "                                                  parent -> height,\n",
        "                                                  parent -> width,\n",
        "                                                  parent -> depth, \n",
        "                                                  child -> elements);\n",
        "}\n",
        "\n",
        "void BN_ALL_PRE_DEFINED(Matrix* D_input, int activate, Matrix *mean, Matrix *variance, Matrix *weights, Matrix *bias)\n",
        "{\n",
        "    /* The ptr matrix is a device matrix */\n",
        " \n",
        "    //printf(\"The start of BatchNorm layer\\n\\n\");\n",
        "    \n",
        "    /*\n",
        "      All weights, bias, running mean and running variance\n",
        "      are pre-defined. Just call the function and use the\n",
        "      matrices.\n",
        "      \n",
        "      All bias, weights, mean and bariance matrices are 1x1xC\n",
        "\n",
        "      Output Matrix is modified by the equation\n",
        "      (y = ((x - Mean) / (sqrt(variance) + epsilon)) * weights + bais)\n",
        "    */\n",
        "\n",
        "    int nbx = (int)ceil((double)D_input -> width / Tile_GEMM);\n",
        "    int nby = (int)ceil((double)D_input -> height / Tile_GEMM);\n",
        "    int nbz = D_input -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    // This is the only kernel that runs 3d Grid; \n",
        "    // Each block in z dimension controls 1 channel  \n",
        "    dim3 dim_Grid3(nbx, nby, nbz);\n",
        "    dim3 dim_Block3(Tile_GEMM, Tile_GEMM, 1);\n",
        "\n",
        "    BN_Kernel_Final_Layer <<< dim_Grid3, dim_Block3 >>> (D_input -> elements,\n",
        "                                                         D_input -> height,\n",
        "                                                         D_input -> width,\n",
        "                                                         D_input -> depth,\n",
        "                                                         mean -> elements, variance -> elements,\n",
        "                                                         weights -> elements, bias -> elements,\n",
        "                                                         activate);\n",
        "}\n",
        "\n",
        "void Padding_Zeros_Function(Matrix* Original_Matrix_Before, int padding_Value, Matrix* padded_Matrix)\n",
        "{\n",
        "    /* \n",
        "      Note: Matrix coming is a device elemente matrix;\n",
        "            Original Matrix is a Device input that needs padding\n",
        "            padded_Matrix is the return of this function;\n",
        "\n",
        "      Warning: Padded_Matrix has a different size than the Original \n",
        "                non padded matrix and it's not allocated in device yet.\n",
        "                The allocateion is done inside this function.\n",
        "    */    \n",
        "\n",
        "    Set_DeviceMatrix(Original_Matrix_Before->height + 2 * padding_Value,\n",
        "                      Original_Matrix_Before->width + 2 * padding_Value,\n",
        "                      Original_Matrix_Before->depth,\n",
        "                      padded_Matrix,\n",
        "                      \"Padded Matrix is allocated in device memory.\");\n",
        "\n",
        "    // 1st: Set padded Matrix with all zeros\n",
        "    cudaMemset(padded_Matrix -> elements,\n",
        "               0, padded_Matrix->height * padded_Matrix->width * padded_Matrix->depth * sizeof(float)); \n",
        "\n",
        "    int nbx = (int)ceil((double)padded_Matrix -> width / Tile_GEMM);\n",
        "    int nby = (int)ceil((double)padded_Matrix -> height / Tile_GEMM);\n",
        "    int nbz = padded_Matrix -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "\n",
        "    if (nby == 0) nby = 1;\n",
        "\n",
        "    dim3 dim_Grid2(nbx, nby, nbz);\n",
        "    dim3 dim_Block2(Tile_GEMM, Tile_GEMM, 1);\n",
        "\n",
        "    // Pass to the copying strided kernel to complete the padding process\n",
        " \n",
        "    Complete_Padding_Process <<< dim_Grid2, dim_Block2 >>> (padded_Matrix -> elements,\n",
        "                                                            padded_Matrix -> height,\n",
        "                                                            padded_Matrix -> width,\n",
        "                                                            padded_Matrix -> depth,\n",
        "                                                            Original_Matrix_Before -> elements,\n",
        "                                                            Original_Matrix_Before -> height,\n",
        "                                                            Original_Matrix_Before -> width,\n",
        "                                                            Original_Matrix_Before -> depth,\n",
        "                                                            padding_Value);\n",
        "}\n",
        "\n",
        "\n",
        "// Call this function directly for 1x1 conv2d. Don't call for DWConv\n",
        "void Conv_vidMultiplier(Matrix* out_11, Matrix* D_2, Matrix* D_1,\n",
        "                        int ReconstructOutHieght, int ReconstructOutWidth, int ReconstructOutDepth,\n",
        "                        int ConvType, int stride_DW, int activation_type, int BIASED_CHOISE, Matrix *biasMat)\n",
        "{\n",
        "    /* Note: Out_11, XXX_Trans and Host_Conv_Filter are device matrices */\n",
        " \n",
        "    // The multiplication kernel is used for the 1x1 Conv2d and kxk Conv2d\n",
        "    if (ConvType == Conv2d_1_x_1 || ConvType == Regular_Conv)\n",
        "    {    \n",
        "        // Get number of blocks\n",
        "        int nbx = (int)ceil((double)out_11 -> width / (THREAD_GRANULARITY_BLOCKS * Tile_GEMM));\n",
        "        int nby = (int)ceil((double)out_11 -> height / Tile_GEMM);\n",
        "        int num_block_for_phases = (int)ceil((double)D_1 -> width / Tile_GEMM);\n",
        "\n",
        "        // Check for zero blocks to make sure code runs correctly\n",
        "        if (nbx == 0) nbx = 1;\n",
        "        if (nby == 0) nby = 1;\n",
        "\n",
        "        dim3 dim_Grid2(nbx, nby, 1);\n",
        "        dim3 dim_Block2(Tile_GEMM, Tile_GEMM, 1);\n",
        "     \n",
        "        if (BIASED_CHOISE == BIASED)\n",
        "        {\n",
        "          Set_HostMatrix(out_11 -> height, 1, 1, biasMat);\n",
        "\n",
        "          // Call shared memory tiled Multiplication  algorithm\n",
        "\n",
        "          MatrixMulKernel <<< dim_Grid2, dim_Block2 >>> (D_1 -> elements, D_1 -> height, D_1 -> width, D_1 -> depth,\n",
        "                                                         D_2 -> elements, D_2 -> height, D_2 -> width, D_2 -> depth,\n",
        "                                                         out_11 -> elements, out_11 -> height, out_11 -> width, out_11 -> depth,\n",
        "                                                         num_block_for_phases, activation_type,\n",
        "                                                         BIASED_CHOISE, biasMat -> elements);         \n",
        "        }\n",
        "        else\n",
        "        {\n",
        "            \n",
        "\n",
        "          MatrixMulKernel <<< dim_Grid2, dim_Block2 >>> (D_1 -> elements, D_1 -> height, D_1 -> width, D_1 -> depth,\n",
        "                                                         D_2 -> elements, D_2 -> height, D_2 -> width, D_2 -> depth,\n",
        "                                                         out_11 -> elements, out_11 -> height, out_11 -> width, out_11 -> depth,\n",
        "                                                         num_block_for_phases, activation_type,\n",
        "                                                         BIASED_CHOISE, NULL);        \n",
        "        }    \n",
        "    }\n",
        "\n",
        "    // This case is for DWConv2d\n",
        "    else\n",
        "    {\n",
        "        int nbx = (int)ceil((double)out_11 -> width / TileDW);\n",
        "        int nby = (int)ceil((double)out_11 -> height / TileDW);\n",
        "        int nbz = out_11 -> depth;\n",
        "     \n",
        "        if (nbx == 0) nbx = 1;\n",
        "        if (nby == 0) nby = 1;\n",
        "\n",
        "        // This is the only kernel that runs 3d Grid; \n",
        "        // Each block in z dimension controls 1 channel  \n",
        "        dim3 dim_Grid2(nbx, nby, nbz);\n",
        "        dim3 dim_Block2(TileDW, TileDW, 1);\n",
        "\n",
        "\n",
        "        DWConv2d_kernel << < dim_Grid2, dim_Block2 >> > (D_2 -> elements, D_2 -> height, D_2 -> width, D_2 -> depth,\n",
        "                                                         D_1 -> elements, D_1 -> height, D_1 -> width, D_1 -> depth,\n",
        "                                                         out_11 -> elements, out_11 -> height, out_11 -> width, out_11 -> depth,\n",
        "                                                         stride_DW);\n",
        "    }\n",
        " \n",
        "    // Reset the output dimensions to continue in the network\n",
        "    Set_HostMatrix(ReconstructOutHieght, ReconstructOutWidth, ReconstructOutDepth, out_11);\n",
        "}\n",
        "\n",
        "void Input_Unroll_gpu(int st_stride, Matrix* Device_Input, Matrix* Device_Unrolled, int O_H, int O_W, int Filter_Size)\n",
        "{   \n",
        "    /* Note: All the function input matrices are device matrices.\n",
        "            Device_Input matrix is already allocated and ready.\n",
        "            Device_Unrolled matrix is already allocated and ready. \n",
        "    */\n",
        "    \n",
        "    int nbx = (int)ceil((double)O_W / TileDW);\n",
        "    int nby = (int)ceil((double)O_H / TileDW);\n",
        "    int nbz = Device_Input -> depth;\n",
        "\n",
        "    if (nbx == 0) nbx = 1;\n",
        "\n",
        "    if (nby == 0) nby = 1;\n",
        " \n",
        "    dim3 dim_Grid2(nbx, nby, nbz);\n",
        "    dim3 dim_Block2(TileDW, TileDW, 1);\n",
        "\n",
        "    // You need to use cudaDeviceSynchronize if the kernel isn't working\n",
        "\n",
        "    INPUT_UNROLLING <<< dim_Grid2, dim_Block2 >>> (st_stride, Filter_Size,\n",
        "                                                   \n",
        "                                                   Device_Input -> elements,\n",
        "                                                   Device_Input -> height,\n",
        "                                                   Device_Input -> width,\n",
        "                                                   Device_Input -> depth,\n",
        "\n",
        "                                                   Device_Unrolled -> elements,\n",
        "                                                   Device_Unrolled -> height,\n",
        "                                                   Device_Unrolled -> width,\n",
        "                                                   Device_Unrolled -> depth,\n",
        "\n",
        "                                                   O_H, O_W);\n",
        "\n",
        "    \n",
        "    //cudaDeviceSynchronize(); \n",
        "\n",
        "    cudaError err = cudaGetLastError();\n",
        "\n",
        "    if ( err != cudaSuccess )\n",
        "    {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "      exit(-1);\n",
        "    } \n",
        "}\n",
        "\n",
        "void DEFINE_FILTERS_FOR_MBCONV_BN(  Matrix *EXP_MEAN, \t\t  float *filter1, int size_1,\n",
        "                                    Matrix *EXP_VARIANCE, \tfloat *filter2, int size_2,\n",
        "                                    Matrix *EXP_WEIGHTS, \t  float *filter3, int size_3,\n",
        "                                    Matrix *EXP_BIAS, \t\t  float *filter4, int size_4,\n",
        "                                  \n",
        "                                    Matrix *DW_MEAN, \t\t    float *filter5, int size_5,\n",
        "                                    Matrix *DW_VARIANCE, \t  float *filter6, int size_6,\n",
        "                                    Matrix *DW_WEIGHTS, \t\tfloat *filter7, int size_7,\n",
        "                                    Matrix *DW_BIAS, \t\t    float *filter8, int size_8,\n",
        "                                    \n",
        "                                    Matrix *PRJ_MEAN, \t\t  float *filter9,  int size_9,\n",
        "                                    Matrix *PRJ_VARIANCE, \tfloat *filter10, int size_10,\n",
        "                                    Matrix *PRJ_WEIGHTS, \t  float *filter11, int size_11,\n",
        "                                    Matrix *PRJ_BIAS, \t\t  float *filter12, int size_12)\n",
        "{\n",
        "  if (MBCONV1_0_flag);\n",
        "  else\n",
        "  {\n",
        "    set_allocate_copy_array_Device(EXP_MEAN, filter1,\n",
        "                      size_1, 1, 1,\n",
        "                      \"expand mean\"); \n",
        "    set_allocate_copy_array_Device(EXP_VARIANCE, filter2,\n",
        "                      size_2, 1, 1,\n",
        "                      \"expand variance\"); \n",
        "    set_allocate_copy_array_Device(EXP_WEIGHTS, filter3,\n",
        "                      size_3, 1, 1,\n",
        "                      \"expand weights\"); \n",
        "    set_allocate_copy_array_Device(EXP_BIAS, filter4,\n",
        "                      size_4, 1, 1,\n",
        "                      \"expand bias\");\n",
        "  } \n",
        "\t\t\t\t\t\t\t\t\t  \n",
        "\tset_allocate_copy_array_Device(DW_MEAN, filter5,\n",
        "\t\t\t\t\t\t\t\t\t  size_5, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW mean\"); \n",
        "\tset_allocate_copy_array_Device(DW_VARIANCE, filter6,\n",
        "\t\t\t\t\t\t\t\t\t  size_6, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW variance\"); \n",
        "\tset_allocate_copy_array_Device(DW_WEIGHTS, filter7,\n",
        "\t\t\t\t\t\t\t\t\t  size_7, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW weights\"); \n",
        "\tset_allocate_copy_array_Device(DW_BIAS, filter8,\n",
        "\t\t\t\t\t\t\t\t\t  size_8, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"expand bias\"); \n",
        "\n",
        "\tset_allocate_copy_array_Device(PRJ_MEAN, filter9,\n",
        "\t\t\t\t\t\t\t\t\t  size_9, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW mean\"); \n",
        "\tset_allocate_copy_array_Device(PRJ_VARIANCE, filter10,\n",
        "\t\t\t\t\t\t\t\t\t  size_10, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW variance\"); \n",
        "\tset_allocate_copy_array_Device(PRJ_WEIGHTS, filter11,\n",
        "\t\t\t\t\t\t\t\t\t  size_11, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"DW weights\"); \n",
        "\tset_allocate_copy_array_Device(PRJ_BIAS, filter12,\n",
        "\t\t\t\t\t\t\t\t\t  size_12, 1, 1,\n",
        "\t\t\t\t\t\t\t\t\t  \"expand bias\"); \n",
        "}\n",
        "\n",
        "// 3 Sequential Operations: Same as \"set_allocate_copy_Matrix_Device\",\n",
        "// However, it uses a pointer to float as a parent.\n",
        "void set_allocate_copy_array_Device(Matrix *child, float *parent,\n",
        "\t\t\t\t\t\t\t\t\tint height, int width, int depth,\n",
        "\t\t\t\t\t\t\t\t\tchar *notification)\n",
        "{\n",
        "\tSet_DeviceMatrix(height, width, depth, child, notification);\n",
        "\n",
        "\tsize_t size = height * width * depth * sizeof(float);\n",
        " \n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent, size,\n",
        "\t\t\t\t\t\t\t\tcudaMemcpyHostToDevice);\n",
        "  \n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "// 3 Sequential Operations: Set dimensions, allocate device memory and copy.\n",
        "void set_allocate_copy_Matrix_Device(Matrix *child, Matrix *parent, char *notification)\n",
        "{\n",
        "\tSet_DeviceMatrix(parent -> height, parent -> width, parent -> depth,\n",
        "\t\t\t\t\t          child, notification);\n",
        "\n",
        "\tsize_t size = parent -> height * parent -> width * parent -> depth * sizeof(float);\n",
        "\t\n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent -> elements,\n",
        "\t\t\t\t\t\t\t\t              size, cudaMemcpyHostToDevice);\n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "void set_allocate_copy_Matrix_Device_specific(Matrix *child, Matrix *parent, char *notification, int height, int width, int depth)\n",
        "{\n",
        "\tSet_DeviceMatrix(height, width, depth, child, notification);\n",
        "\n",
        "\tsize_t size = child -> height * child -> width * child -> depth * sizeof(float);\n",
        "\t\n",
        "\n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent -> elements,\n",
        "\t\t\t\t\t\t\t\t            size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  \n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "void just_copy_HTD(Matrix *child, Matrix *parent, char *notification)\n",
        "{\n",
        "    // Read C from device memory\n",
        "  size_t size = parent -> width * parent -> height * parent -> depth * sizeof(float);\n",
        "    \n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent -> elements, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  \n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "void just_copy_DTH(Matrix *child, Matrix *parent, char *notification)\n",
        "{\n",
        "  // Read C from device memory\n",
        "  size_t size = parent -> width * parent -> height * parent -> depth * sizeof(float);\n",
        "  \n",
        "\n",
        "\tcudaError err = cudaMemcpy(child -> elements, parent -> elements, size, cudaMemcpyDeviceToHost);\n",
        "  \n",
        "\tCheckCudaError(notification, err);\n",
        "}\n",
        "\n",
        "void set_allocate_Host(Matrix *ptr, int height, int width, int depth)\n",
        "{\n",
        "\t// Note this function allocates memory, remember to free \n",
        "\tSet_HostMatrix(height, width, depth, ptr);\n",
        "\t\n",
        "\tint Fsize = height * width * depth* sizeof(float);\n",
        " \n",
        "\tptr -> elements = (float *) malloc(Fsize);\n",
        "}\n",
        "\n",
        "void FreeHost_Allocated(Matrix *ptr)\n",
        "{\n",
        "\tfree(ptr -> elements);\n",
        "}\n",
        "\n",
        "// Allocations for Device matrices\n",
        "void Set_DeviceMatrix(int height, int width, int depth, Matrix* ptr, char* NamePtr)\n",
        "{\n",
        "    ptr->width = width;\n",
        "    ptr->height = height;\n",
        "    ptr->depth = depth;\n",
        "\n",
        "    size_t size = width * height * depth * sizeof(float);\n",
        "    cudaError err = cudaMalloc((void **)&(ptr->elements), size);\n",
        "    CheckCudaError(NamePtr, err);\n",
        "}\n",
        "\n",
        "void Set_HostMatrix(int height, int width, int depth, Matrix* ptr)\n",
        "{\n",
        "    ptr->width = width;\n",
        "    ptr->height = height;\n",
        "    ptr->depth = depth;\n",
        "}\n",
        "\n",
        "void CheckCudaError(char* ptr, cudaError err)\n",
        "{\n",
        "    if (err == cudaSuccess);\n",
        "    else\n",
        "        printf(\"CUDA error in %s: %s\\n\", ptr, cudaGetErrorString(err));\n",
        "}\n",
        "\n",
        "\n",
        "void show_me_enhanced(Matrix* ptr, char* NamePtr)\n",
        "{\n",
        "    if(show_out == 1)\n",
        "    {\n",
        "      setvbuf(stdout, NULL, _IOLBF, 0);\n",
        "\n",
        "          printf(\"%s,\"\n",
        "              \"it has height = %d, \"\n",
        "              \"width = %d, \"\n",
        "              \"depth = %d \\n\",\n",
        "              NamePtr, ptr->height, ptr->width, ptr->depth);\n",
        "\n",
        "          printf(\"{\\n\");\n",
        "          for (int i = 0; i < ptr -> height * ptr -> width * ptr -> depth; i++)\n",
        "          {\n",
        "              if (i % ptr->width == 0 && i >= ptr->width)\n",
        "                  printf(\"\\n\");\n",
        "\n",
        "              if (i % (ptr->width * ptr->height) == 0 && i >= (ptr->width * ptr->height));\n",
        "                  //printf(\"\\n\");\n",
        "\n",
        "              printf(\"%.8f\", ptr->elements[i]);\n",
        "              if (i + 1 == ptr->height * ptr->width * ptr->depth);\n",
        "              else\n",
        "                  printf(\", \");\n",
        "          }\n",
        "\n",
        "          printf(\"} \\n\");\n",
        "          printf(\"\\n\");\n",
        "\n",
        "          setvbuf(stdout, NULL, _IOLBF, 0);        \n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "void start()\n",
        "{\n",
        "  HANDLE_ERROR(cudaEventCreate(&start_timing));\n",
        "  HANDLE_ERROR(cudaEventCreate(&stop_timing));\n",
        "  HANDLE_ERROR(cudaEventRecord(start_timing, 0));\n",
        "}\n",
        "\n",
        "void stop(char *notification, int pause_time)\n",
        "{\n",
        "  HANDLE_ERROR(cudaEventRecord(stop_timing, 0));\n",
        "  HANDLE_ERROR(cudaEventSynchronize(stop_timing));\n",
        "  HANDLE_ERROR(cudaEventElapsedTime(&time_defined, start_timing, stop_timing));\n",
        " \n",
        "  if(pause_time)\n",
        " {\n",
        "    tmp_time += time_defined; \n",
        " }   \n",
        " \n",
        "  else\n",
        "  {\n",
        "    tmp_time = 0;\n",
        "    printf(\"Time elapsed for %s:  %.8f ms\\n\", notification, time_defined);  \n",
        "    total_time_for_layer += time_defined;\n",
        "  }\n",
        "}\n",
        "\n",
        "void after_pause(char *notification)\n",
        "{\n",
        "  printf(\"Time elapsed for %s: %.8f ms\\n\", notification, tmp_time); \n",
        "  total_time_for_layer += tmp_time;\n",
        " \n",
        "  tmp_time = 0;         \n",
        "}\n",
        "\n",
        "void reset_time()\n",
        "{\n",
        "  printf(\"Total time: %.8f ms\\n\", total_time_for_layer); \n",
        "  total_time_for_layer = 0;\n",
        "}\n",
        "\n",
        "void show_me_enhanced_from_devince(Matrix *ptr, char *notification)\n",
        "{\n",
        "    Matrix H_OUT;\n",
        "\n",
        "    set_allocate_Host(&H_OUT, ptr -> height, ptr -> width, ptr -> depth);\n",
        "\n",
        "    just_copy_DTH(&H_OUT, ptr, \"show_device_elements\");\n",
        "  \n",
        "    show_out = 1;\n",
        "    show_me_enhanced(&H_OUT, notification);\n",
        "    show_out = 0;  \n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/FUNCTIONS.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dxEa1LxA0H1"
      },
      "source": [
        "# !nvcc -o /content/src/my_curand /content/src/my_curand.cu -lcurand --use_fast_math\n",
        "!nvcc -o /content/src/EfficientNet /content/src/APP.cu /content/src/KERNELS.cu /content/src/FUNCTIONS.cu --use_fast_math "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im2j8WyEBLl_",
        "outputId": "46c4554a-f227-49a9-fcf4-66f2bed85616"
      },
      "source": [
        "!/content/src/EfficientNet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed for Model: :  9.85216045 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWNUsvTZzdFb"
      },
      "source": [
        "with open('Results'+'.txt', 'w') as out:\n",
        "    out.write(cap.stdout)\n",
        "\n",
        "# !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAt6mKlI12-9"
      },
      "source": [
        "!cp Results.txt /content/drive/MyDrive/Colab_Notebooks/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}